{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c47b0f9c-3cb5-4757-959a-d88f7be39a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, GRU, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "from sklearn.metrics import classification_report, accuracy_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b491e3a-26f7-4950-acf7-2acc31f72a06",
   "metadata": {},
   "source": [
    "### **Load and Preprocess Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6373bdf3-0903-49ae-bf5b-4c95c9922899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "# Map original labels to binary values\n",
    "label_mapping = {'__label__0': 0, '__label__1': 1}\n",
    "train_data['label'] = train_data['label'].map(label_mapping)\n",
    "test_data['label'] = test_data['label'].map(label_mapping)\n",
    "\n",
    "# Ensure text column is string type and handle missing values\n",
    "train_data['text'] = train_data['text'].fillna('').astype(str)\n",
    "test_data['text'] = test_data['text'].fillna('').astype(str)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1818106-2ba5-47b0-a7fc-7b902abe7788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple text preprocessing function\n",
    "def preprocess_text(text):\n",
    "    return text.lower()\n",
    "\n",
    "# Apply preprocessing\n",
    "train_data['text'] = train_data['text'].apply(preprocess_text)\n",
    "test_data['text'] = test_data['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acc7ae5d-0e14-4919-a7bc-76bb7272a0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(train_data['text'])\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(train_data['text'])\n",
    "X_test_seq = tokenizer.texts_to_sequences(test_data['text'])\n",
    "\n",
    "# Pad the sequences\n",
    "max_sequence_length = 100\n",
    "X_train_padded = pad_sequences(X_train_seq, maxlen=max_sequence_length)\n",
    "X_test_padded = pad_sequences(X_test_seq, maxlen=max_sequence_length)\n",
    "\n",
    "# Extract labels\n",
    "y_train = train_data['label'].values\n",
    "y_test = test_data['label'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f7c684-bf19-4196-b0e3-47bd25625392",
   "metadata": {},
   "source": [
    "## ***Deep Learning Models***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd2b68c-d6ae-471f-b1ca-5dee90cd86b1",
   "metadata": {},
   "source": [
    "**LSTM Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4abf8bbe-cbce-46b9-a97c-358bc0d23870",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lstm_model(input_length, vocab_size):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size, output_dim=128, input_length=input_length),\n",
    "        LSTM(128, return_sequences=False),\n",
    "        Dropout(0.5),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f603a657-30ee-4a28-8d86-555e34a42798",
   "metadata": {},
   "source": [
    "**GRU Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82553de4-e34e-4ec2-bb6c-f7a332d9dc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_gru_model(input_length, vocab_size):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size, output_dim=128, input_length=input_length),\n",
    "        GRU(128, return_sequences=False),\n",
    "        Dropout(0.5),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c359a6-d610-4a5e-ad91-f881c0efd32d",
   "metadata": {},
   "source": [
    "**CNN Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baad2264-fbde-41f6-81e5-506f7ae3b8d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(input_length, vocab_size):\n",
    "    model = Sequential([\n",
    "        Embedding(input_dim=vocab_size, output_dim=128, input_length=input_length),\n",
    "        Conv1D(128, 5, activation='relu'),\n",
    "        MaxPooling1D(pool_size=2),\n",
    "        GlobalMaxPooling1D(),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cbd093-4951-4bce-bded-a24a77ddb513",
   "metadata": {},
   "source": [
    "### **Train and Evaluate Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81fb89b1-11e7-4abe-8b23-9f891aad55db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "input_length = max_sequence_length\n",
    "batch_size = 32\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45557b36-3733-4abf-8ff9-d7031d493d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training LSTM model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aman Shekhar Sachan\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 145ms/step - accuracy: 0.7833 - loss: 0.5260 - val_accuracy: 0.8612 - val_loss: 0.3793\n",
      "Epoch 2/5\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 143ms/step - accuracy: 0.8770 - loss: 0.3401 - val_accuracy: 0.9015 - val_loss: 0.3025\n",
      "Epoch 3/5\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 138ms/step - accuracy: 0.9064 - loss: 0.2715 - val_accuracy: 0.8967 - val_loss: 0.3111\n",
      "Epoch 4/5\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 139ms/step - accuracy: 0.9142 - loss: 0.2305 - val_accuracy: 0.8780 - val_loss: 0.3453\n",
      "Epoch 5/5\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 139ms/step - accuracy: 0.9320 - loss: 0.1871 - val_accuracy: 0.8754 - val_loss: 0.4003\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step\n",
      "LSTM Accuracy: 0.8705\n",
      "LSTM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.91      3298\n",
      "           1       0.73      0.76      0.75      1103\n",
      "\n",
      "    accuracy                           0.87      4401\n",
      "   macro avg       0.83      0.83      0.83      4401\n",
      "weighted avg       0.87      0.87      0.87      4401\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate LSTM model\n",
    "print(\"Training LSTM model...\")\n",
    "lstm_model = create_lstm_model(input_length, vocab_size)\n",
    "lstm_model.fit(X_train_padded, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
    "lstm_y_pred = (lstm_model.predict(X_test_padded) > 0.5).astype(int)\n",
    "lstm_accuracy = accuracy_score(y_test, lstm_y_pred)\n",
    "print(f\"LSTM Accuracy: {lstm_accuracy:.4f}\")\n",
    "print(\"LSTM Classification Report:\")\n",
    "print(classification_report(y_test, lstm_y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d1bcb67-fcc9-4059-9db5-2d2b04ef66ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training GRU model...\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aman Shekhar Sachan\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 121ms/step - accuracy: 0.7922 - loss: 0.5170 - val_accuracy: 0.8978 - val_loss: 0.3136\n",
      "Epoch 2/5\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 122ms/step - accuracy: 0.8848 - loss: 0.3177 - val_accuracy: 0.9032 - val_loss: 0.3067\n",
      "Epoch 3/5\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 121ms/step - accuracy: 0.8934 - loss: 0.2919 - val_accuracy: 0.8953 - val_loss: 0.3297\n",
      "Epoch 4/5\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m86s\u001b[0m 130ms/step - accuracy: 0.9080 - loss: 0.2481 - val_accuracy: 0.8916 - val_loss: 0.3455\n",
      "Epoch 5/5\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 127ms/step - accuracy: 0.9106 - loss: 0.2278 - val_accuracy: 0.8709 - val_loss: 0.3674\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 31ms/step\n",
      "GRU Accuracy: 0.8632\n",
      "GRU Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91      3298\n",
      "           1       0.72      0.74      0.73      1103\n",
      "\n",
      "    accuracy                           0.86      4401\n",
      "   macro avg       0.82      0.82      0.82      4401\n",
      "weighted avg       0.86      0.86      0.86      4401\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate GRU model\n",
    "print(\"\\nTraining GRU model...\")\n",
    "gru_model = create_gru_model(input_length, vocab_size)\n",
    "gru_model.fit(X_train_padded, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
    "gru_y_pred = (gru_model.predict(X_test_padded) > 0.5).astype(int)\n",
    "gru_accuracy = accuracy_score(y_test, gru_y_pred)\n",
    "print(f\"GRU Accuracy: {gru_accuracy:.4f}\")\n",
    "print(\"GRU Classification Report:\")\n",
    "print(classification_report(y_test, gru_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0ec6b76-2076-49d8-b581-3e598967a843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training CNN model...\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aman Shekhar Sachan\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 65ms/step - accuracy: 0.7961 - loss: 0.4869 - val_accuracy: 0.9047 - val_loss: 0.2814\n",
      "Epoch 2/5\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 65ms/step - accuracy: 0.9028 - loss: 0.2764 - val_accuracy: 0.9030 - val_loss: 0.2859\n",
      "Epoch 3/5\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 64ms/step - accuracy: 0.9303 - loss: 0.1914 - val_accuracy: 0.8885 - val_loss: 0.3365\n",
      "Epoch 4/5\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 63ms/step - accuracy: 0.9683 - loss: 0.1041 - val_accuracy: 0.8785 - val_loss: 0.4106\n",
      "Epoch 5/5\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 63ms/step - accuracy: 0.9887 - loss: 0.0469 - val_accuracy: 0.8686 - val_loss: 0.5453\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
      "CNN Accuracy: 0.8648\n",
      "CNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91      3298\n",
      "           1       0.78      0.65      0.71      1103\n",
      "\n",
      "    accuracy                           0.86      4401\n",
      "   macro avg       0.83      0.79      0.81      4401\n",
      "weighted avg       0.86      0.86      0.86      4401\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate CNN model\n",
    "print(\"\\nTraining CNN model...\")\n",
    "cnn_model = create_cnn_model(input_length, vocab_size)\n",
    "cnn_model.fit(X_train_padded, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)\n",
    "cnn_y_pred = (cnn_model.predict(X_test_padded) > 0.5).astype(int)\n",
    "cnn_accuracy = accuracy_score(y_test, cnn_y_pred)\n",
    "print(f\"CNN Accuracy: {cnn_accuracy:.4f}\")\n",
    "print(\"CNN Classification Report:\")\n",
    "print(classification_report(y_test, cnn_y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0971185-b521-4297-b2d2-d389c32e6ab9",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90c0b301-3e6b-48fe-b1ae-7de27e1779e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c84eba5a-7e89-4279-a547-1789922b004e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from hyperparam_tuning\\lstm_tuning\\tuner0.json\n",
      "{'embedding_dim': 256, 'lstm_units': 160, 'dropout_rate': 0.30000000000000004, 'dense_units': 32, 'dropout_rate_2': 0.30000000000000004, 'learning_rate': 0.0007940243226892147, 'tuner/epochs': 10, 'tuner/initial_epoch': 4, 'tuner/bracket': 1, 'tuner/round': 1, 'tuner/trial_id': '0023'}\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aman Shekhar Sachan\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 219ms/step - accuracy: 0.7950 - loss: 0.4988 - val_accuracy: 0.9010 - val_loss: 0.3002\n",
      "Epoch 2/10\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 224ms/step - accuracy: 0.8835 - loss: 0.3213 - val_accuracy: 0.8961 - val_loss: 0.3026\n",
      "Epoch 3/10\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 226ms/step - accuracy: 0.9024 - loss: 0.2713 - val_accuracy: 0.8973 - val_loss: 0.3093\n",
      "Epoch 4/10\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 226ms/step - accuracy: 0.9034 - loss: 0.2461 - val_accuracy: 0.8990 - val_loss: 0.3339\n",
      "Epoch 5/10\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 225ms/step - accuracy: 0.9190 - loss: 0.1991 - val_accuracy: 0.8873 - val_loss: 0.3849\n",
      "Epoch 6/10\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 225ms/step - accuracy: 0.9340 - loss: 0.1562 - val_accuracy: 0.8777 - val_loss: 0.4402\n",
      "Epoch 7/10\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 223ms/step - accuracy: 0.9527 - loss: 0.1213 - val_accuracy: 0.8496 - val_loss: 0.5320\n",
      "Epoch 8/10\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 226ms/step - accuracy: 0.9643 - loss: 0.0972 - val_accuracy: 0.8578 - val_loss: 0.6619\n",
      "Epoch 9/10\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 239ms/step - accuracy: 0.9696 - loss: 0.0808 - val_accuracy: 0.8405 - val_loss: 0.6934\n",
      "Epoch 10/10\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 216ms/step - accuracy: 0.9812 - loss: 0.0567 - val_accuracy: 0.8462 - val_loss: 0.7748\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1c3fdb12790>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a hypermodel for LSTM with Keras Tuner\n",
    "def build_lstm_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=hp.Int('embedding_dim', 64, 256, step=64), input_length=input_length))\n",
    "    model.add(LSTM(units=hp.Int('lstm_units', 32, 256, step=32), return_sequences=False))\n",
    "    model.add(Dropout(rate=hp.Float('dropout_rate', 0.2, 0.5, step=0.1)))\n",
    "    model.add(Dense(units=hp.Int('dense_units', 32, 128, step=32), activation='relu'))\n",
    "    model.add(Dropout(rate=hp.Float('dropout_rate_2', 0.2, 0.5, step=0.1)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(hp.Float('learning_rate', 1e-4, 1e-2, sampling='log')),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# Initialize the tuner\n",
    "tuner = kt.Hyperband(\n",
    "    build_lstm_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=10,\n",
    "    factor=3,\n",
    "    directory='hyperparam_tuning',\n",
    "    project_name='lstm_tuning'\n",
    ")\n",
    "# Search for the best hyperparameters\n",
    "tuner.search(X_train_padded, y_train, epochs=10, validation_split=0.2)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_hyperparameters = tuner.get_best_hyperparameters(1)[0]\n",
    "print(best_hyperparameters.values)\n",
    "\n",
    "# Get the best model\n",
    "best_lstm_model = tuner.hypermodel.build(best_hyperparameters)\n",
    "\n",
    "# Train the best model\n",
    "best_lstm_model.fit(X_train_padded, y_train, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59be98d5-8a8c-4df1-a355-b5f063a16be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hypermodel for GRU\n",
    "def build_gru_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=hp.Int('embedding_dim', 64, 256, step=64), input_length=input_length))\n",
    "    model.add(GRU(units=hp.Int('gru_units', 32, 256, step=32), return_sequences=False))\n",
    "    model.add(Dropout(rate=hp.Float('dropout_rate', 0.2, 0.5, step=0.1)))\n",
    "    model.add(Dense(units=hp.Int('dense_units', 32, 128, step=32), activation='relu'))\n",
    "    model.add(Dropout(rate=hp.Float('dropout_rate_2', 0.2, 0.5, step=0.1)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(hp.Float('learning_rate', 1e-4, 1e-2, sampling='log')),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5669f5e9-e1ae-41d7-aab8-0b9e07b60d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define hypermodel for CNN\n",
    "def build_cnn_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(input_dim=vocab_size, output_dim=hp.Int('embedding_dim', 64, 256, step=64), input_length=input_length))\n",
    "    model.add(Conv1D(filters=hp.Int('conv_filters', 32, 128, step=32), kernel_size=hp.Choice('kernel_size', [3, 5, 7]), activation='relu'))\n",
    "    model.add(MaxPooling1D(pool_size=hp.Choice('pool_size', [2, 3])))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    model.add(Dense(units=hp.Int('dense_units', 32, 128, step=32), activation='relu'))\n",
    "    model.add(Dropout(rate=hp.Float('dropout_rate', 0.2, 0.5, step=0.1)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(hp.Float('learning_rate', 1e-4, 1e-2, sampling='log')),\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22027213-ee2f-4830-b521-f149dde5efda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from hyperparam_tuning\\lstm_tuning\\tuner0.json\n",
      "Reloading Tuner from hyperparam_tuning\\gru_tuning\\tuner0.json\n",
      "Reloading Tuner from hyperparam_tuning\\cnn_tuning\\tuner0.json\n"
     ]
    }
   ],
   "source": [
    "# Tune and train models\n",
    "tuners = {\n",
    "    'LSTM': kt.Hyperband(build_lstm_model, objective='val_accuracy', max_epochs=10, factor=3, directory='hyperparam_tuning', project_name='lstm_tuning'),\n",
    "    'GRU': kt.Hyperband(build_gru_model, objective='val_accuracy', max_epochs=10, factor=3, directory='hyperparam_tuning', project_name='gru_tuning'),\n",
    "    'CNN': kt.Hyperband(build_cnn_model, objective='val_accuracy', max_epochs=10, factor=3, directory='hyperparam_tuning', project_name='cnn_tuning')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4210e9ac-132a-4a92-a112-e9279779a309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 06m 38s]\n",
      "val_accuracy: 0.9026674032211304\n",
      "\n",
      "Best val_accuracy So Far: 0.9060726165771484\n",
      "Total elapsed time: 03h 41m 23s\n",
      "Epoch 1/10\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 28ms/step - accuracy: 0.7627 - loss: 0.5670 - val_accuracy: 0.8306 - val_loss: 0.4250\n",
      "Epoch 2/10\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - accuracy: 0.8831 - loss: 0.3291 - val_accuracy: 0.9049 - val_loss: 0.2826\n",
      "Epoch 3/10\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - accuracy: 0.9118 - loss: 0.2336 - val_accuracy: 0.8930 - val_loss: 0.3062\n",
      "Epoch 4/10\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 29ms/step - accuracy: 0.9462 - loss: 0.1580 - val_accuracy: 0.8851 - val_loss: 0.3569\n",
      "Epoch 5/10\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - accuracy: 0.9769 - loss: 0.0864 - val_accuracy: 0.8785 - val_loss: 0.3973\n",
      "Epoch 6/10\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - accuracy: 0.9882 - loss: 0.0501 - val_accuracy: 0.8698 - val_loss: 0.4716\n",
      "Epoch 7/10\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - accuracy: 0.9932 - loss: 0.0296 - val_accuracy: 0.8726 - val_loss: 0.5331\n",
      "Epoch 8/10\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - accuracy: 0.9927 - loss: 0.0254 - val_accuracy: 0.8720 - val_loss: 0.5705\n",
      "Epoch 9/10\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - accuracy: 0.9956 - loss: 0.0189 - val_accuracy: 0.8683 - val_loss: 0.6235\n",
      "Epoch 10/10\n",
      "\u001b[1m441/441\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - accuracy: 0.9948 - loss: 0.0188 - val_accuracy: 0.8717 - val_loss: 0.5980\n"
     ]
    }
   ],
   "source": [
    "best_models = {}\n",
    "\n",
    "for model_name, tuner in tuners.items():\n",
    "    print(f\"Tuning and training {model_name}...\")\n",
    "    tuner.search(X_train_padded, y_train, epochs=10, validation_split=0.2)\n",
    "    best_hyperparameters = tuner.get_best_hyperparameters(1)[0]\n",
    "    best_model = tuner.hypermodel.build(best_hyperparameters)\n",
    "    best_model.fit(X_train_padded, y_train, epochs=10, validation_split=0.2)\n",
    "    best_models[model_name] = best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a426b07-d05e-4d6e-9c86-427c8fd896fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating LSTM...\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 49ms/step\n",
      "LSTM Accuracy: 0.8337\n",
      "LSTM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.91      0.89      3298\n",
      "           1       0.69      0.61      0.65      1103\n",
      "\n",
      "    accuracy                           0.83      4401\n",
      "   macro avg       0.78      0.76      0.77      4401\n",
      "weighted avg       0.83      0.83      0.83      4401\n",
      "\n",
      "\n",
      "Evaluating GRU...\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 57ms/step\n",
      "GRU Accuracy: 0.8355\n",
      "GRU Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.89      3298\n",
      "           1       0.68      0.65      0.67      1103\n",
      "\n",
      "    accuracy                           0.84      4401\n",
      "   macro avg       0.78      0.77      0.78      4401\n",
      "weighted avg       0.83      0.84      0.83      4401\n",
      "\n",
      "\n",
      "Evaluating CNN...\n",
      "\u001b[1m138/138\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
      "CNN Accuracy: 0.8680\n",
      "CNN Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91      3298\n",
      "           1       0.78      0.66      0.71      1103\n",
      "\n",
      "    accuracy                           0.87      4401\n",
      "   macro avg       0.84      0.80      0.81      4401\n",
      "weighted avg       0.86      0.87      0.86      4401\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate models\n",
    "results = {}\n",
    "for model_name, model in best_models.items():\n",
    "    print(f\"\\nEvaluating {model_name}...\")\n",
    "    y_pred = (model.predict(X_test_padded) > 0.5).astype(int)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{model_name} Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"{model_name} Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    results[model_name] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "15055dc1-c89d-49cb-9993-2dbfbb23dd2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Comparison:\n",
      "LSTM: 0.8337\n",
      "GRU: 0.8355\n",
      "CNN: 0.8680\n"
     ]
    }
   ],
   "source": [
    "# Print comparison\n",
    "print(\"\\nModel Comparison:\")\n",
    "for model_name, accuracy in results.items():\n",
    "    print(f\"{model_name}: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cda14d-2eb1-40ac-b1a6-16dfc543b703",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
