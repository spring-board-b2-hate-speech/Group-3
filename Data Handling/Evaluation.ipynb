{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9326914-3ce6-4e1a-bdb0-9fa1b002c4d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_spacy</th>\n",
       "      <th>word2vec_vector</th>\n",
       "      <th>cleaned_comment</th>\n",
       "      <th>fasttext_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A subsection of retarded Hungarians? Oh boy. b...</td>\n",
       "      <td>1</td>\n",
       "      <td>['a', 'subsection', 'of', 'retarded', 'hungari...</td>\n",
       "      <td>['a', 'subsection', 'of', 'retarded', 'hungari...</td>\n",
       "      <td>[ 0.36349716 -0.22094536  0.01051669 -0.602767...</td>\n",
       "      <td>a subsection of retarded hungarians oh boy bra...</td>\n",
       "      <td>[0.004770048428326845, -0.03953176364302635, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iii. Just got off work. Foundation and groundi...</td>\n",
       "      <td>0</td>\n",
       "      <td>['iii', '.', 'just', 'got', 'off', 'work', '.'...</td>\n",
       "      <td>['iii', '.', 'just', 'got', 'off', 'work', '.'...</td>\n",
       "      <td>[ 0.06504157 -0.12219669  0.10038512 -0.005708...</td>\n",
       "      <td>iii just got off work foundation and grounding...</td>\n",
       "      <td>[-0.012044071219861507, -0.011684201657772064,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wow i guess cowboys are the same in every country</td>\n",
       "      <td>0</td>\n",
       "      <td>['wow', 'i', 'guess', 'cowboys', 'are', 'the',...</td>\n",
       "      <td>['wow', 'i', 'guess', 'cowboys', 'are', 'the',...</td>\n",
       "      <td>[ 2.92166289e-01  3.85734248e-01 -4.80327269e-...</td>\n",
       "      <td>wow i guess cowboys are the same in every country</td>\n",
       "      <td>[-0.0008766286191530526, 0.0192383024841547, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Owen Benjamin's cowboy song goes for every cou...</td>\n",
       "      <td>0</td>\n",
       "      <td>['owen', 'benjamin', \"'s\", 'cowboy', 'song', '...</td>\n",
       "      <td>['owen', 'benjamin', \"'s\", 'cowboy', 'song', '...</td>\n",
       "      <td>[ 0.07474209  0.08315161 -0.081609   -0.397689...</td>\n",
       "      <td>owen benjamins cowboy song goes for every coun...</td>\n",
       "      <td>[0.00418263953179121, -0.0029789397958666086, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&gt; \"y'all hear sun?\" by all means I live in a s...</td>\n",
       "      <td>0</td>\n",
       "      <td>['&gt;', '``', \"y'all\", 'hear', 'sun', '?', \"''\",...</td>\n",
       "      <td>['&gt;', '\"', \"y'\", 'all', 'hear', 'sun', '?', '\"...</td>\n",
       "      <td>[ 0.19263356 -0.10749349 -0.08967624 -0.271426...</td>\n",
       "      <td>yall hear sun by all means i live in a small t...</td>\n",
       "      <td>[-6.847345503047109e-05, 0.0004209601611364633...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  hate_speech  \\\n",
       "0  A subsection of retarded Hungarians? Oh boy. b...            1   \n",
       "1  Iii. Just got off work. Foundation and groundi...            0   \n",
       "2  wow i guess cowboys are the same in every country            0   \n",
       "3  Owen Benjamin's cowboy song goes for every cou...            0   \n",
       "4  > \"y'all hear sun?\" by all means I live in a s...            0   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  ['a', 'subsection', 'of', 'retarded', 'hungari...   \n",
       "1  ['iii', '.', 'just', 'got', 'off', 'work', '.'...   \n",
       "2  ['wow', 'i', 'guess', 'cowboys', 'are', 'the',...   \n",
       "3  ['owen', 'benjamin', \"'s\", 'cowboy', 'song', '...   \n",
       "4  ['>', '``', \"y'all\", 'hear', 'sun', '?', \"''\",...   \n",
       "\n",
       "                                        tokens_spacy  \\\n",
       "0  ['a', 'subsection', 'of', 'retarded', 'hungari...   \n",
       "1  ['iii', '.', 'just', 'got', 'off', 'work', '.'...   \n",
       "2  ['wow', 'i', 'guess', 'cowboys', 'are', 'the',...   \n",
       "3  ['owen', 'benjamin', \"'s\", 'cowboy', 'song', '...   \n",
       "4  ['>', '\"', \"y'\", 'all', 'hear', 'sun', '?', '\"...   \n",
       "\n",
       "                                     word2vec_vector  \\\n",
       "0  [ 0.36349716 -0.22094536  0.01051669 -0.602767...   \n",
       "1  [ 0.06504157 -0.12219669  0.10038512 -0.005708...   \n",
       "2  [ 2.92166289e-01  3.85734248e-01 -4.80327269e-...   \n",
       "3  [ 0.07474209  0.08315161 -0.081609   -0.397689...   \n",
       "4  [ 0.19263356 -0.10749349 -0.08967624 -0.271426...   \n",
       "\n",
       "                                     cleaned_comment  \\\n",
       "0  a subsection of retarded hungarians oh boy bra...   \n",
       "1  iii just got off work foundation and grounding...   \n",
       "2  wow i guess cowboys are the same in every country   \n",
       "3  owen benjamins cowboy song goes for every coun...   \n",
       "4  yall hear sun by all means i live in a small t...   \n",
       "\n",
       "                                     fasttext_vector  \n",
       "0  [0.004770048428326845, -0.03953176364302635, -...  \n",
       "1  [-0.012044071219861507, -0.011684201657772064,...  \n",
       "2  [-0.0008766286191530526, 0.0192383024841547, 0...  \n",
       "3  [0.00418263953179121, -0.0029789397958666086, ...  \n",
       "4  [-6.847345503047109e-05, 0.0004209601611364633...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "df = pd.read_csv('RedditTokenized.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3838d101-0295-43dc-8fce-c0808cf13782",
   "metadata": {},
   "source": [
    "## Improving model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c8ad40-0b05-4af2-9ca2-822c63e971e3",
   "metadata": {},
   "source": [
    "#### Techniques for Handling Imbalanced Data\n",
    "- ##### Data Resampling Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58e5230e-0252-475e-9c88-312f644a5181",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aman Shekhar Sachan\\AppData\\Local\\Temp\\ipykernel_8368\\2969848702.py:6: DeprecationWarning: string or file could not be read to its end due to unmatched data; this will raise a ValueError in the future.\n",
      "  df['word2vec_vector'] = df['word2vec_vector'].apply(lambda x: np.fromstring(x.strip('[]'), sep=','))\n"
     ]
    }
   ],
   "source": [
    "#Over-sampling the minority class\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Convert string representation of vectors to actual numerical format\n",
    "df['word2vec_vector'] = df['word2vec_vector'].apply(lambda x: np.fromstring(x.strip('[]'), sep=','))\n",
    "df['fasttext_vector'] = df['fasttext_vector'].apply(lambda x: np.fromstring(x.strip('[]'), sep=','))\n",
    "\n",
    "# Combine numerical features\n",
    "X = np.vstack(df['word2vec_vector'].values)\n",
    "# Alternatively, you can also use 'fasttext_vector' or combine both\n",
    "# X = np.hstack((np.vstack(df['word2vec_vector'].values), np.vstack(df['fasttext_vector'].values)))\n",
    "\n",
    "y = df['hate_speech']\n",
    "\n",
    "# Initialize SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "\n",
    "# Fit and resample\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Create DataFrame from resampled data\n",
    "df_resampled = pd.DataFrame(X_resampled, columns=[f'vector_{i}' for i in range(X_resampled.shape[1])])\n",
    "df_resampled['hate_speech'] = y_resampled\n",
    "\n",
    "# Optionally, recombine vectors into a format similar to the original\n",
    "df_resampled['word2vec_vector'] = df_resampled[[f'vector_{i}' for i in range(X_resampled.shape[1])]].apply(lambda x: x.values, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fffa37e9-3eeb-4323-8b1b-60ae395d3393",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Undersampling the Majority Class\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# Extract the feature vectors and target\n",
    "X = np.vstack(df['word2vec_vector'].values)\n",
    "y = df['hate_speech']\n",
    "\n",
    "# Apply undersampling\n",
    "undersampler = RandomUnderSampler(random_state=42)\n",
    "X_resampled, y_resampled = undersampler.fit_resample(X, y)\n",
    "\n",
    "# Reconstruct DataFrame\n",
    "df_resampled = pd.DataFrame(X_resampled, columns=[f'vector_{i}' for i in range(X_resampled.shape[1])])\n",
    "df_resampled['hate_speech'] = y_resampled\n",
    "\n",
    "# Optionally, recombine vectors into a format similar to the original\n",
    "df_resampled['word2vec_vector'] = df_resampled[[f'vector_{i}' for i in range(X_resampled.shape[1])]].apply(lambda x: x.values, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fafe30b1-b86e-4682-856e-051244c5f824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combination of Over- and Undersampling\n",
    "\n",
    "from imblearn.combine import SMOTETomek\n",
    "#SMOTETomek\n",
    "smote_tomek = SMOTETomek(random_state=42)\n",
    "X_resampled_tomek, y_resampled_tomek = smote_tomek.fit_resample(X, y)\n",
    "\n",
    "# Reconstruct DataFrame for SMOTETomek\n",
    "df_resampled_tomek = pd.DataFrame(X_resampled_tomek, columns=[f'vector_{i}' for i in range(X_resampled_tomek.shape[1])])\n",
    "df_resampled_tomek['hate_speech'] = y_resampled_tomek\n",
    "\n",
    "# Optionally, recombine vectors into a format similar to the original\n",
    "df_resampled_tomek['word2vec_vector'] = df_resampled_tomek[[f'vector_{i}' for i in range(X_resampled_tomek.shape[1])]].apply(lambda x: x.values, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e658d866-d012-4609-aeca-91d20c3923c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.45      0.56      3341\n",
      "           1       0.25      0.54      0.34      1109\n",
      "\n",
      "    accuracy                           0.48      4450\n",
      "   macro avg       0.50      0.50      0.45      4450\n",
      "weighted avg       0.62      0.48      0.51      4450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using Class Weights\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming you have your dataset ready in X and y\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Logistic Regression with class weights\n",
    "model = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3fffd4a-9c8a-4202-9bbb-4f0a6414d0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.75      3341\n",
      "           1       0.25      0.25      0.25      1109\n",
      "\n",
      "    accuracy                           0.63      4450\n",
      "   macro avg       0.50      0.50      0.50      4450\n",
      "weighted avg       0.63      0.63      0.63      4450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Algorithmic Approaches\n",
    "#Many algorithms can inherently handle imbalanced data by adjusting for class weights.\n",
    "\n",
    "#Example with RandomForest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# RandomForest with class weights\n",
    "rf_model = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f598ded-2268-4df8-9c01-88d0018a56b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.90      0.82      3341\n",
      "           1       0.24      0.10      0.14      1109\n",
      "\n",
      "    accuracy                           0.70      4450\n",
      "   macro avg       0.49      0.50      0.48      4450\n",
      "weighted avg       0.62      0.70      0.65      4450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Anomaly Detection Techniques\n",
    "#Anomaly detection can be useful for imbalanced datasets, particularly when the minority class is significantly underrepresented.\n",
    "\n",
    "#Example with Isolation Forest\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Fit Isolation Forest\n",
    "iso_forest = IsolationForest(contamination=0.1, random_state=42)\n",
    "y_train_pred = iso_forest.fit_predict(X_train)\n",
    "y_test_pred = iso_forest.predict(X_test)\n",
    "\n",
    "# Convert the output to binary classification (1 for normal, -1 for anomaly)\n",
    "y_train_pred = [1 if x == -1 else 0 for x in y_train_pred]\n",
    "y_test_pred = [1 if x == -1 else 0 for x in y_test_pred]\n",
    "\n",
    "print(classification_report(y_test, y_test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2999f422-8d1a-47c5-bcaf-74296c55e100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.47      0.48      3379\n",
      "           1       0.50      0.52      0.51      3405\n",
      "\n",
      "    accuracy                           0.49      6784\n",
      "   macro avg       0.49      0.49      0.49      6784\n",
      "weighted avg       0.49      0.49      0.49      6784\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Generating Synthetic Data\n",
    "#Using techniques like SMOTE (Synthetic Minority Over-sampling Technique) to generate synthetic samples for the minority class can help balance the dataset.\n",
    "\n",
    "#Example with SMOTE\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_res, y_res = smote.fit_resample(X, y)\n",
    "\n",
    "# Splitting resampled data\n",
    "X_train_res, X_test_res, y_train_res, y_test_res = train_test_split(X_res, y_res, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model training with resampled data\n",
    "model_resampled = LogisticRegression(random_state=42)\n",
    "model_resampled.fit(X_train_res, y_train_res)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred_resampled = model_resampled.predict(X_test_res)\n",
    "print(classification_report(y_test_res, y_pred_resampled))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4c0163-f160-4c97-b47c-cf195cbb825e",
   "metadata": {},
   "source": [
    "#### Evaluation and Validation\n",
    "##### Proper evaluation is crucial for imbalanced datasets. Metrics like Precision, Recall, F1-score, and AUC-ROC should be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a317c334-ede0-4d87-b95b-07667b665a31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[2525  816]\n",
      " [ 836  273]]\n",
      "Precision-Recall AUC: 0.342360796219475\n",
      "ROC-AUC Score: 0.5009647333225555\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, auc, confusion_matrix\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_rf)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Precision-Recall Curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_rf)\n",
    "pr_auc = auc(recall, precision)\n",
    "print(f\"Precision-Recall AUC: {pr_auc}\")\n",
    "\n",
    "# ROC-AUC Score\n",
    "roc_auc = roc_auc_score(y_test, y_pred_rf)\n",
    "print(f\"ROC-AUC Score: {roc_auc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db84e3dc-95d8-419c-bf33-00632033b958",
   "metadata": {},
   "source": [
    "#### Pipeline Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57b6d339-d21a-439d-9e98-1ac367e68638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.45      0.56      3341\n",
      "           1       0.25      0.54      0.34      1109\n",
      "\n",
      "    accuracy                           0.48      4450\n",
      "   macro avg       0.50      0.50      0.45      4450\n",
      "weighted avg       0.62      0.48      0.51      4450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = ImbPipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('classifier', LogisticRegression(random_state=42))\n",
    "])\n",
    "\n",
    "# Fit the pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred_pipeline = pipeline.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_pipeline))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d15e1ef-ed3b-4219-a459-f59accafdb17",
   "metadata": {},
   "source": [
    "### The results indicate that the model is not performing well:\n",
    "\n",
    "- ##### High False Positives and False Negatives:  The high number of both false positives and false negatives suggests that the model is not correctly identifying the minority class (hate speech).\n",
    "- ##### Low Precision-Recall AUC:  Indicates poor balance between precision and recall.\n",
    "- ##### ROC-AUC close to 0.5:  Shows the model struggles to distinguish between classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9412ba0-258c-41ea-aaca-e51d49d4bf8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[2524  817]\n",
      " [ 328  781]]\n",
      "Precision-Recall AUC: 0.6333409186838915\n",
      "ROC-AUC Score: 0.7298502443478286\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.76      0.82      3341\n",
      "           1       0.49      0.70      0.58      1109\n",
      "\n",
      "    accuracy                           0.74      4450\n",
      "   macro avg       0.69      0.73      0.70      4450\n",
      "weighted avg       0.79      0.74      0.76      4450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve, auc, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Assuming X contains FastText vectors and y is the target labels\n",
    "X = np.array(df['fasttext_vector'].tolist())  # Use FastText vectors\n",
    "y = df['hate_speech']  # Target labels\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Resample the data\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Logistic Regression with hyperparameter tuning\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'solver': ['lbfgs', 'liblinear']\n",
    "}\n",
    "model = GridSearchCV(LogisticRegression(class_weight='balanced', max_iter=1000), param_grid, cv=5, scoring='f1')\n",
    "model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Confusion Matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Precision-Recall Curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred)\n",
    "pr_auc = auc(recall, precision)\n",
    "print(f\"Precision-Recall AUC: {pr_auc}\")\n",
    "\n",
    "# ROC-AUC Score\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(f\"ROC-AUC Score: {roc_auc}\")\n",
    "\n",
    "# Detailed report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "876396a5-8c02-4834-98b3-e0daed0532d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[2779  562]\n",
      " [ 311  798]]\n",
      "Precision-Recall AUC: 0.6881097619846513\n",
      "ROC-AUC Score: 0.7756770338950801\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.83      0.86      3341\n",
      "           1       0.59      0.72      0.65      1109\n",
      "\n",
      "    accuracy                           0.80      4450\n",
      "   macro avg       0.74      0.78      0.76      4450\n",
      "weighted avg       0.82      0.80      0.81      4450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Assuming the structure of your dataset\n",
    "X = df['cleaned_comment'].astype(str)  # Convert to string explicitly if needed\n",
    "y = df['hate_speech']  # Replace with your actual target column\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform feature extraction using TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Resample the training data using SMOTE due to class imbalance\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_tfidf_resampled, y_train_resampled = smote.fit_resample(X_train_tfidf, y_train)\n",
    "\n",
    "# Logistic Regression with hyperparameter tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],\n",
    "    'solver': ['lbfgs', 'liblinear']\n",
    "}\n",
    "model = GridSearchCV(LogisticRegression(class_weight='balanced', max_iter=1000), param_grid, cv=5, scoring='f1')\n",
    "model.fit(X_train_tfidf_resampled, y_train_resampled)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred)\n",
    "pr_auc = auc(recall, precision)\n",
    "print(f\"Precision-Recall AUC: {pr_auc}\")\n",
    "\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "print(f\"ROC-AUC Score: {roc_auc}\")\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6ea4a3-93e7-41d4-9583-b2d3ebc6e4a0",
   "metadata": {},
   "source": [
    "#### Great job on improving the model performance! Now that we have these evaluation metrics:\n",
    "\n",
    "- ##### Precision-Recall AUC: 0.688\n",
    "- ##### ROC-AUC Score: 0.776\n",
    "- ##### F1-score: 0.65 for class 1 (hate speech)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55dc042-00e4-4936-9d78-1bf1fcaff5bd",
   "metadata": {},
   "source": [
    "### Next steps to consider for further improvement:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da08e77-43af-46d2-a4cc-97bc6b07dbc6",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b9c5d78-87c2-4abc-a64f-813aeb963c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier Performance:\n",
      "Confusion Matrix:\n",
      " [[3179  162]\n",
      " [ 354  755]]\n",
      "Precision-Recall AUC: 0.8063958932310429\n",
      "ROC-AUC Score: 0.816152515580261\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.95      0.92      3341\n",
      "           1       0.82      0.68      0.75      1109\n",
      "\n",
      "    accuracy                           0.88      4450\n",
      "   macro avg       0.86      0.82      0.84      4450\n",
      "weighted avg       0.88      0.88      0.88      4450\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize Random Forest classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Fit the model\n",
    "rf_model.fit(X_train_tfidf_resampled, y_train_resampled)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_pred_rf = rf_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Random Forest Classifier Performance:\")\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))\n",
    "print(\"Precision-Recall AUC:\", auc(recall, precision_recall_curve(y_test, y_pred_rf)[0]))\n",
    "print(\"ROC-AUC Score:\", roc_auc_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff03765-8d61-4812-b5d1-9177ff0191a0",
   "metadata": {},
   "source": [
    "#### Using Multinomial Naive Bayes for Hate Speech Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8d220f01-86f6-404f-9971-03f929150428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[3356   29]\n",
      " [ 771  287]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.99      0.89      3385\n",
      "           1       0.91      0.27      0.42      1058\n",
      "\n",
      "    accuracy                           0.82      4443\n",
      "   macro avg       0.86      0.63      0.66      4443\n",
      "weighted avg       0.84      0.82      0.78      4443\n",
      "\n",
      "ROC-AUC Score: 0.8432351947460859\n",
      "Precision-Recall AUC: 0.7221803482578294\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Handle missing values in the text data\n",
    "# Option 1: Remove rows with NaN values in 'cleaned_comment'\n",
    "df = df.dropna(subset=['cleaned_comment'])\n",
    "\n",
    "# Option 2: Fill NaN values with a placeholder (if appropriate)\n",
    "# df['cleaned_comment'] = df['cleaned_comment'].fillna('missing')\n",
    "\n",
    "# Extract features and labels\n",
    "X = df['cleaned_comment'].astype(str)  # Convert to string to avoid issues with TfidfVectorizer\n",
    "y = df['hate_speech']\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Feature extraction using TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Train the Naive Bayes classifier\n",
    "naive_bayes = MultinomialNB()\n",
    "naive_bayes.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predictions on the test set\n",
    "y_pred = naive_bayes.predict(X_test_tfidf)\n",
    "y_pred_proba = naive_bayes.predict_proba(X_test_tfidf)[:, 1]\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# ROC-AUC Score\n",
    "roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
    "print(f\"ROC-AUC Score: {roc_auc}\")\n",
    "\n",
    "# Precision-Recall Curve and AUC\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n",
    "pr_auc = auc(recall, precision)\n",
    "print(f\"Precision-Recall AUC: {pr_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81176da-4d2f-4aab-b465-ec0af1db52f2",
   "metadata": {},
   "source": [
    "### Observations\n",
    "- ##### The Random Forest Classifier has a high overall accuracy (0.88) and good precision and recall for both classes, especially class 0.\n",
    "- ##### The \"Other Model\" has a very high precision for class 1 but a very low recall, indicating that it misses many of the true positives for class 1.\n",
    "- ##### The Random Forest Classifier provides a better balance between precision and recall for the minority class, which is crucial for handling class imbalance.\n",
    "- ##### The ROC-AUC score of 0.816 and Precision-Recall AUC of 0.806 for the Random Forest Classifier suggest that it is relatively robust and balanced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679ff3f1-f8b1-47bc-a48e-9b6c6c66b83c",
   "metadata": {},
   "source": [
    "#### Simplified Hyperparameter Tuning with RandomizedSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab2a3831-fc56-4e3f-9e70-306c8267b653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best Parameters: {'n_estimators': 80, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_depth': None, 'bootstrap': False}\n",
      "Confusion Matrix:\n",
      " [[2792  593]\n",
      " [ 762  296]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.82      0.80      3385\n",
      "           1       0.33      0.28      0.30      1058\n",
      "\n",
      "    accuracy                           0.70      4443\n",
      "   macro avg       0.56      0.55      0.55      4443\n",
      "weighted avg       0.68      0.70      0.69      4443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Define the parameter grid for Random Forest\n",
    "'''\n",
    "param_dist_rf = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [5, 10, 15, 20, 25, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "'''\n",
    "\n",
    "param_dist_rf = {\n",
    "    'n_estimators': [80, 100, 120],\n",
    "    'max_depth': [None, 10, 15],\n",
    "    'min_samples_split': [4, 5, 6],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'bootstrap': [False]\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize RandomizedSearchCV\n",
    "random_search_rf = RandomizedSearchCV(\n",
    "    estimator=RandomForestClassifier(class_weight='balanced', random_state=42),\n",
    "    param_distributions=param_dist_rf,\n",
    "    n_iter=20,  # Number of parameter settings to try\n",
    "    cv=5,  # 5-fold cross-validation\n",
    "    scoring='f1',\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1  # Use all available cores\n",
    ")\n",
    "\n",
    "# Fit the model and check if fit_transform is executed correctly\n",
    "try:\n",
    "    random_search_rf.fit(X_train_tfidf_resampled, y_train_resampled)\n",
    "except ValueError as e:\n",
    "    print(f\"ValueError during model fitting: {e}\")\n",
    "    exit(1)  # Exit if there's an error\n",
    "\n",
    "# Best parameters and model\n",
    "print(\"Best Parameters:\", random_search_rf.best_params_)\n",
    "best_rf_model = random_search_rf.best_estimator_\n",
    "\n",
    "# Predictions on the test set\n",
    "y_pred_rf = best_rf_model.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02957fa0-d837-4565-9879-feb8a62c405d",
   "metadata": {},
   "source": [
    "#### Feature Engineering and Selection\n",
    "##### Enhance your features to potentially improve model performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e22560f-634b-4f3b-90c1-abde13398a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# Define the pipeline with TfidfVectorizer and TruncatedSVD\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer(max_features=1000, stop_words='english')),\n",
    "    ('svd', TruncatedSVD(n_components=300, random_state=42)),  # Reduce to 300 features\n",
    "])\n",
    "\n",
    "# Transform the text data\n",
    "X_train_tfidf = pipeline.fit_transform(X_train)\n",
    "X_test_tfidf = pipeline.transform(X_test)\n",
    "\n",
    "# Use the transformed data for training and evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0433a491-2099-44d2-933c-4301bfa04307",
   "metadata": {},
   "source": [
    "#### Threshold Tuning\n",
    "##### Optimize the decision threshold to balance precision and recall\n",
    "#### Imbalanced Data Handling\n",
    "##### Ensure that your data handling techniques are effective in addressing class imbalance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4cc6202-cbbc-40f8-ae7f-f33557f1fab4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix with best threshold:\n",
      " [[3179  206]\n",
      " [ 265  793]]\n",
      "Classification Report with best threshold:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.94      0.93      3385\n",
      "           1       0.79      0.75      0.77      1058\n",
      "\n",
      "    accuracy                           0.89      4443\n",
      "   macro avg       0.86      0.84      0.85      4443\n",
      "weighted avg       0.89      0.89      0.89      4443\n",
      "\n",
      "Best Threshold: 0.5573443223443223\n"
     ]
    }
   ],
   "source": [
    "# Drop any rows with missing 'cleaned_comment' or 'hate_speech'\n",
    "df = df.dropna(subset=['cleaned_comment', 'hate_speech'])\n",
    "\n",
    "# Split the dataset into features and labels\n",
    "X = df['cleaned_comment'].values\n",
    "y = df['hate_speech'].values\n",
    "\n",
    "# Split into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Feature extraction using TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features=1000, stop_words='english')\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Handle class imbalance with SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_tfidf_resampled, y_train_resampled = smote.fit_resample(X_train_tfidf, y_train)\n",
    "\n",
    "# Define and train the Random Forest model\n",
    "rf_model = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "rf_model.fit(X_train_tfidf_resampled, y_train_resampled)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_proba_rf = rf_model.predict_proba(X_test_tfidf)[:, 1]\n",
    "\n",
    "# Calculate precision-recall pairs\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_proba_rf)\n",
    "\n",
    "# Find the threshold with the best trade-off\n",
    "f1_scores = 2 * (precision * recall) / (precision + recall)\n",
    "best_threshold_index = np.argmax(f1_scores)\n",
    "best_threshold = thresholds[best_threshold_index]\n",
    "\n",
    "# Apply the best threshold\n",
    "y_pred_best_threshold = (y_proba_rf >= best_threshold).astype(int)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix with best threshold:\\n\", confusion_matrix(y_test, y_pred_best_threshold))\n",
    "print(\"Classification Report with best threshold:\\n\", classification_report(y_test, y_pred_best_threshold))\n",
    "\n",
    "# Display the best threshold for reference\n",
    "print(\"Best Threshold:\", best_threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0ce428-d0af-4787-994a-9a746c3bb4a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ee19e7-d1c5-419f-95f1-a66dc1fece0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
