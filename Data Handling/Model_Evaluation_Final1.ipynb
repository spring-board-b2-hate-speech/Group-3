{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c6e9dd3-1d28-43c6-9f5f-885c23675899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f567473b-aa8c-48e5-b717-62a3cb8d7c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aman Shekhar Sachan\\AppData\\Local\\Temp\\ipykernel_16768\\1104661963.py:2: DtypeWarning: Columns (300) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  train_df = pd.read_csv('train.csv')\n"
     ]
    }
   ],
   "source": [
    "# Load the train and test CSV files\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# Split the train data into features (X_train) and labels (y_train)\n",
    "X_train = train_df.iloc[:, :-2]  # All columns except the last two (features)\n",
    "y_train = train_df['hate_speech']  # The 'hate_speech' column (labels)\n",
    "\n",
    "# Split the test data into features (X_test) and labels (y_test)\n",
    "X_test = test_df.iloc[:, :-2]  # All columns except the last two (features)\n",
    "y_test = test_df['hate_speech']  # The 'hate_speech' column (labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c27cddc-368c-4076-b14a-e93312d08f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the feature data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54461722-29c8-4da0-a13e-9303d77c9bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
    "    \"Support Vector Machine\": SVC(kernel='linear', random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=5),\n",
    "    \"SGD Classifier\": SGDClassifier(max_iter=1000, random_state=42)\n",
    "}\n",
    "\n",
    "# Store accuracy results\n",
    "results = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc70700e-a881-43d5-9db8-06d6494cb833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model:\n",
      "Accuracy: 0.8125140670717983\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88      3386\n",
      "           1       0.64      0.50      0.56      1057\n",
      "\n",
      "    accuracy                           0.81      4443\n",
      "   macro avg       0.74      0.70      0.72      4443\n",
      "weighted avg       0.80      0.81      0.80      4443\n",
      "\n",
      "--------------------------------------------------\n",
      "Logistic Regression Model:\n",
      "Accuracy: 0.7996848975917173\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.82      0.86      3386\n",
      "           1       0.56      0.74      0.64      1057\n",
      "\n",
      "    accuracy                           0.80      4443\n",
      "   macro avg       0.74      0.78      0.75      4443\n",
      "weighted avg       0.83      0.80      0.81      4443\n",
      "\n",
      "--------------------------------------------------\n",
      "Support Vector Machine Model:\n",
      "Accuracy: 0.8035111411208643\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.82      0.86      3386\n",
      "           1       0.57      0.74      0.64      1057\n",
      "\n",
      "    accuracy                           0.80      4443\n",
      "   macro avg       0.74      0.78      0.75      4443\n",
      "weighted avg       0.83      0.80      0.81      4443\n",
      "\n",
      "--------------------------------------------------\n",
      "Gradient Boosting Model:\n",
      "Accuracy: 0.7990096781453973\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.83      0.86      3386\n",
      "           1       0.56      0.72      0.63      1057\n",
      "\n",
      "    accuracy                           0.80      4443\n",
      "   macro avg       0.73      0.77      0.75      4443\n",
      "weighted avg       0.82      0.80      0.81      4443\n",
      "\n",
      "--------------------------------------------------\n",
      "K-Nearest Neighbors Model:\n",
      "Accuracy: 0.46207517443169027\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.33      0.48      3386\n",
      "           1       0.29      0.90      0.44      1057\n",
      "\n",
      "    accuracy                           0.46      4443\n",
      "   macro avg       0.60      0.61      0.46      4443\n",
      "weighted avg       0.77      0.46      0.47      4443\n",
      "\n",
      "--------------------------------------------------\n",
      "SGD Classifier Model:\n",
      "Accuracy: 0.6948008102633356\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.67      0.77      3386\n",
      "           1       0.42      0.78      0.55      1057\n",
      "\n",
      "    accuracy                           0.69      4443\n",
      "   macro avg       0.66      0.72      0.66      4443\n",
      "weighted avg       0.79      0.69      0.72      4443\n",
      "\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Apply each model\n",
    "for model_name, model in models.items():\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    # Store the results\n",
    "    results[model_name] = {\n",
    "        'accuracy': accuracy,\n",
    "        'classification_report': report\n",
    "    }\n",
    "    \n",
    "    # Print the results for each model\n",
    "    print(f'{model_name} Model:')\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print('Classification Report:')\n",
    "    print(report)\n",
    "    print('--------------------------------------------------')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1947069b-2cef-494c-b317-7ceb63247dd6",
   "metadata": {},
   "source": [
    "### Adding Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "380a1373-80df-4cd5-9c7f-f4c3a3393c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a494b3c2-af66-47ba-8ea7-e18157eb94b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"Random Forest\": {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'max_depth': [None, 10, 20, 30],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    },\n",
    "    \"Logistic Regression\": {\n",
    "        'C': [0.01, 0.1, 1, 10, 100],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear']\n",
    "    },\n",
    "    \"Support Vector Machine\": {\n",
    "        'C': [100],\n",
    "        'kernel': ['rbf'],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    },\n",
    "    \"Gradient Boosting\": {\n",
    "        'n_estimators': [50, 100, 200],\n",
    "        'learning_rate': [0.01, 0.1, 0.5],\n",
    "        'max_depth': [3, 5, 7]\n",
    "    },\n",
    "    \"K-Nearest Neighbors\": {\n",
    "        'n_neighbors': [3, 5, 7, 10],\n",
    "        'weights': ['uniform', 'distance'],\n",
    "        'metric': ['euclidean', 'manhattan']\n",
    "    },\n",
    "    \"SGD Classifier\": {\n",
    "        'loss': ['hinge', 'log', 'perceptron'],\n",
    "        'alpha': [0.0001, 0.001, 0.01, 0.1],\n",
    "        'penalty': ['l2', 'l1', 'elasticnet'],\n",
    "        'max_iter': [1000, 2000]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32fa88e2-72cf-4347-92f7-ff0193a37069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning Random Forest...\n",
      "Random Forest best parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Random Forest accuracy: 0.8177\n",
      "Random Forest classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.88      3386\n",
      "           1       0.65      0.51      0.57      1057\n",
      "\n",
      "    accuracy                           0.82      4443\n",
      "   macro avg       0.75      0.71      0.73      4443\n",
      "weighted avg       0.81      0.82      0.81      4443\n",
      "\n",
      "Tuning Logistic Regression...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aman Shekhar Sachan\\AppData\\Roaming\\Python\\Python311\\site-packages\\joblib\\externals\\loky\\process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression best parameters: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Logistic Regression accuracy: 0.7997\n",
      "Logistic Regression classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.82      0.86      3386\n",
      "           1       0.56      0.74      0.64      1057\n",
      "\n",
      "    accuracy                           0.80      4443\n",
      "   macro avg       0.74      0.78      0.75      4443\n",
      "weighted avg       0.83      0.80      0.81      4443\n",
      "\n",
      "Tuning Support Vector Machine...\n",
      "Support Vector Machine best parameters: {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Support Vector Machine accuracy: 0.8296\n",
      "Support Vector Machine classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89      3386\n",
      "           1       0.66      0.60      0.62      1057\n",
      "\n",
      "    accuracy                           0.83      4443\n",
      "   macro avg       0.77      0.75      0.76      4443\n",
      "weighted avg       0.82      0.83      0.83      4443\n",
      "\n",
      "Tuning Gradient Boosting...\n",
      "Gradient Boosting best parameters: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200}\n",
      "Gradient Boosting accuracy: 0.8431\n",
      "Gradient Boosting classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.90      3386\n",
      "           1       0.68      0.65      0.66      1057\n",
      "\n",
      "    accuracy                           0.84      4443\n",
      "   macro avg       0.78      0.78      0.78      4443\n",
      "weighted avg       0.84      0.84      0.84      4443\n",
      "\n",
      "Tuning K-Nearest Neighbors...\n",
      "K-Nearest Neighbors best parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "K-Nearest Neighbors accuracy: 0.4990\n",
      "K-Nearest Neighbors classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.38      0.54      3386\n",
      "           1       0.31      0.87      0.45      1057\n",
      "\n",
      "    accuracy                           0.50      4443\n",
      "   macro avg       0.60      0.63      0.50      4443\n",
      "weighted avg       0.76      0.50      0.52      4443\n",
      "\n",
      "Tuning SGD Classifier...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aman Shekhar Sachan\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py:540: FitFailedWarning: \n",
      "120 fits failed out of a total of 360.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "47 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Aman Shekhar Sachan\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Aman Shekhar Sachan\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Aman Shekhar Sachan\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Aman Shekhar Sachan\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'perceptron', 'hinge', 'modified_huber', 'squared_error', 'huber', 'squared_epsilon_insensitive', 'log_loss', 'squared_hinge', 'epsilon_insensitive'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "46 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Aman Shekhar Sachan\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Aman Shekhar Sachan\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Aman Shekhar Sachan\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Aman Shekhar Sachan\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_error', 'epsilon_insensitive', 'squared_hinge', 'hinge', 'squared_epsilon_insensitive', 'log_loss', 'modified_huber', 'perceptron', 'huber'}. Got 'log' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "27 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Aman Shekhar Sachan\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_validation.py\", line 888, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\Aman Shekhar Sachan\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py\", line 1466, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\Aman Shekhar Sachan\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py\", line 666, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\Aman Shekhar Sachan\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'loss' parameter of SGDClassifier must be a str among {'squared_epsilon_insensitive', 'log_loss', 'huber', 'squared_hinge', 'squared_error', 'perceptron', 'hinge', 'epsilon_insensitive', 'modified_huber'}. Got 'log' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\Aman Shekhar Sachan\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\model_selection\\_search.py:1102: UserWarning: One or more of the test scores are non-finite: [0.71530452 0.72427687 0.71571035 0.71530452 0.72427687 0.71571035\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.67198518 0.6714311  0.68007268 0.67198518 0.6714311  0.68007268\n",
      " 0.74414628 0.74082221 0.74159791 0.74414628 0.74082221 0.74159791\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.6596125  0.66234539 0.66803305 0.6596125  0.66234539 0.66803305\n",
      " 0.74927908 0.71508124 0.74565967 0.74927908 0.71508124 0.74565967\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.65987095 0.63457126 0.65669579 0.65987095 0.63457126 0.65669579\n",
      " 0.73398964 0.61071615 0.70045667 0.73398964 0.61071615 0.70045667\n",
      "        nan        nan        nan        nan        nan        nan\n",
      " 0.65285563 0.54734995 0.61865886 0.65285563 0.54734995 0.61865886]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Classifier best parameters: {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l2'}\n",
      "SGD Classifier accuracy: 0.8087\n",
      "SGD Classifier classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87      3386\n",
      "           1       0.58      0.73      0.65      1057\n",
      "\n",
      "    accuracy                           0.81      4443\n",
      "   macro avg       0.74      0.78      0.76      4443\n",
      "weighted avg       0.83      0.81      0.82      4443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuned_results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Tuning {model_name}...\")\n",
    "    param_grid_model = param_grid[model_name]\n",
    "    \n",
    "    grid_search = GridSearchCV(estimator=model, param_grid=param_grid_model, scoring='accuracy', cv=5, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Get the best estimator\n",
    "    best_model = grid_search.best_estimator_\n",
    "    \n",
    "    # Predict on the test set\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Get classification report\n",
    "    class_report = classification_report(y_test, y_pred)\n",
    "    \n",
    "    # Store the result\n",
    "    tuned_results[model_name] = {\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'accuracy': accuracy,\n",
    "        'classification_report': class_report\n",
    "    }\n",
    "    \n",
    "    print(f\"{model_name} best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"{model_name} accuracy: {accuracy:.4f}\")\n",
    "    print(f\"{model_name} classification report:\\n{class_report}\")\n",
    "\n",
    "# Store the tuned results for further analysis\n",
    "results = tuned_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64b6d78b-32b4-4fb8-89ee-6be8ecd285e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Random Forest\n",
      "Best Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Accuracy: 0.8177\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.88      3386\n",
      "           1       0.65      0.51      0.57      1057\n",
      "\n",
      "    accuracy                           0.82      4443\n",
      "   macro avg       0.75      0.71      0.73      4443\n",
      "weighted avg       0.81      0.82      0.81      4443\n",
      "\n",
      "\n",
      "Model: Logistic Regression\n",
      "Best Parameters: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Accuracy: 0.7997\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.82      0.86      3386\n",
      "           1       0.56      0.74      0.64      1057\n",
      "\n",
      "    accuracy                           0.80      4443\n",
      "   macro avg       0.74      0.78      0.75      4443\n",
      "weighted avg       0.83      0.80      0.81      4443\n",
      "\n",
      "\n",
      "Model: Support Vector Machine\n",
      "Best Parameters: {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Accuracy: 0.8296\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89      3386\n",
      "           1       0.66      0.60      0.62      1057\n",
      "\n",
      "    accuracy                           0.83      4443\n",
      "   macro avg       0.77      0.75      0.76      4443\n",
      "weighted avg       0.82      0.83      0.83      4443\n",
      "\n",
      "\n",
      "Model: Gradient Boosting\n",
      "Best Parameters: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200}\n",
      "Accuracy: 0.8431\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.90      3386\n",
      "           1       0.68      0.65      0.66      1057\n",
      "\n",
      "    accuracy                           0.84      4443\n",
      "   macro avg       0.78      0.78      0.78      4443\n",
      "weighted avg       0.84      0.84      0.84      4443\n",
      "\n",
      "\n",
      "Model: K-Nearest Neighbors\n",
      "Best Parameters: {'metric': 'manhattan', 'n_neighbors': 3, 'weights': 'distance'}\n",
      "Accuracy: 0.4990\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.38      0.54      3386\n",
      "           1       0.31      0.87      0.45      1057\n",
      "\n",
      "    accuracy                           0.50      4443\n",
      "   macro avg       0.60      0.63      0.50      4443\n",
      "weighted avg       0.76      0.50      0.52      4443\n",
      "\n",
      "\n",
      "Model: SGD Classifier\n",
      "Best Parameters: {'alpha': 0.01, 'loss': 'hinge', 'max_iter': 1000, 'penalty': 'l2'}\n",
      "Accuracy: 0.8087\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87      3386\n",
      "           1       0.58      0.73      0.65      1057\n",
      "\n",
      "    accuracy                           0.81      4443\n",
      "   macro avg       0.74      0.78      0.76      4443\n",
      "weighted avg       0.83      0.81      0.82      4443\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model_name, results in tuned_results.items():\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Best Parameters: {results['best_params']}\")\n",
    "    print(f\"Accuracy: {results['accuracy']:.4f}\")\n",
    "    print(f\"Classification Report:\\n{results['classification_report']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7052efc-a2d4-4133-b08f-1df24b9a05d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
