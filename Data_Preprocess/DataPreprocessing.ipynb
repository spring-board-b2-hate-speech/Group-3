{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b557e9a5",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7005d7a9",
   "metadata": {},
   "source": [
    "## Installing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32b07a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stop_words in c:\\users\\aman shekhar sachan\\appdata\\roaming\\python\\python311\\site-packages (2018.7.23)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ec0ea9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: autocorrect in c:\\users\\aman shekhar sachan\\anaconda3\\lib\\site-packages (2.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install autocorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5aef525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspellchecker in c:\\users\\aman shekhar sachan\\anaconda3\\lib\\site-packages (0.8.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyspellchecker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a7206b",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fd1f3bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Aman Shekhar\n",
      "[nltk_data]     Sachan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Aman Shekhar\n",
      "[nltk_data]     Sachan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "from stop_words import get_stop_words\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer(language='english')\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from autocorrect import Speller"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb4b83d",
   "metadata": {},
   "source": [
    "## Analyze the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf5d52ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Original_Reddit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f185787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>hate_speech_idx</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. e8q18lf\\n2. \\te8q9w5s\\n3. \\t\\te8qbobk\\n4. \\...</td>\n",
       "      <td>1. A subsection of retarded Hungarians? Ohh bo...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[\"I don't see a reason why it's okay to insult...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1. e9c6naz\\n2. \\te9d03a5\\n3. \\t\\te9d8e4d\\n</td>\n",
       "      <td>1. &gt; \"y'all hear sumn?\"  by all means I live i...</td>\n",
       "      <td>[3]</td>\n",
       "      <td>['Persons with disabilities is the accepted te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1. e84rl2i\\n2. \\te84w60l\\n3. \\t\\te8544rn\\n4. \\...</td>\n",
       "      <td>1. wouldn't the defenders or whatever they are...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1. e7kq72n\\n2. \\te7m24ar\\n</td>\n",
       "      <td>1. Because the Japanese aren't retarded and kn...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[\"It's not right for anyone of any gender to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1. e7hdgoh\\n2. \\te7iyj6a\\n3. \\t\\te7j6iho\\n4. \\...</td>\n",
       "      <td>1. That might be true if we didn't have an exa...</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>[\"You shouldn't be bringing up sensitive topic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  \\\n",
       "0  1. e8q18lf\\n2. \\te8q9w5s\\n3. \\t\\te8qbobk\\n4. \\...   \n",
       "1         1. e9c6naz\\n2. \\te9d03a5\\n3. \\t\\te9d8e4d\\n   \n",
       "2  1. e84rl2i\\n2. \\te84w60l\\n3. \\t\\te8544rn\\n4. \\...   \n",
       "3                         1. e7kq72n\\n2. \\te7m24ar\\n   \n",
       "4  1. e7hdgoh\\n2. \\te7iyj6a\\n3. \\t\\te7j6iho\\n4. \\...   \n",
       "\n",
       "                                                text hate_speech_idx  \\\n",
       "0  1. A subsection of retarded Hungarians? Ohh bo...             [1]   \n",
       "1  1. > \"y'all hear sumn?\"  by all means I live i...             [3]   \n",
       "2  1. wouldn't the defenders or whatever they are...             NaN   \n",
       "3  1. Because the Japanese aren't retarded and kn...             [1]   \n",
       "4  1. That might be true if we didn't have an exa...          [2, 3]   \n",
       "\n",
       "                                            response  \n",
       "0  [\"I don't see a reason why it's okay to insult...  \n",
       "1  ['Persons with disabilities is the accepted te...  \n",
       "2                                                NaN  \n",
       "3  [\"It's not right for anyone of any gender to b...  \n",
       "4  [\"You shouldn't be bringing up sensitive topic...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "83fb19ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5020 entries, 0 to 5019\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   id               5020 non-null   object\n",
      " 1   text             5020 non-null   object\n",
      " 2   hate_speech_idx  3847 non-null   object\n",
      " 3   response         3847 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 157.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dc79f7",
   "metadata": {},
   "source": [
    "### Each row of text contains more than 1 comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9d822a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Grammatical errors, overt racism, child prostitution.. It would appear we have a despicable moron on our hands. \\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c460049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. > \"y\\'all hear sumn?\"  by all means I live in a small town rn (for work). 5k people here, originally a mining community. No one is protesting here. Nobody mentioned the protest today. Nobody here cares, they\\'re busy loving their family and working hard.  Thank god for the electoral college. Liberals think we don\\'t matter. \\n2. \\t[removed]\\n3. \\t\\tah a liberal has slipped in. you can tell because the first question asked was loaded and retarded.  >  What does \"working hard\" mean? Your political views get more validated by how much manual labour you put in?   where did I say that? and yes, of course you have no clue what \"working hard\" means. Few soyboys do.  > Based on your comment regarding the EC I guess you don\\'t really think that 2 mil majority of people who voted for Hillary don\\'t really matter.  I shouldn\\'t have to explain to you the point of the EC. If you want to talk to someone who is more patient with you than I am, you can check out AskThe_Donald. \\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d2e43c",
   "metadata": {},
   "source": [
    "### The corresponding hate speech index determines which comments are categorized as hate speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec9dee9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hate_speech_idx'][17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b2c2f93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[3]'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hate_speech_idx'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157fdd9d",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "472abd97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                   5020\n",
       "unique                  5002\n",
       "top       1. What a cunt. \\n\n",
       "freq                       4\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a991594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     3847\n",
       "unique     316\n",
       "top        [1]\n",
       "freq      1740\n",
       "Name: hate_speech_idx, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hate_speech_idx'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e866bcd",
   "metadata": {},
   "source": [
    "## Restructuring the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5999637e",
   "metadata": {},
   "source": [
    "### Restructuring the dataset to have individual rows for each comment from a post, tagging them with a 1 if they contain hate speech and 0 if not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53d344a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing complete. New CSV file saved.\n"
     ]
    }
   ],
   "source": [
    "# Function to split comments and mark hate speech\n",
    "def process_comments(row):\n",
    "    # Using regex to find the pattern \"index. comment\"\n",
    "    pattern = re.compile(r'(\\d+)\\.\\s(.*?)(?=\\d+\\.\\s|$)', re.DOTALL)\n",
    "    matches = pattern.findall(row['text'])\n",
    "    \n",
    "    # Clean and split the hate_speech_idx column\n",
    "    hate_indices = list(map(int, re.sub(r'[^0-9,]', '', row['hate_speech_idx']).split(','))) if pd.notna(row['hate_speech_idx']) else []\n",
    "    \n",
    "    processed_data = []\n",
    "    \n",
    "    for index, comment in matches:\n",
    "        index = int(index)\n",
    "        comment = comment.strip()\n",
    "        is_hate_speech = 1 if index in hate_indices else 0\n",
    "        processed_data.append([index, comment, is_hate_speech])\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "processed_comments = df.apply(process_comments, axis=1)\n",
    "processed_comments = [item for sublist in processed_comments for item in sublist]\n",
    "new_df = pd.DataFrame(processed_comments, columns=['index','comment', 'hate_speech'])\n",
    "\n",
    "new_df.to_csv('Restructure_Reddit.csv', index=False)\n",
    "print(\"Processing complete. New CSV file saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffae5dd",
   "metadata": {},
   "source": [
    "## Import Processed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2c93f0e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names: Index(['index', 'comment', 'hate_speech'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Restructure_Reddit.csv')\n",
    "print(\"Column names:\", df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32e1ff22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>comment</th>\n",
       "      <th>hate_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A subsection of retarded Hungarians? Ohh boy. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Hiii. Just got off work. 444 is mainly the typ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>wow i guess soyboys are the same in every country</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Owen Benjamin's soyboy song goes for every cou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>&gt; \"y'all hear sumn?\"  by all means I live in a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                            comment  hate_speech\n",
       "0      1  A subsection of retarded Hungarians? Ohh boy. ...            1\n",
       "1      2  Hiii. Just got off work. 444 is mainly the typ...            0\n",
       "2      3  wow i guess soyboys are the same in every country            0\n",
       "3      4  Owen Benjamin's soyboy song goes for every cou...            0\n",
       "4      1  > \"y'all hear sumn?\"  by all means I live in a...            0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "205144d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54df9a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>hate_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A subsection of retarded Hungarians? Ohh boy. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hiii. Just got off work. 444 is mainly the typ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wow i guess soyboys are the same in every country</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Owen Benjamin's soyboy song goes for every cou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&gt; \"y'all hear sumn?\"  by all means I live in a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  hate_speech\n",
       "0  A subsection of retarded Hungarians? Ohh boy. ...            1\n",
       "1  Hiii. Just got off work. 444 is mainly the typ...            0\n",
       "2  wow i guess soyboys are the same in every country            0\n",
       "3  Owen Benjamin's soyboy song goes for every cou...            0\n",
       "4  > \"y'all hear sumn?\"  by all means I live in a...            0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b11f2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22841 entries, 0 to 22840\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   comment      22757 non-null  object\n",
      " 1   hate_speech  22841 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 357.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78ecfcbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hate_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22841.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.231864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.422032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        hate_speech\n",
       "count  22841.000000\n",
       "mean       0.231864\n",
       "std        0.422032\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000000\n",
       "75%        0.000000\n",
       "max        1.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "550c485a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeAAAAHACAYAAAB6eLujAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAAAz6UlEQVR4nO3deVhWdf7/8deNxqIBigvLhEqaqIm4TEM4aZqMqIwTM06LWlqSZmGmlDLMmKFOg2lkNZVOMxn1yyZ1Jm1cxkRyySBTDFFLxwV1Sm6cUrjDBVnu3x99OeM9uBChH5bn47rOdXE+n/d9zvtQ+LrOue9zbpvT6XQKAABcU26mGwAAoDEigAEAMIAABgDAAAIYAAADCGAAAAwggAEAMIAABgDAAAIYAAADmppuoKGoqKjQ8ePH5e3tLZvNZrodAIAhTqdT3377rYKCguTmdunzXAK4lhw/flzBwcGm2wAA1BH//ve/dcMNN1xyngCuJd7e3pK++4X7+PgY7gYAYIrD4VBwcLCVC5dCANeSysvOPj4+BDAA4IpvR/IhLAAADCCAAQAwgAAGAMAAAhgAAAMIYAAADCCAcdVt2bJFw4cPV1BQkGw2m1auXOkyb7PZLrrMnz/fqunQoUOV+blz5150fwcPHpS3t7datGjhMp6WllZlG56enrV9uABQLdyGhKvu9OnTCg8P17hx4/SrX/2qynx+fr7L+j//+U/FxcVpxIgRLuOzZ8/W+PHjrfWL3WNXWlqqkSNHql+/fsrMzKwy7+Pjo/3791vrPLUMgCkEMK66oUOHaujQoZecDwgIcFl///33NXDgQN14440u497e3lVq/9eMGTPUpUsXDRo06KIBbLPZrrgNALgWuASNOqWgoEBr1qxRXFxclbm5c+eqVatW6tWrl+bPn6+ysjKX+Q8//FDLly/XK6+8csntFxcXq3379goODtadd96pvXv31voxAEB1cAaMOuXNN9+Ut7d3lUvVkydPVu/eveXn56fMzEwlJSUpPz9fzz//vCTpm2++0QMPPKC33377kk8iCw0N1eLFi9WjRw8VFRXpueeeU9++fbV3797LPq8VAK4GAhh1yuLFizV69OgqH45KSEiwfu7Ro4fc3d318MMPKyUlRR4eHho/frxGjRql/v37X3LbkZGRioyMtNb79u2rrl276k9/+pPmzJlT+wcDAJfBJWjUGR999JH279+vhx566Iq1ERERKisr05EjRyR9d/n5ueeeU9OmTdW0aVPFxcWpqKhITZs21eLFiy+6jeuuu069evXSwYMHa/MwAKBajAbwtbo9JTc3V/369ZOnp6eCg4M1b968Kr0sX75cXbp0kaenp8LCwrR27dqrcsy4tNdff119+vRReHj4FWtzcnLk5uamtm3bSpKysrKUk5NjLbNnz5a3t7dycnL0y1/+8qLbKC8v1+7duxUYGFirxwEA1WH0EvS1uD3F4XBo8ODBioqK0qJFi7R7926NGzdOLVq00IQJEyRJmZmZGjlypFJSUvTzn/9c77zzjmJjY7Vz50517969Ng+5USouLnY5y8zLy1NOTo78/PzUrl07Sd/9d1q+fLlSU1OrvD4rK0vbtm3TwIED5e3traysLE2dOlX33XefWrZsKUnq2rWry2t27NghNzc3l/9+s2fP1q233qpOnTqpsLBQ8+fP19GjR6t1xg0Atc5ZR0hyrlix4rI1d955p/OOO+5wGWvfvr1zwYIFl3zNq6++6mzZsqWzpKTEGktMTHSGhoZa63fffbczJibG5XURERHOhx9+uNr9FxUVOSU5i4qKqv2axmLjxo1OSVWWsWPHWjV/+tOfnF5eXs7CwsIqr8/OznZGREQ4fX19nZ6ens6uXbs6//CHPzjPnTt3yX2+8cYbTl9fX5exKVOmONu1a+d0d3d3+vv7O4cNG+bcuXNnbR0mADidzurngc3pdDrNxf9/2Ww2rVixQrGxsRedLygo0A033KA333xTo0aNssY7dOigc+fOqbS0VO3atdOoUaM0depUNW363cn9mDFj5HA4XC5vb9y4UXfccYdOnjypli1bql27dkpISNCUKVOsmqefflorV67Url27LtpPSUmJSkpKrPXKL2AuKiqqte8D7jPtrVrZDnAl2fPHmG4BaDAcDod8fX2vmAf15lPQNb09xW63KyQkxOU1/v7+1lzLli1lt9utsQtr7Hb7JftJSUnRrFmzauPQAACNUL0J4JrennK1JCUluey78gwYAIDqqBcBXHl7ytKlS69Ye+HtKaGhoQoICFBBQYFLTeV65SMJL1VzuUcWenh4XNWABwA0bPXiPuAfcntKZGSktmzZotLSUqsmPT1doaGh1idoIyMjlZGR4bKd9PR0l4c2AABQm4wGcHFxsXXfpvTf21OOHTtm1VTennKxW0WysrL0wgsvaNeuXTp8+LCWLFlS5faUUaNGyd3dXXFxcdq7d6+WLl2qF1980eXy8eOPP65169YpNTVV+/btU3Jysnbs2KFJkyZd3V8AAKDRMnoJeseOHRo4cKC1XhmKY8eOVVpamiTp3XffldPp1MiRI6u83sPDQ++++66Sk5NVUlKikJAQTZ061SVcfX19tX79esXHx6tPnz5q3bq1Zs6cad0DLH33SMJ33nlHM2bM0G9/+1vddNNNWrlyJfcAAwCumjpzG1J9V92PnX8f3IaEa4XbkIDaU908qBfvAQMA0NAQwAAAGEAAAwBgAAEMAIABBDAAAAYQwAAAGEAAAwBgAAEMAIABBDAAAAYQwAAAGEAAAwBgAAEMAIABBDAAAAYQwAAAGEAAAwBgAAEMAIABBDAAAAYQwAAAGEAAAwBgAAEMAIABBDAAAAYQwAAAGEAAAwBgAAEMAIABBDAAAAYQwAAAGEAAAwBgAAEMAIABBDAAAAYQwAAAGEAAAwBgAAEMAIABBDAAAAYQwAAAGEAAAwBgAAEMAIABBDAAAAYQwAAAGEAAAwBgAAEMAIABBDAAAAYYDeAtW7Zo+PDhCgoKks1m08qVK13mH3jgAdlsNpdlyJAhLjUnT57U6NGj5ePjoxYtWiguLk7FxcUuNbm5uerXr588PT0VHBysefPmVell+fLl6tKlizw9PRUWFqa1a9fW+vECAFDJaACfPn1a4eHheuWVVy5ZM2TIEOXn51vLX//6V5f50aNHa+/evUpPT9fq1au1ZcsWTZgwwZp3OBwaPHiw2rdvr+zsbM2fP1/Jycl67bXXrJrMzEyNHDlScXFx+uyzzxQbG6vY2Fjt2bOn9g8aAABJNqfT6TTdhCTZbDatWLFCsbGx1tgDDzygwsLCKmfGlb744gt169ZN27dv149//GNJ0rp16zRs2DB9+eWXCgoK0sKFC/W73/1Odrtd7u7ukqTf/OY3Wrlypfbt2ydJuueee3T69GmtXr3a2vatt96qnj17atGiRdXq3+FwyNfXV0VFRfLx8anBb6CqPtPeqpXtAFeSPX+M6RaABqO6eVDn3wPetGmT2rZtq9DQUD3yyCP65ptvrLmsrCy1aNHCCl9JioqKkpubm7Zt22bV9O/f3wpfSYqOjtb+/ft16tQpqyYqKsplv9HR0crKyrpkXyUlJXI4HC4LAADVVacDeMiQIXrrrbeUkZGhZ599Vps3b9bQoUNVXl4uSbLb7Wrbtq3La5o2bSo/Pz/Z7Xarxt/f36Wmcv1KNZXzF5OSkiJfX19rCQ4O/mEHCwBoVJqabuBy7r33XuvnsLAw9ejRQx07dtSmTZs0aNAgg51JSUlJSkhIsNYdDgchDACotjp9Bvy/brzxRrVu3VoHDx6UJAUEBOjEiRMuNWVlZTp58qQCAgKsmoKCApeayvUr1VTOX4yHh4d8fHxcFgAAqqteBfCXX36pb775RoGBgZKkyMhIFRYWKjs726r58MMPVVFRoYiICKtmy5YtKi0ttWrS09MVGhqqli1bWjUZGRku+0pPT1dkZOTVPiQAQCNlNICLi4uVk5OjnJwcSVJeXp5ycnJ07NgxFRcXa9q0afrkk0905MgRZWRk6M4771SnTp0UHR0tSeratauGDBmi8ePH69NPP9XHH3+sSZMm6d5771VQUJAkadSoUXJ3d1dcXJz27t2rpUuX6sUXX3S5fPz4449r3bp1Sk1N1b59+5ScnKwdO3Zo0qRJ1/x3AgBoHIwG8I4dO9SrVy/16tVLkpSQkKBevXpp5syZatKkiXJzc/WLX/xCnTt3VlxcnPr06aOPPvpIHh4e1jaWLFmiLl26aNCgQRo2bJhuu+02l3t8fX19tX79euXl5alPnz564oknNHPmTJd7hfv27at33nlHr732msLDw/W3v/1NK1euVPfu3a/dLwMA0KjUmfuA6zvuA0Z9xn3AQO1pMPcBAwDQEBHAAAAYQAADAGAAAQwAgAEEMAAABhDAAAAYQAADAGAAAQwAgAEEMAAABhDAAAAYQAADAGAAAQwAgAEEMAAABhDAAAAYQAADAGAAAQwAgAEEMAAABhDAAAAYQAADAGAAAQwAgAEEMAAABhDAAAAYQAADAGAAAQwAgAEEMAAABhDAAAAYQAADAGAAAQwAgAEEMAAABhDAAAAYQAADAGAAAQwAgAEEMAAABhDAAAAYQAADAGAAAQwAgAEEMAAABhDAAAAYQAADAGAAAQwAgAEEMAAABhgN4C1btmj48OEKCgqSzWbTypUrrbnS0lIlJiYqLCxMzZs3V1BQkMaMGaPjx4+7bKNDhw6y2Wwuy9y5c11qcnNz1a9fP3l6eio4OFjz5s2r0svy5cvVpUsXeXp6KiwsTGvXrr0qxwwAgGQ4gE+fPq3w8HC98sorVebOnDmjnTt36qmnntLOnTv13nvvaf/+/frFL35RpXb27NnKz8+3lscee8yaczgcGjx4sNq3b6/s7GzNnz9fycnJeu2116yazMxMjRw5UnFxcfrss88UGxur2NhY7dmz5+ocOACg0WtqcudDhw7V0KFDLzrn6+ur9PR0l7GXX35ZP/nJT3Ts2DG1a9fOGvf29lZAQMBFt7NkyRKdP39eixcvlru7u26++Wbl5OTo+eef14QJEyRJL774ooYMGaJp06ZJkubMmaP09HS9/PLLWrRoUW0cKgAALurVe8BFRUWy2Wxq0aKFy/jcuXPVqlUr9erVS/Pnz1dZWZk1l5WVpf79+8vd3d0ai46O1v79+3Xq1CmrJioqymWb0dHRysrKumQvJSUlcjgcLgsAANVl9Az4+zh37pwSExM1cuRI+fj4WOOTJ09W79695efnp8zMTCUlJSk/P1/PP/+8JMlutyskJMRlW/7+/tZcy5YtZbfbrbELa+x2+yX7SUlJ0axZs2rr8AAAjUy9CODS0lLdfffdcjqdWrhwoctcQkKC9XOPHj3k7u6uhx9+WCkpKfLw8LhqPSUlJbns2+FwKDg4+KrtDwDQsNT5AK4M36NHj+rDDz90Ofu9mIiICJWVlenIkSMKDQ1VQECACgoKXGoq1yvfN75UzaXeV5YkDw+PqxrwAICGrU6/B1wZvgcOHNCGDRvUqlWrK74mJydHbm5uatu2rSQpMjJSW7ZsUWlpqVWTnp6u0NBQtWzZ0qrJyMhw2U56eroiIyNr8WgAAPgvo2fAxcXFOnjwoLWel5ennJwc+fn5KTAwUL/+9a+1c+dOrV69WuXl5dZ7sn5+fnJ3d1dWVpa2bdumgQMHytvbW1lZWZo6daruu+8+K1xHjRqlWbNmKS4uTomJidqzZ49efPFFLViwwNrv448/rttvv12pqamKiYnRu+++qx07drjcqgQAQG2yOZ1Op6mdb9q0SQMHDqwyPnbsWCUnJ1f58FSljRs3asCAAdq5c6ceffRR7du3TyUlJQoJCdH999+vhIQEl8vDubm5io+P1/bt29W6dWs99thjSkxMdNnm8uXLNWPGDB05ckQ33XST5s2bp2HDhlX7WBwOh3x9fVVUVHTFy+TV1WfaW7WyHeBKsuePMd0C0GBUNw+MBnBDQgCjPiOAgdpT3Tyo0+8BAwDQUBHAAAAYQAADAGAAAQwAgAEEMAAABhDAAAAYQAADAGAAAQwAgAEEMAAABhDAAAAYQAADAGAAAQwAgAEEMAAABhDAAAAYQAADAGAAAQwAgAEEMAAABhDAAAAYQAADAGAAAQwAgAEEMAAABhDAAAAYQAADAGAAAQwAgAEEMAAABhDAAAAYQAADAGAAAQwAgAEEMAAABhDAAAAYQAADAGAAAQwAgAEEMAAABhDAAAAYQAADAGAAAQwAgAEEMAAABhDAAAAYQAADAGAAAQwAgAEEMAAABhDAAAAYYDSAt2zZouHDhysoKEg2m00rV650mXc6nZo5c6YCAwPl5eWlqKgoHThwwKXm5MmTGj16tHx8fNSiRQvFxcWpuLjYpSY3N1f9+vWTp6engoODNW/evCq9LF++XF26dJGnp6fCwsK0du3aWj9eAAAqGQ3g06dPKzw8XK+88spF5+fNm6eXXnpJixYt0rZt29S8eXNFR0fr3LlzVs3o0aO1d+9epaena/Xq1dqyZYsmTJhgzTscDg0ePFjt27dXdna25s+fr+TkZL322mtWTWZmpkaOHKm4uDh99tlnio2NVWxsrPbs2XP1Dh4A0KjZnE6n03QTkmSz2bRixQrFxsZK+u7sNygoSE888YSefPJJSVJRUZH8/f2Vlpame++9V1988YW6deum7du368c//rEkad26dRo2bJi+/PJLBQUFaeHChfrd734nu90ud3d3SdJvfvMbrVy5Uvv27ZMk3XPPPTp9+rRWr15t9XPrrbeqZ8+eWrRoUbX6dzgc8vX1VVFRkXx8fGrld9Jn2lu1sh3gSrLnjzHdAtBgVDcPanQGfMcdd6iwsPCiO73jjjtqsskq8vLyZLfbFRUVZY35+voqIiJCWVlZkqSsrCy1aNHCCl9JioqKkpubm7Zt22bV9O/f3wpfSYqOjtb+/ft16tQpq+bC/VTWVO7nYkpKSuRwOFwWAACqq0YBvGnTJp0/f77K+Llz5/TRRx/94KYkyW63S5L8/f1dxv39/a05u92utm3busw3bdpUfn5+LjUX28aF+7hUTeX8xaSkpMjX19dagoODv+8hAgAasabfpzg3N9f6+fPPP3cJqPLycq1bt04/+tGPaq+7OiwpKUkJCQnWusPhIIQBANX2vQK4Z8+estlsstlsF73U7OXlpT/+8Y+10lhAQIAkqaCgQIGBgdZ4QUGBevbsadWcOHHC5XVlZWU6efKk9fqAgAAVFBS41FSuX6mmcv5iPDw85OHhUYMjAwDge16CzsvL06FDh+R0OvXpp58qLy/PWr766is5HA6NGzeuVhoLCQlRQECAMjIyrDGHw6Ft27YpMjJSkhQZGanCwkJlZ2dbNR9++KEqKioUERFh1WzZskWlpaVWTXp6ukJDQ9WyZUur5sL9VNZU7gcAgNr2vc6A27dvL0mqqKiolZ0XFxfr4MGD1npeXp5ycnLk5+endu3aacqUKfr973+vm266SSEhIXrqqacUFBRkfVK6a9euGjJkiMaPH69FixaptLRUkyZN0r333qugoCBJ0qhRozRr1izFxcUpMTFRe/bs0YsvvqgFCxZY+3388cd1++23KzU1VTExMXr33Xe1Y8cOl1uVAACoTd8rgC904MABbdy4USdOnKgSyDNnzqzWNnbs2KGBAwda65XvqY4dO1ZpaWmaPn26Tp8+rQkTJqiwsFC33Xab1q1bJ09PT+s1S5Ys0aRJkzRo0CC5ublpxIgReumll6x5X19frV+/XvHx8erTp49at26tmTNnutwr3LdvX73zzjuaMWOGfvvb3+qmm27SypUr1b179xr9bgAAuJIa3Qf85z//WY888ohat26tgIAA2Wy2/27QZtPOnTtrtcn6gPuAUZ9xHzBQe6qbBzU6A/7973+vZ555RomJiTVuEACAxqxG9wGfOnVKd911V233AgBAo1GjAL7rrru0fv362u4FAIBGo0aXoDt16qSnnnpKn3zyicLCwnTddde5zE+ePLlWmgMAoKGqUQC/9tpruv7667V582Zt3rzZZc5msxHAAABcQY0COC8vr7b7AACgUTH6fcAAADRWNToDvtLjJhcvXlyjZgAAaCxqFMCV36NbqbS0VHv27FFhYWGtfR8wAAANWY0CeMWKFVXGKioq9Mgjj6hjx44/uCkAABq6WnsP2M3NTQkJCS5fcgAAAC6uVj+EdejQIZWVldXmJgEAaJBqdAm68luLKjmdTuXn52vNmjUaO3ZsrTQGAEBDVqMA/uyzz1zW3dzc1KZNG6Wmpl7xE9IAAKCGAbxx48ba7gMAgEalRgFc6T//+Y/2798vSQoNDVWbNm1qpSkAABq6Gn0I6/Tp0xo3bpwCAwPVv39/9e/fX0FBQYqLi9OZM2dqu0cAABqcGgVwQkKCNm/erFWrVqmwsFCFhYV6//33tXnzZj3xxBO13SMAAA1OjS5B//3vf9ff/vY3DRgwwBobNmyYvLy8dPfdd2vhwoW11R8AAA1Sjc6Az5w5I39//yrjbdu25RI0AADVUKMAjoyM1NNPP61z585ZY2fPntWsWbMUGRlZa80BANBQ1egS9AsvvKAhQ4bohhtuUHh4uCRp165d8vDw0Pr162u1QQAAGqIaBXBYWJgOHDigJUuWaN++fZKkkSNHavTo0fLy8qrVBgEAaIhqFMApKSny9/fX+PHjXcYXL16s//znP0pMTKyV5gAAaKhq9B7wn/70J3Xp0qXK+M0336xFixb94KYAAGjoahTAdrtdgYGBVcbbtGmj/Pz8H9wUAAANXY0CODg4WB9//HGV8Y8//lhBQUE/uCkAABq6Gr0HPH78eE2ZMkWlpaW64447JEkZGRmaPn06T8ICAKAaahTA06ZN0zfffKNHH31U58+flyR5enoqMTFRSUlJtdogAAANUY0C2Gaz6dlnn9VTTz2lL774Ql5eXrrpppvk4eFR2/0BANAg/aCvI7z++ut1yy231FYvAAA0GjX6EBYAAPhhCGAAAAwggAEAMIAABgDAAAIYAAADCGAAAAwggAEAMIAABgDAAAIYAAADCGAAAAyo8wHcoUMH2Wy2Kkt8fLwkacCAAVXmJk6c6LKNY8eOKSYmRs2aNVPbtm01bdo0lZWVudRs2rRJvXv3loeHhzp16qS0tLRrdYgAgEboBz0L+lrYvn27ysvLrfU9e/boZz/7me666y5rbPz48Zo9e7a13qxZM+vn8vJyxcTEKCAgQJmZmcrPz9eYMWN03XXX6Q9/+IMkKS8vTzExMZo4caKWLFmijIwMPfTQQwoMDFR0dPQ1OEoAQGNT5wO4TZs2Lutz585Vx44ddfvtt1tjzZo1U0BAwEVfv379en3++efasGGD/P391bNnT82ZM0eJiYlKTk6Wu7u7Fi1apJCQEKWmpkqSunbtqq1bt2rBggUEMADgqqjzl6AvdP78eb399tsaN26cbDabNb5kyRK1bt1a3bt3V1JSks6cOWPNZWVlKSwsTP7+/tZYdHS0HA6H9u7da9VERUW57Cs6OlpZWVmX7KWkpEQOh8NlAQCguur8GfCFVq5cqcLCQj3wwAPW2KhRo9S+fXsFBQUpNzdXiYmJ2r9/v9577z1Jkt1udwlfSda63W6/bI3D4dDZs2fl5eVVpZeUlBTNmjWrNg8PANCI1KsAfv311zV06FAFBQVZYxMmTLB+DgsLU2BgoAYNGqRDhw6pY8eOV62XpKQkJSQkWOsOh0PBwcFXbX8AgIal3gTw0aNHtWHDBuvM9lIiIiIkSQcPHlTHjh0VEBCgTz/91KWmoKBAkqz3jQMCAqyxC2t8fHwuevYrSR4eHvLw8KjRsQAAUG/eA37jjTfUtm1bxcTEXLYuJydHkhQYGChJioyM1O7du3XixAmrJj09XT4+PurWrZtVk5GR4bKd9PR0RUZG1uIRAADwX/UigCsqKvTGG29o7Nixatr0vyfthw4d0pw5c5Sdna0jR47oH//4h8aMGaP+/furR48ekqTBgwerW7duuv/++7Vr1y598MEHmjFjhuLj460z2IkTJ+rw4cOaPn269u3bp1dffVXLli3T1KlTjRwvAKDhqxcBvGHDBh07dkzjxo1zGXd3d9eGDRs0ePBgdenSRU888YRGjBihVatWWTVNmjTR6tWr1aRJE0VGRuq+++7TmDFjXO4bDgkJ0Zo1a5Senq7w8HClpqbqL3/5C7cgAQCuGpvT6XSabqIhcDgc8vX1VVFRkXx8fGplm32mvVUr2wGuJHv+GNMtAA1GdfOgXpwBAwDQ0BDAAAAYQAADAGAAAQwAgAEEMAAABhDAAAAYQAADAGAAAQwAgAEEMAAABhDAAAAYQAADAGAAAQwAgAEEMAAABhDAAAAYQAADAGAAAQwAgAEEMAAABhDAAAAYQAADAGAAAQwAgAEEMAAABhDAAAAYQAADAGAAAQwAgAEEMAAABhDAAAAYQAADAGAAAQwAgAEEMAAABhDAAHCVJScny2azuSxdunSRJJ08eVKPPfaYQkND5eXlpXbt2mny5MkqKipy2UZGRob69u0rb29vBQQEKDExUWVlZS41TqdTzz33nDp37iwPDw/96Ec/0jPPPHPNjhPfT1PTDQBAY3DzzTdrw4YN1nrTpt/983v8+HEdP35czz33nLp166ajR49q4sSJOn78uP72t79Jknbt2qVhw4bpd7/7nd566y199dVXmjhxosrLy/Xcc89Z23z88ce1fv16PffccwoLC9PJkyd18uTJa3ugqDYCGACugaZNmyogIKDKePfu3fX3v//dWu/YsaOeeeYZ3XfffSorK1PTpk21dOlS9ejRQzNnzpQkderUSfPmzdPdd9+tp59+Wt7e3vriiy+0cOFC7dmzR6GhoZKkkJCQa3NwqBEuQQPANXDgwAEFBQXpxhtv1OjRo3Xs2LFL1hYVFcnHx8c6Sy4pKZGnp6dLjZeXl86dO6fs7GxJ0qpVq3TjjTdq9erVCgkJUYcOHfTQQw9xBlyHEcAAcJVFREQoLS1N69at08KFC5WXl6d+/frp22+/rVL79ddfa86cOZowYYI1Fh0drczMTP31r39VeXm5vvrqK82ePVuSlJ+fL0k6fPiwjh49quXLl+utt95SWlqasrOz9etf//raHCS+NwIYAK6yoUOH6q677lKPHj0UHR2ttWvXqrCwUMuWLXOpczgciomJUbdu3ZScnGyNDx48WPPnz9fEiRPl4eGhzp07a9iwYZIkN7fv/hmvqKhQSUmJ3nrrLfXr108DBgzQ66+/ro0bN2r//v3X7FhRfQQwAFxjLVq0UOfOnXXw4EFr7Ntvv9WQIUPk7e2tFStW6LrrrnN5TUJCggoLC3Xs2DF9/fXXuvPOOyVJN954oyQpMDBQTZs2VefOna3XdO3aVZIue7kb5hDAAHCNFRcX69ChQwoMDJT03Znv4MGD5e7urn/84x9V3u+tZLPZFBQUJC8vL/31r39VcHCwevfuLUn66U9/qrKyMh06dMiq/9e//iVJat++/VU+ItQEn4IGgKvsySef1PDhw9W+fXsdP35cTz/9tJo0aaKRI0da4XvmzBm9/fbbcjgccjgckqQ2bdqoSZMmkqT58+dryJAhcnNz03vvvae5c+dq2bJl1nxUVJR69+6tcePG6YUXXlBFRYXi4+P1s5/9zOWsGHUHAQwAV9mXX36pkSNH6ptvvlGbNm1022236ZNPPlGbNm20adMmbdu2TdJ3txddKC8vTx06dJAk/fOf/9QzzzyjkpIShYeH6/3339fQoUOtWjc3N61atUqPPfaY+vfvr+bNm2vo0KFKTU29ZseJ78fmdDqdpptoCBwOh3x9fa3bB2pDn2lv1cp2gCvJnj/GdAsXxd8ArpXa/Buobh7wHjAAAAbU6QC+3PNTJencuXOKj49Xq1atdP3112vEiBEqKChw2caxY8cUExOjZs2aqW3btpo2bVqV56du2rRJvXv3loeHhzp16qS0tLRrcXgAgEasTgew9N3zU/Pz861l69at1tzUqVO1atUqLV++XJs3b9bx48f1q1/9ypovLy9XTEyMzp8/r8zMTL355ptKS0uzHucmffceS0xMjAYOHKicnBxNmTJFDz30kD744INrepwAgMalzn8I61LPTy0qKtLrr7+ud955R3fccYck6Y033lDXrl31ySef6NZbb9X69ev1+eefa8OGDfL391fPnj01Z84cJSYmKjk5We7u7lq0aJFCQkKsDyp07dpVW7du1YIFCxQdHX1NjxUA0HjU+TPgSz0/NTs7W6WlpYqKirJqu3Tponbt2ikrK0uSlJWVpbCwMPn7+1s10dHRcjgc2rt3r1Vz4TYqayq3cSklJSXW7QIX3jYAAEB11OkAvtzzU+12u9zd3dWiRQuX1/j7+8tut0uS7Ha7S/hWzlfOXa7G4XDo7Nmzl+wtJSVFvr6+1hIcHPxDDxcA0IjU6UvQF97j1qNHD0VERKh9+/ZatmyZvLy8DHYmJSUlKSEhwVp3OByEMACg2ur0GfD/uvD5qQEBATp//rwKCwtdagoKCqz3jAMCAqp8Krpy/Uo1Pj4+lw15Dw8P+fj4uCwAAFRXvQrgC5+f2qdPH1133XXKyMiw5vfv369jx44pMjJSkhQZGandu3frxIkTVk16erp8fHzUrVs3q+bCbVTWVG4DAICroU4H8JNPPqnNmzfryJEjyszM1C9/+Uvr+am+vr6Ki4tTQkKCNm7cqOzsbD344IOKjIzUrbfeKum7r/Dq1q2b7r//fu3atUsffPCBZsyYofj4eHl4eEiSJk6cqMOHD2v69Onat2+fXn31VS1btkxTp041eegAgAauTr8HfLnnp0rSggUL5ObmphEjRqikpETR0dF69dVXrdc3adJEq1ev1iOPPKLIyEg1b95cY8eOtb7IWpJCQkK0Zs0aTZ06VS+++KJuuOEG/eUvf+EWJADAVcWzoGsJz4JGfcazoNHY8SxoAAAaCQIYAAADCGAAAAwggAEAMIAABgDAAAIYAAADCGAAAAwggAEAMIAABgDAAAIYAAADCGAAAAwggAEAMIAABgDAAAIYAAADCGAAAAwggAEAMIAABgDAAAIYAAADCGAAAAwggAEAMIAABgDAAAIYAAADCGAAAAwggAEAMIAABgDAAAIYAAADCGAAAAwggAEAMIAABgDAAAIYAAADCGAAAAwggAEAMIAABgDAAAIYAAADCGAAAAwggAEAMIAABgDAAAIYAAADCGAAAAwggAEAMIAABgDAgDodwCkpKbrlllvk7e2ttm3bKjY2Vvv373epGTBggGw2m8syceJEl5pjx44pJiZGzZo1U9u2bTVt2jSVlZW51GzatEm9e/eWh4eHOnXqpLS0tKt9eACARqxOB/DmzZsVHx+vTz75ROnp6SotLdXgwYN1+vRpl7rx48crPz/fWubNm2fNlZeXKyYmRufPn1dmZqbefPNNpaWlaebMmVZNXl6eYmJiNHDgQOXk5GjKlCl66KGH9MEHH1yzYwUANC5NTTdwOevWrXNZT0tLU9u2bZWdna3+/ftb482aNVNAQMBFt7F+/Xp9/vnn2rBhg/z9/dWzZ0/NmTNHiYmJSk5Olru7uxYtWqSQkBClpqZKkrp27aqtW7dqwYIFio6OvnoHCABotOr0GfD/KioqkiT5+fm5jC9ZskStW7dW9+7dlZSUpDNnzlhzWVlZCgsLk7+/vzUWHR0th8OhvXv3WjVRUVEu24yOjlZWVtYleykpKZHD4XBZAACorjp9BnyhiooKTZkyRT/96U/VvXt3a3zUqFFq3769goKClJubq8TERO3fv1/vvfeeJMlut7uEryRr3W63X7bG4XDo7Nmz8vLyqtJPSkqKZs2aVavHCABoPOpNAMfHx2vPnj3aunWry/iECROsn8PCwhQYGKhBgwbp0KFD6tix41XrJykpSQkJCda6w+FQcHDwVdsfAKBhqReXoCdNmqTVq1dr48aNuuGGGy5bGxERIUk6ePCgJCkgIEAFBQUuNZXrle8bX6rGx8fnome/kuTh4SEfHx+XBQCA6qrTAex0OjVp0iStWLFCH374oUJCQq74mpycHElSYGCgJCkyMlK7d+/WiRMnrJr09HT5+PioW7duVk1GRobLdtLT0xUZGVlLRwIAgKs6HcDx8fF6++239c4778jb21t2u112u11nz56VJB06dEhz5sxRdna2jhw5on/84x8aM2aM+vfvrx49ekiSBg8erG7duun+++/Xrl279MEHH2jGjBmKj4+Xh4eHJGnixIk6fPiwpk+frn379unVV1/VsmXLNHXqVGPHDgBo2Op0AC9cuFBFRUUaMGCAAgMDrWXp0qWSJHd3d23YsEGDBw9Wly5d9MQTT2jEiBFatWqVtY0mTZpo9erVatKkiSIjI3XfffdpzJgxmj17tlUTEhKiNWvWKD09XeHh4UpNTdVf/vIXbkECAFw1dfpDWE6n87LzwcHB2rx58xW30759e61du/ayNQMGDNBnn332vfoDAKCm6vQZMAAADRUBDACAAQQwAAAGEMAAABhAAAMAYAABDACAAQQwAAAGEMAAABhAAAMAYAABDACAAQQwAAAGEMAAABhAAAMAYAABDACAAQQwAAAGEMAAABhAAAMAYAABDACAAQQwAAAGEMAAABhAAAMAYAABDACAAQQwAAAGEMAAABhAAAMAYAABDACAAQQwAAAGEMAAABhAAAMAYAABDACAAQQwAAAGEMAAABhAAAMAYAABDACAAQQwAAAGEMAAABhAAAMAYAABDACAAQQwAAAGEMAAABhAAAMAYAABDACAAQTw/3jllVfUoUMHeXp6KiIiQp9++qnplgAADRABfIGlS5cqISFBTz/9tHbu3Knw8HBFR0frxIkTplsDADQwBPAFnn/+eY0fP14PPvigunXrpkWLFqlZs2ZavHix6dYAAA1MU9MN1BXnz59Xdna2kpKSrDE3NzdFRUUpKyurSn1JSYlKSkqs9aKiIkmSw+GotZ7KS87W2raAy6nN/29rE38DuFZq82+gcltOp/OydQTw//n6669VXl4uf39/l3F/f3/t27evSn1KSopmzZpVZTw4OPiq9QhcLb5/nGi6BcCoq/E38O2338rX1/eS8wRwDSUlJSkhIcFar6io0MmTJ9WqVSvZbDaDnTVeDodDwcHB+ve//y0fHx/T7QBG8HdgntPp1LfffqugoKDL1hHA/6d169Zq0qSJCgoKXMYLCgoUEBBQpd7Dw0MeHh4uYy1atLiaLaKafHx8+IcHjR5/B2Zd7sy3Eh/C+j/u7u7q06ePMjIyrLGKigplZGQoMjLSYGcAgIaIM+ALJCQkaOzYsfrxj3+sn/zkJ3rhhRd0+vRpPfjgg6ZbAwA0MATwBe655x795z//0cyZM2W329WzZ0+tW7euygezUDd5eHjo6aefrvLWANCY8HdQf9icV/qcNAAAqHW8BwwAgAEEMAAABhDAAAAYQAADAGAAAYwGg6+SRGO2ZcsWDR8+XEFBQbLZbFq5cqXplnAFBDAaBL5KEo3d6dOnFR4erldeecV0K6gmbkNCgxAREaFbbrlFL7/8sqTvnmIWHBysxx57TL/5zW8MdwdcWzabTStWrFBsbKzpVnAZnAGj3qv8KsmoqChr7HJfJQkAdQEBjHrvcl8labfbDXUFAJdHAAMAYAABjHrv+36VJADUBQQw6j2+ShJAfcS3IaFB4Ksk0dgVFxfr4MGD1npeXp5ycnLk5+endu3aGewMl8JtSGgwXn75Zc2fP9/6KsmXXnpJERERptsCrolNmzZp4MCBVcbHjh2rtLS0a98QrogABgDAAN4DBgDAAAIYAAADCGAAAAwggAEAMIAABgDAAAIYAAADCGAAAAwggIF6YMCAAZoyZYrpNuodfm+oywhgoBFIS0tTixYtTLcB4AIEMAAABhDAQD1RUVGh6dOny8/PTwEBAUpOTrbmnn/+eYWFhal58+YKDg7Wo48+quLiYknfPSP4wQcfVFFRkWw2m2w2m/XakpISPfnkk/rRj36k5s2bKyIiQps2bapWP0ePHtXw4cPVsmVLNW/eXDfffLPWrl1r7dNms2nNmjXq0aOHPD09deutt2rPnj0u29i6dav69esnLy8vBQcHa/LkyTp9+rQ1X53+Pv74Yw0YMEDNmjVTy5YtFR0drVOnTlXr9waYRAAD9cSbb76p5s2ba9u2bZo3b55mz56t9PR0SZKbm5teeukl7d27V2+++aY+/PBDTZ8+XZLUt29fvfDCC/Lx8VF+fr7y8/P15JNPSpImTZqkrKwsvfvuu8rNzdVdd92lIUOG6MCBA1fsJz4+XiUlJdqyZYt2796tZ599Vtdff71LzbRp05Samqrt27erTZs2Gj58uEpLSyVJhw4d0pAhQzRixAjl5uZq6dKl2rp1qyZNmmS9/kr95eTkaNCgQerWrZuysrK0detWDR8+XOXl5dX6vQFGOQHUebfffrvztttucxm75ZZbnImJiRetX758ubNVq1bW+htvvOH09fV1qTl69KizSZMmzq+++splfNCgQc6kpKQr9hQWFuZMTk6+6NzGjRudkpzvvvuuNfbNN984vby8nEuXLnU6nU5nXFycc8KECS6v++ijj5xubm7Os2fPVqu/kSNHOn/6059essfv+3sDriW+DxioJ3r06OGyHhgYqBMnTkiSNmzYoJSUFO3bt08Oh0NlZWU6d+6czpw5o2bNml10e7t371Z5ebk6d+7sMl5SUqJWrVpdsZ/JkyfrkUce0fr16xUVFaURI0ZU6TEyMtL62c/PT6Ghofriiy8kSbt27VJubq6WLFli1TidTlVUVCgvL0+HDx++Yn85OTm66667Ltvn5X5vgEkEMFBPXHfddS7rNptNFRUVOnLkiH7+85/rkUce0TPPPCM/Pz9t3bpVcXFxOn/+/CUDuLi4WE2aNFF2draaNGniMve/l5Iv5qGHHlJ0dLTWrFmj9evXKyUlRampqXrssceqdTzFxcV6+OGHNXny5Cpz7dq1U25u7hX78/LyuuJ+LvV7A0wjgIF6Ljs7WxUVFUpNTZWb23cf61i2bJlLjbu7u8v7opLUq1cvlZeX68SJE+rXr1+N9h0cHKyJEydq4sSJSkpK0p///GeXAP7kk0/Url07SdKpU6f0r3/9S127dpUk9e7dW59//rk6dep00W1Xp78ePXooIyNDs2bNqlH/gEl8CAuo5zp16qTS0lL98Y9/1OHDh/X//t//06JFi1xqOnTooOLiYmVkZOjrr7/WmTNn1LlzZ40ePVpjxozRe++9p7y8PH366adKSUnRmjVrrrjfKVOm6IMPPlBeXp527typjRs3WuFaafbs2crIyNCePXv0wAMPqHXr1oqNjZUkJSYmKjMzU5MmTVJOTo4OHDig999/3/oQVnX6S0pK0vbt2/Xoo48qNzdX+/bt08KFC/X111/Xwm8WuLoIYKCeCw8P1/PPP69nn31W3bt315IlS5SSkuJS07dvX02cOFH33HOP2rRpo3nz5kmS3njjDY0ZM0ZPPPGEQkNDFRsbq+3bt1tnrZdTXl6u+Ph4de3aVUOGDFHnzp316quvutTMnTtXjz/+uPr06SO73a5Vq1bJ3d1d0ndnr5s3b9a//vUv9evXT7169dLMmTMVFBRkvf5K/XXu3Fnr16/Xrl279JOf/ESRkZF6//331bQpF/dQ99mcTqfTdBMAGpZNmzZp4MCBOnXqFE/gAi6BM2AAAAwggAFc1NChQ3X99ddfdPnDH/5guj2g3uMSNICL+uqrr3T27NmLzvn5+cnPz+8adwQ0LAQwAAAGcAkaAAADCGAAAAwggAEAMIAABgDAAAIYAAADCGAAAAwggAEAMIAABgDAgP8PnULNex7BbG8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "ax=sns.countplot(x=df['hate_speech'],data=df,order=df['hate_speech'].value_counts().index)\n",
    "for p,label in zip(ax.patches,df['hate_speech'].value_counts()):\n",
    "    ax.annotate(label,(p.get_x()+0.25,p.get_height()+0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704129cf",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9201f1d",
   "metadata": {},
   "source": [
    "#### Remove NaN values and drop comments which are deleted or removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c83555f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment Length:  22841\n",
      "Comment Count:  22757\n",
      "Hate Speech Length:  22841\n",
      "Hate Speech Count:  22841\n"
     ]
    }
   ],
   "source": [
    "size_col0 = len(df['comment'])\n",
    "size_col1 = df['comment'].count()\n",
    "size_col2 = len(df['hate_speech'])\n",
    "size_col3 = df['hate_speech'].count()\n",
    "print(\"Comment Length: \", size_col0)\n",
    "print(\"Comment Count: \", size_col1)\n",
    "print(\"Hate Speech Length: \", size_col2)\n",
    "print(\"Hate Speech Count: \",size_col3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b85b670",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna().loc[(df['comment'] != '[deleted]') & (df['comment'] != '[removed]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c3293986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment Length:  22246\n",
      "Comment Count:  22246\n",
      "Hate Speech Length:  22246\n",
      "Hate Speech Count:  22246\n"
     ]
    }
   ],
   "source": [
    "size_col0 = len(df['comment'])\n",
    "size_col1 = df['comment'].count()\n",
    "size_col2 = len(df['hate_speech'])\n",
    "size_col3 = df['hate_speech'].count()\n",
    "print(\"Comment Length: \", size_col0)\n",
    "print(\"Comment Count: \", size_col1)\n",
    "print(\"Hate Speech Length: \", size_col2)\n",
    "print(\"Hate Speech Count: \",size_col3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6202991",
   "metadata": {},
   "source": [
    "#### Save the cleaned dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e4064d33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved.\n"
     ]
    }
   ],
   "source": [
    "df.to_csv('Reddit_Cleaned.csv', index=False)\n",
    "print(\"File saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ed0471",
   "metadata": {},
   "source": [
    "## Convert to lowercase \n",
    "\n",
    "\n",
    "#### In tokenization a sentence word by word, same word represented in upper and lower case notations are identified as different words. For example, ‘Basic’ and ‘basic’ are considered different but they both are same,because python is case-sensitive,it adds complexity to model, to simplify it we do lowercasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aede55c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hiii. Just got off work. 444 is mainly the typa guys you imagine writing for US stupid sites, but basically they just try to fit in with the Western European and US big city hipsters.   Rich kids from Budapest who feel they are brave journalistic heroes.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c48614a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>hate_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a subsection of retarded hungarians? ohh boy. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hiii. just got off work. 444 is mainly the typ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wow i guess soyboys are the same in every country</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>owen benjamin's soyboy song goes for every cou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&gt; \"y'all hear sumn?\"  by all means i live in a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  hate_speech\n",
       "0  a subsection of retarded hungarians? ohh boy. ...            1\n",
       "1  hiii. just got off work. 444 is mainly the typ...            0\n",
       "2  wow i guess soyboys are the same in every country            0\n",
       "3  owen benjamin's soyboy song goes for every cou...            0\n",
       "4  > \"y'all hear sumn?\"  by all means i live in a...            0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment']=df['comment'].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "59dbde25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hiii. just got off work. 444 is mainly the typa guys you imagine writing for us stupid sites, but basically they just try to fit in with the western european and us big city hipsters.   rich kids from budapest who feel they are brave journalistic heroes.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a22cb1",
   "metadata": {},
   "source": [
    "## Removing HTML Tags \n",
    "\n",
    "#### Removing unwanted data from the text, let’s take the case of scraping data from web, where we get html tags which are unnecessary for the data,those should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "65cee46d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>hate_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a subsection of retarded hungarians? ohh boy. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hiii. just got off work. 444 is mainly the typ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wow i guess soyboys are the same in every country</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>owen benjamin's soyboy song goes for every cou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&gt; \"y'all hear sumn?\"  by all means i live in a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  hate_speech\n",
       "0  a subsection of retarded hungarians? ohh boy. ...            1\n",
       "1  hiii. just got off work. 444 is mainly the typ...            0\n",
       "2  wow i guess soyboys are the same in every country            0\n",
       "3  owen benjamin's soyboy song goes for every cou...            0\n",
       "4  > \"y'all hear sumn?\"  by all means i live in a...            0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_html_tags(text):\n",
    "    if isinstance(text, float) or text is None:  # Check for float or None and convert to empty string\n",
    "        text = ''\n",
    "    pattern = re.compile(r'<.*?>')\n",
    "    return pattern.sub('', text)\n",
    "\n",
    "df['comment'] = df['comment'].astype(str)\n",
    "df['comment'] = df['comment'].apply(remove_html_tags)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938e6737",
   "metadata": {},
   "source": [
    "## Removing URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "801ce1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>hate_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a subsection of retarded hungarians? ohh boy. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hiii. just got off work. 444 is mainly the typ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wow i guess soyboys are the same in every country</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>owen benjamin's soyboy song goes for every cou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&gt; \"y'all hear sumn?\"  by all means i live in a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  hate_speech\n",
       "0  a subsection of retarded hungarians? ohh boy. ...            1\n",
       "1  hiii. just got off work. 444 is mainly the typ...            0\n",
       "2  wow i guess soyboys are the same in every country            0\n",
       "3  owen benjamin's soyboy song goes for every cou...            0\n",
       "4  > \"y'all hear sumn?\"  by all means i live in a...            0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_url(text):\n",
    "    pattern=re.compile(r'https?://\\s+|www.\\.\\S+')\n",
    "    return pattern.sub(r'',text)\n",
    "\n",
    "df['comment']=df['comment'].apply(remove_url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f1d0fa",
   "metadata": {},
   "source": [
    "## Stop words Removal \n",
    "\n",
    "#### Words which help in sentence formation, but does not aid any meaning to the sentence like ‘a’, ‘an’, ‘the’, ‘is’ and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a0581abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hiii. just got off work. 444 is mainly the typa guys you imagine writing for us stupid sites, but basically they just try to fit in with the western european and us big city hipsters.   rich kids from budapest who feel they are brave journalistic heroes.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2e7e163e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>hate_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subsection  retarded hungarians? ohh boy. bra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hiii. just got  work. 444  mainly  typa guys  ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wow  guess soyboys     every country</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>owen benjamin's soyboy song goes  every countr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&gt; \"y'all hear sumn?\"   means  live   small tow...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  hate_speech\n",
       "0   subsection  retarded hungarians? ohh boy. bra...            1\n",
       "1  hiii. just got  work. 444  mainly  typa guys  ...            0\n",
       "2               wow  guess soyboys     every country            0\n",
       "3  owen benjamin's soyboy song goes  every countr...            0\n",
       "4  > \"y'all hear sumn?\"   means  live   small tow...            0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = get_stop_words('en')\n",
    "def stop_words_removal(text):\n",
    "    new_text=[]\n",
    "    for word in text.split():\n",
    "        if word in get_stop_words('en'):\n",
    "            new_text.append('')\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    return ' '.join(new_text)\n",
    "\n",
    "df['comment']=df['comment'].apply(stop_words_removal)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "408eff26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hiii. just got  work. 444  mainly  typa guys  imagine writing  us stupid sites,  basically  just try  fit    western european  us big city hipsters. rich kids  budapest  feel   brave journalistic heroes.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa06d54",
   "metadata": {},
   "source": [
    "## Removing Punctuations \n",
    "\n",
    "#### When we are tokenizing the sentences, punctuations become different words. For example, \"Hello! how are you?\" is tokenized as [Hello , !, how ,are, you,?]. Here punctuation marks are taken as different words. It adds complexity to the model by performing more operations to the code and punctuations does not attribute any meaning to the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1559f232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hiii. just got  work. 444  mainly  typa guys  imagine writing  us stupid sites,  basically  just try  fit    western european  us big city hipsters. rich kids  budapest  feel   brave journalistic heroes.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "32d7ded2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>hate_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subsection  retarded hungarians ohh boy brace...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hiii just got  work 444  mainly  typa guys  im...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wow  guess soyboys     every country</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>owen benjamins soyboy song goes  every country...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yall hear sumn   means  live   small town rn ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  hate_speech\n",
       "0   subsection  retarded hungarians ohh boy brace...            1\n",
       "1  hiii just got  work 444  mainly  typa guys  im...            0\n",
       "2               wow  guess soyboys     every country            0\n",
       "3  owen benjamins soyboy song goes  every country...            0\n",
       "4   yall hear sumn   means  live   small town rn ...            0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(string.punctuation)\n",
    "exclude=string.punctuation\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    for char in exclude:\n",
    "        text=text.replace(char,'')\n",
    "    return text\n",
    "\n",
    "df['comment']=df['comment'].apply(remove_punctuation)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1c83247b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hiii just got  work 444  mainly  typa guys  imagine writing  us stupid sites  basically  just try  fit    western european  us big city hipsters rich kids  budapest  feel   brave journalistic heroes'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a26915",
   "metadata": {},
   "source": [
    "## Chat Word Treatment \n",
    "\n",
    "#### Words like ROFL,LMAO,FYI,GD,ASAP, are found in chat messages of many social media platforms like WhatsApp, Instagram, Twitter. While summarizing the text, to understand the meaning of the word, these short words should be replaced with long forms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "50a4f48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_words={'AFAIK': 'As Far As I Know',\n",
    "'AFK':'Away From Keyboard',\n",
    "'ASAP':'As Soon As Possible',\n",
    "'ATK':'At The Keyboard',\n",
    "'ATM':'At The Moment',\n",
    "'A3':'Anytime, Anywhere, Anyplace',\n",
    "'BAK':'Back At Keyboard',\n",
    "'BBL': 'Be Back Later',\n",
    "'BBS': 'Be Back Soon',\n",
    "'BFN': 'Bye For Now',\n",
    "'B4N': 'Bye For Now',\n",
    "'BRB': 'Be Right Back',\n",
    "'BRT': 'Be Right There',\n",
    "'BTW': 'By The Way',\n",
    "'B4': 'Before',\n",
    "'B4N': 'Bye For Now',\n",
    "'CU':'See You',\n",
    "'CUL8R':'See You Later',\n",
    "'CYA': 'See You',\n",
    "'FAQ': 'Frequently Asked Questions',\n",
    "'FC': 'Fingers Crossed',\n",
    "'FWIW': 'For What Its Worth',\n",
    "'FYI': 'For Your Information',\n",
    "'GAL': 'Get A Life',\n",
    "'GG': 'Good Game',\n",
    "'GN' : 'Good Night',\n",
    "'GMTA': 'Great Minds Think Alike',\n",
    "'GR8': 'Great!',\n",
    "'G9': 'Genius',\n",
    "'IC': 'I See',\n",
    "'ICQ': 'I Seek you (also a chat program)',\n",
    "'ILU': 'I Love You',\n",
    "'IMHO': 'In My Honest/Humble Opinion',\n",
    "'IMO':'In My Opinion',\n",
    "'IOW':'In Other Words',\n",
    "'IRL': 'In Real Life',\n",
    "'KISS':'Keep It Simple, Stupid',\n",
    "'LDR':'Long Distance Relationship',\n",
    "'LMAO':'Laugh My A.. Off',\n",
    "'LOL':'Laughing Out Loud',\n",
    "'LTNS': 'Long Time No See',\n",
    "'L8R': 'Later',\n",
    "'MTE': 'My Thoughts Exactly',\n",
    "'M8': 'Mate',\n",
    "'NRN': 'No Reply Necessary',\n",
    "'OIC':'Oh I See',\n",
    "'PITA':'Pain In The A..',\n",
    "'PRT': 'Party',\n",
    "'PRW':'Parents Are Watching',\n",
    "'QPSA':\t'Que Pasa?',\n",
    "'ROFL':'Rolling On The Floor Laughing',\n",
    "'ROFLOL': 'Rolling On The Floor Laughing Out Loud',\n",
    "'ROTFLMAO':'Rolling On The Floor Laughing My A.. Off',\n",
    "'SK8':'Skate',\n",
    "'STATS':'Your sex and age',\n",
    "'ASL':'Age, Sex, Location',\n",
    "'THX':'Thank You',\n",
    "'TTFN':'Ta-Ta For Now!',\n",
    "'TTYL':'Talk To You Later',\n",
    "'U':'You',\n",
    "'U2':'You Too',\n",
    "'U4E':'Yours For Ever',\n",
    "'WB':'Welcome Back',\n",
    "'WTF':'What The F...',\n",
    "'WTG':'Way To Go!',\n",
    "'WUF':'Where Are You From?',\n",
    "'W8':'Wait...',\n",
    "'7K':'Sick'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a1bc79e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' apparently  don’t study    either    had you’d know   muchanticipated modern reformation  islam will never actually happen  i’m wasting  time   think marxism   positive influence   christian west   retarded last  checked atheists still need food lol'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment'][16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dbe898a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>hate_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subsection retarded hungarians ohh boy brace l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hiii just got work 444 mainly typa guys imagin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wow guess soyboys every country</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>owen benjamins soyboy song goes every country ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yall hear sumn means live small town rn for wo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  hate_speech\n",
       "0  subsection retarded hungarians ohh boy brace l...            1\n",
       "1  hiii just got work 444 mainly typa guys imagin...            0\n",
       "2                    wow guess soyboys every country            0\n",
       "3  owen benjamins soyboy song goes every country ...            0\n",
       "4  yall hear sumn means live small town rn for wo...            0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chat_word(text):\n",
    "    new_text=[]\n",
    "    for word in text.split():\n",
    "        if word.upper() in chat_words:\n",
    "            new_text.append(chat_words[word.upper()])\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "            \n",
    "    return \" \".join(new_text)\n",
    "\n",
    "df['comment']=df['comment'].apply(chat_word)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5dd103c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'apparently don’t study either had you’d know muchanticipated modern reformation islam will never actually happen i’m wasting time think marxism positive influence christian west retarded last checked atheists still need food Laughing Out Loud'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment'][16]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea68239",
   "metadata": {},
   "source": [
    "## Handling Emoji’s \n",
    "\n",
    "#### While analyzing chatting messages, for text classification or sentiment analysis, emoji’s particularly have a meaning, we can replace emoji expression with their corresponding meaning. If our problem statement does not have anything to do with sentiments or feelings,we can remove them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d9b52a2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>hate_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subsection retarded hungarians ohh boy brace l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hiii just got work 444 mainly typa guys imagin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wow guess soyboys every country</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>owen benjamins soyboy song goes every country ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yall hear sumn means live small town rn for wo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  hate_speech\n",
       "0  subsection retarded hungarians ohh boy brace l...            1\n",
       "1  hiii just got work 444 mainly typa guys imagin...            0\n",
       "2                    wow guess soyboys every country            0\n",
       "3  owen benjamins soyboy song goes every country ...            0\n",
       "4  yall hear sumn means live small town rn for wo...            0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def emoji_removal(text):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "df['comment']=df['comment'].apply(emoji_removal)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711681bd",
   "metadata": {},
   "source": [
    "## Tokenization \n",
    "\n",
    "#### Breaking the text into sentences and words, we understand context of the text and we can also the find the topic of the text and many more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2fc78483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good answer print pin wall top unconstructive fallacies internet'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment'][17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8cae6cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>hate_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[subsection, retarded, hungarians, ohh, boy, b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[hiii, just, got, work, 444, mainly, typa, guy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[wow, guess, soyboys, every, country]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[owen, benjamins, soyboy, song, goes, every, c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[yall, hear, sumn, means, live, small, town, r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  hate_speech\n",
       "0  [subsection, retarded, hungarians, ohh, boy, b...            1\n",
       "1  [hiii, just, got, work, 444, mainly, typa, guy...            0\n",
       "2              [wow, guess, soyboys, every, country]            0\n",
       "3  [owen, benjamins, soyboy, song, goes, every, c...            0\n",
       "4  [yall, hear, sumn, means, live, small, town, r...            0"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment']=df['comment'].apply(word_tokenize)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5a3daa38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good',\n",
       " 'answer',\n",
       " 'print',\n",
       " 'pin',\n",
       " 'wall',\n",
       " 'top',\n",
       " 'unconstructive',\n",
       " 'fallacies',\n",
       " 'internet']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment'][17]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2297f19",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534bbe13",
   "metadata": {},
   "source": [
    "#### Stemming is the process of reducing inflection in words to their root forms such as mapping a group of words to the same stem even if the stem itself is not a valid word in the Language. Inflection is the modification of a word to express different grammatical categories such as tense, voice, aspect, person, gender and mood. In stemming, inflection is not cared much, other than the reducing the word to its stem.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b6afa352",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good',\n",
       " 'answer',\n",
       " 'print',\n",
       " 'pin',\n",
       " 'wall',\n",
       " 'top',\n",
       " 'unconstructive',\n",
       " 'fallacies',\n",
       " 'internet']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment'][17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cee4a723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>hate_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[subsect, retard, hungarian, ohh, boy, brace, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[hiii, just, got, work, 444, main, typa, guy, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[wow, guess, soyboy, everi, countri]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[owen, benjamin, soyboy, song, goe, everi, cou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[yall, hear, sumn, mean, live, small, town, rn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  hate_speech\n",
       "0  [subsect, retard, hungarian, ohh, boy, brace, ...            1\n",
       "1  [hiii, just, got, work, 444, main, typa, guy, ...            0\n",
       "2               [wow, guess, soyboy, everi, countri]            0\n",
       "3  [owen, benjamin, soyboy, song, goe, everi, cou...            0\n",
       "4  [yall, hear, sumn, mean, live, small, town, rn...            0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment'] = df['comment'].apply(lambda x: [stemmer.stem(y) for y in x]) \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d93e6f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good',\n",
       " 'answer',\n",
       " 'print',\n",
       " 'pin',\n",
       " 'wall',\n",
       " 'top',\n",
       " 'unconstruct',\n",
       " 'fallaci',\n",
       " 'internet']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment'][17]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e494c2b",
   "metadata": {},
   "source": [
    "## Lemmatization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d17653b9",
   "metadata": {},
   "source": [
    "#### Lemmatization unlike stemming reduces inflected words properly ensuring that the root word belongs to the language. In the lemmatization root word is called lemma.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "32d44e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['good',\n",
       " 'answer',\n",
       " 'print',\n",
       " 'pin',\n",
       " 'wall',\n",
       " 'top',\n",
       " 'unconstruct',\n",
       " 'fallaci',\n",
       " 'internet']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment'][17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b88dab8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>hate_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subsect retard hungarian ohh boy brace livid b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hiii just got work 444 main typa guy imagin wr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wow guess soyboy everi countri</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>owen benjamin soyboy song goe everi countri amaz</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yall hear sumn mean live small town rn for wor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  hate_speech\n",
       "0  subsect retard hungarian ohh boy brace livid b...            1\n",
       "1  hiii just got work 444 main typa guy imagin wr...            0\n",
       "2                     wow guess soyboy everi countri            0\n",
       "3   owen benjamin soyboy song goe everi countri amaz            0\n",
       "4  yall hear sumn mean live small town rn for wor...            0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment'] = df['comment'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
    "wnl=WordNetLemmatizer()\n",
    "def lemmatizing(text):\n",
    "    return \" \".join([wnl.lemmatize(word,pos='v') for word in text.split('  ')])\n",
    "\n",
    "df['comment']=df['comment'].apply(lemmatizing)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "403dcf3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'good answer print pin wall top unconstruct fallaci internet'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment'][17]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7f2bc4-b259-40a1-8a06-5774afe3d94a",
   "metadata": {},
   "source": [
    "## Remove extra spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "349e6d17-333f-45ec-b554-7e2a46979cab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aman Shekhar Sachan\\AppData\\Local\\Temp\\ipykernel_4164\\2490348515.py:18: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(clean_spaces)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data has been saved to 'Cleaned_spaces_Reddit.csv'\n"
     ]
    }
   ],
   "source": [
    "#removing spaces\n",
    "input_file_path = 'Original_Reddit.csv'\n",
    "output_file_path = 'Cleaned_spaces_Reddit.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(input_file_path)\n",
    "\n",
    "# Function to clean up extra spaces in a string\n",
    "def clean_spaces(text):\n",
    "    if isinstance(text, str):\n",
    "        # Remove multiple consecutive spaces\n",
    "        text = re.sub(r'\\s{2,}', ' ', text)\n",
    "        # Trim leading and trailing spaces\n",
    "        text = text.strip()\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to each cell in the DataFrame\n",
    "df = df.applymap(clean_spaces)\n",
    "\n",
    "# Save the cleaned DataFrame to a new CSV file\n",
    "df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Cleaned data has been saved to '{output_file_path}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cb556d",
   "metadata": {},
   "source": [
    "## Remove Numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "37640f1e-cc65-45ad-82be-99defe414c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Define the file paths\n",
    "input_file_path = 'Cleaned_spaces_Reddit.csv'\n",
    "output_file_path = 'processed_Reddit.csv'\n",
    "\n",
    "# Dictionary of number meanings\n",
    "number_meanings = {\n",
    "    '111': 'Alignment and manifestation',\n",
    "    '1111': 'New beginnings and unity',\n",
    "    '222': 'Balance and harmony',\n",
    "    '333': 'Protection and encouragement',\n",
    "    '444': 'Foundation and grounding',\n",
    "    '555': 'Change and transformation',\n",
    "    '666': 'Reflection and personal development',\n",
    "    '777': 'Spiritual growth and good fortune',\n",
    "    '888': 'Abundance and success',\n",
    "    '999': 'Completion and closure',\n",
    "    '1010': 'Personal development and growth',\n",
    "    '1212': 'Spiritual awakening and higher consciousness',\n",
    "    '1234': 'Progress and moving forward',\n",
    "    '2222': 'Peace and balance in life',\n",
    "    '3333': 'Divine protection and guidance',\n",
    "    '4444': 'Strong foundation and support',\n",
    "    '5555': 'Major life changes',\n",
    "    '6666': 'Reflecting on past choices',\n",
    "    '7777': 'Luck and spiritual awareness',\n",
    "    '8888': 'Financial abundance and prosperity',\n",
    "    '9999': 'Endings leading to new beginnings',\n",
    "    '1001': 'Self-improvement and new perspectives',\n",
    "    '1101': 'Opening new doors and opportunities',\n",
    "    '1211': 'Embracing new phases in life',\n",
    "    '1233': 'Balanced progress and harmony',\n",
    "    '1441': 'Foundation and new opportunities',\n",
    "    '1515': 'Personal growth and freedom',\n",
    "    '1616': 'Stability and inner strength',\n",
    "    '1717': 'Awakening and self-awareness',\n",
    "    '1818': 'Financial success and independence',\n",
    "    '1919': 'Completion of cycles and new beginnings',\n",
    "    '2020': 'Vision and clarity',\n",
    "    '2121': 'Positive change and new opportunities',\n",
    "    '2323': 'Creativity and self-expression',\n",
    "    '2424': 'Building strong foundations',\n",
    "    '2525': 'Adaptability and positive change',\n",
    "    '2626': 'Nurturing and care for loved ones',\n",
    "    '2727': 'Spiritual awareness and inner wisdom',\n",
    "    '2828': 'Abundance and prosperity',\n",
    "    '2929': 'Transformation and new phases',\n",
    "    '3030': 'Creativity and communication',\n",
    "    '3131': 'Optimism and positive energy',\n",
    "    '3232': 'Faith and trust in the universe',\n",
    "    '3434': 'Stability and determination',\n",
    "    '3535': 'Personal freedom and individuality',\n",
    "    '3636': 'Nurturing and compassion',\n",
    "    '3737': 'Spiritual growth and awareness',\n",
    "    '3838': 'Ab'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fc96d676",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aman Shekhar Sachan\\AppData\\Local\\Temp\\ipykernel_4164\\364568715.py:21: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: replace_numbers(x, number_meanings))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed data has been saved to 'processed_Reddit.csv'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to replace or remove numbers in a string\n",
    "def replace_numbers(text, number_meanings):\n",
    "    if isinstance(text, str):\n",
    "        # Find all numbers in the text\n",
    "        numbers = re.findall(r'\\b\\d+\\b', text)\n",
    "        for number in numbers:\n",
    "            if number in number_meanings:\n",
    "                # Replace number with its meaning\n",
    "                text = re.sub(r'\\b' + re.escape(number) + r'\\b', number_meanings[number], text)\n",
    "            else:\n",
    "                # Remove number if no meaning exists\n",
    "                text = re.sub(r'\\b' + re.escape(number) + r'\\b', '', text)\n",
    "        # Remove any extra spaces after replacement/removal\n",
    "        text = re.sub(r'\\s{2,}', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(input_file_path)\n",
    "\n",
    "# Apply the number replacement function to each cell in the DataFrame\n",
    "df = df.applymap(lambda x: replace_numbers(x, number_meanings))\n",
    "\n",
    "# Save the processed DataFrame to a new CSV file\n",
    "df.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(f\"Processed data has been saved to '{output_file_path}'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89871ed",
   "metadata": {},
   "source": [
    "## Apply Autocorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9864e8c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 5020/5020 [1:33:39<00:00,  1.12s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 5020/5020 [07:39<00:00, 10.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  id  \\\n",
      "0         . e8q18lf\\n. e8q9w5s\\n. e8qbobk\\n. e8qfn91   \n",
      "1                    . e9c6naz\\n. e9d03a5\\n. e9d8e4d   \n",
      "2  . e84rl2i\\n. e84w60l\\n. e8544rn\\n. e85ifut\\n. ...   \n",
      "3                               . e7kq72n\\n. e7m24ar   \n",
      "4  . e7hdgoh\\n. e7iyj6a\\n. e7j6iho\\n. e7m2412\\n. ...   \n",
      "\n",
      "                                                text hate_speech_idx  \\\n",
      "0  . A subsection of retarded Hungarians? Oh boy....              []   \n",
      "1  . > \"y'all hear sun?\" by all means I live in a...              []   \n",
      "2  . wouldn't the defenders or whatever they are ...             NaN   \n",
      "3  . Because the Japanese aren't retarded and kno...              []   \n",
      "4  . That might be true if we didn't have an exam...            [, ]   \n",
      "\n",
      "                                            response  \n",
      "0  [\"I don't see a reason why it's okay to insult...  \n",
      "1  ['Persons with disabilities is the accepted te...  \n",
      "2                                                NaN  \n",
      "3  [\"It's not right for anyone of any gender to b...  \n",
      "4  [\"You shouldn't be bringing up sensitive topic...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from autocorrect import Speller\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('processed_Reddit.csv')\n",
    "\n",
    "# Initialize the spell checker\n",
    "spell = Speller()\n",
    "\n",
    "# Define the autocorrect function\n",
    "def autocorrect_text(text):\n",
    "    if isinstance(text, str):\n",
    "        return spell(text)\n",
    "    return text\n",
    "\n",
    "# Function to apply autocorrect in parallel\n",
    "def parallel_apply(data, func, workers=4):\n",
    "    with ThreadPoolExecutor(max_workers=workers) as executor:\n",
    "        results = list(tqdm(executor.map(func, data), total=len(data)))\n",
    "    return results\n",
    "\n",
    "# Choose the columns to apply autocorrect\n",
    "target_columns = ['text', 'response']\n",
    "\n",
    "# Apply autocorrect to each target column in parallel\n",
    "for column in target_columns:\n",
    "    df[column] = parallel_apply(df[column], autocorrect_text)\n",
    "\n",
    "# Save the processed DataFrame to a new CSV file\n",
    "output_file_path = 'processed_Reddit_autocorrected.csv'\n",
    "df.to_csv(output_file_path, index=False)\n",
    "\n",
    "# Display the first few rows to confirm changes\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cd19e7",
   "metadata": {},
   "source": [
    "#### Save the Preprocessed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f59a9ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved\n"
     ]
    }
   ],
   "source": [
    "df.to_csv('Reddit_final.csv', index=False)\n",
    "print(\"File saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
