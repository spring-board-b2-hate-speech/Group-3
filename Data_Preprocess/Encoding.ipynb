{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4536f773-a077-44c9-a8eb-21d0bd45c908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4563244-d2b0-4c36-8fc5-79582c611476",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>words</th>\n",
       "      <th>lemmatized_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subsection retarded hungarians ohh boy brace l...</td>\n",
       "      <td>1</td>\n",
       "      <td>['subsection', 'retarded', 'hungarians', 'ohh'...</td>\n",
       "      <td>subsection retard hungarians ohh boy brace liv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hiii just got work Foundation and grounding ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>['hiii', 'just', 'got', 'work', 'Foundation', ...</td>\n",
       "      <td>hiii just get work Foundation and ground mainl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wow guess soyboys every country</td>\n",
       "      <td>0</td>\n",
       "      <td>['wow', 'guess', 'soyboys', 'every', 'country']</td>\n",
       "      <td>wow guess soyboys every country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>owen benjamins soyboy song goes every country ...</td>\n",
       "      <td>0</td>\n",
       "      <td>['owen', 'benjamins', 'soyboy', 'song', 'goes'...</td>\n",
       "      <td>owen benjamins soyboy song go every country amaze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yall hear sumn means live small town rn for w...</td>\n",
       "      <td>0</td>\n",
       "      <td>['yall', 'hear', 'sumn', 'means', 'live', 'sma...</td>\n",
       "      <td>yall hear sumn mean live small town rn for wor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  hate_speech  \\\n",
       "0  subsection retarded hungarians ohh boy brace l...            1   \n",
       "1  hiii just got work Foundation and grounding ma...            0   \n",
       "2                    wow guess soyboys every country            0   \n",
       "3  owen benjamins soyboy song goes every country ...            0   \n",
       "4   yall hear sumn means live small town rn for w...            0   \n",
       "\n",
       "                                               words  \\\n",
       "0  ['subsection', 'retarded', 'hungarians', 'ohh'...   \n",
       "1  ['hiii', 'just', 'got', 'work', 'Foundation', ...   \n",
       "2    ['wow', 'guess', 'soyboys', 'every', 'country']   \n",
       "3  ['owen', 'benjamins', 'soyboy', 'song', 'goes'...   \n",
       "4  ['yall', 'hear', 'sumn', 'means', 'live', 'sma...   \n",
       "\n",
       "                                  lemmatized_comment  \n",
       "0  subsection retard hungarians ohh boy brace liv...  \n",
       "1  hiii just get work Foundation and ground mainl...  \n",
       "2                    wow guess soyboys every country  \n",
       "3  owen benjamins soyboy song go every country amaze  \n",
       "4  yall hear sumn mean live small town rn for wor...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('Reddit_Tokenization.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00225fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>words</th>\n",
       "      <th>lemmatized_comment</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subsection retarded hungarians ohh boy brace l...</td>\n",
       "      <td>1</td>\n",
       "      <td>['subsection', 'retarded', 'hungarians', 'ohh'...</td>\n",
       "      <td>subsection retard hungarians ohh boy brace liv...</td>\n",
       "      <td>[subsection, retard, hungarians, ohh, boy, bra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hiii just got work Foundation and grounding ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>['hiii', 'just', 'got', 'work', 'Foundation', ...</td>\n",
       "      <td>hiii just get work Foundation and ground mainl...</td>\n",
       "      <td>[hiii, just, get, work, Foundation, and, groun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wow guess soyboys every country</td>\n",
       "      <td>0</td>\n",
       "      <td>['wow', 'guess', 'soyboys', 'every', 'country']</td>\n",
       "      <td>wow guess soyboys every country</td>\n",
       "      <td>[wow, guess, soyboys, every, country]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>owen benjamins soyboy song goes every country ...</td>\n",
       "      <td>0</td>\n",
       "      <td>['owen', 'benjamins', 'soyboy', 'song', 'goes'...</td>\n",
       "      <td>owen benjamins soyboy song go every country amaze</td>\n",
       "      <td>[owen, benjamins, soyboy, song, go, every, cou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yall hear sumn means live small town rn for w...</td>\n",
       "      <td>0</td>\n",
       "      <td>['yall', 'hear', 'sumn', 'means', 'live', 'sma...</td>\n",
       "      <td>yall hear sumn mean live small town rn for wor...</td>\n",
       "      <td>[yall, hear, sumn, mean, live, small, town, rn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  hate_speech  \\\n",
       "0  subsection retarded hungarians ohh boy brace l...            1   \n",
       "1  hiii just got work Foundation and grounding ma...            0   \n",
       "2                    wow guess soyboys every country            0   \n",
       "3  owen benjamins soyboy song goes every country ...            0   \n",
       "4   yall hear sumn means live small town rn for w...            0   \n",
       "\n",
       "                                               words  \\\n",
       "0  ['subsection', 'retarded', 'hungarians', 'ohh'...   \n",
       "1  ['hiii', 'just', 'got', 'work', 'Foundation', ...   \n",
       "2    ['wow', 'guess', 'soyboys', 'every', 'country']   \n",
       "3  ['owen', 'benjamins', 'soyboy', 'song', 'goes'...   \n",
       "4  ['yall', 'hear', 'sumn', 'means', 'live', 'sma...   \n",
       "\n",
       "                                  lemmatized_comment  \\\n",
       "0  subsection retard hungarians ohh boy brace liv...   \n",
       "1  hiii just get work Foundation and ground mainl...   \n",
       "2                    wow guess soyboys every country   \n",
       "3  owen benjamins soyboy song go every country amaze   \n",
       "4  yall hear sumn mean live small town rn for wor...   \n",
       "\n",
       "                                              tokens  \n",
       "0  [subsection, retard, hungarians, ohh, boy, bra...  \n",
       "1  [hiii, just, get, work, Foundation, and, groun...  \n",
       "2              [wow, guess, soyboys, every, country]  \n",
       "3  [owen, benjamins, soyboy, song, go, every, cou...  \n",
       "4  [yall, hear, sumn, mean, live, small, town, rn...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "df['tokens'] = df['lemmatized_comment'].apply(lambda x: word_tokenize(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cfd05f-0da7-4a76-965d-8dbcf91cd6e4",
   "metadata": {},
   "source": [
    "## One Hot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d8f8911-35a0-4820-8723-9e196f5cc170",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Happy: [1, 0, 0, 0, 0, 0]\n",
      "Welcome: [0, 1, 0, 0, 0, 0]\n",
      "learning.: [0, 0, 1, 0, 0, 0]\n",
      "to: [0, 0, 0, 1, 0, 0]\n",
      "Educative.: [0, 0, 0, 0, 1, 0]\n",
      "Hello!: [0, 0, 0, 0, 0, 1]\n",
      "{'Happy', 'Welcome', 'learning.', 'to', 'Educative.', 'Hello!'}\n"
     ]
    }
   ],
   "source": [
    "text = \"Hello! Welcome to Educative. Happy learning.\"\n",
    "words = text.split()\n",
    "\n",
    "vocabulary = set(words)\n",
    "\n",
    "one_hot_encoded = []\n",
    "for word in vocabulary:\n",
    "    encoding = [0] * len(vocabulary)\n",
    "    \n",
    "    index = list(vocabulary).index(word)\n",
    "    \n",
    "    encoding[index] = 1\n",
    "    one_hot_encoded.append((word, encoding))\n",
    "\n",
    "for word, encoding in one_hot_encoded:\n",
    "    print(f\"{word}: {encoding}\")\n",
    "\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a435a72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vocabulary = set()\n",
    "_ = df['tokens'].apply(lambda x: vocabulary.update(x))\n",
    "\n",
    "vocab_list = list(vocabulary)\n",
    "\n",
    "def one_hot_encode(tokens, vocab_list):\n",
    "    encoding = [0] * len(vocab_list)\n",
    "    \n",
    "    for token in tokens:\n",
    "        index = vocab_list.index(token)\n",
    "        \n",
    "        encoding[index] = 1\n",
    "    return encoding\n",
    "\n",
    "df['one_hot_encoded'] = df['tokens'].apply(lambda x: one_hot_encode(x, vocab_list))\n",
    "\n",
    "print(df[['lemmatized_comment', 'one_hot_encoded']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc695ee5",
   "metadata": {},
   "source": [
    "## Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c20a791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   comment  encoded_comment\n",
      "0             play running                0\n",
      "1               run runner                3\n",
      "2             playing runs                2\n",
      "3  play running run runner                1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "data = {\n",
    "    'comment': [\n",
    "        \"play running\",\n",
    "        \"run runner\",\n",
    "        \"playing runs\",\n",
    "        \"play running run runner\"\n",
    "    ]\n",
    "}\n",
    "df_sample = pd.DataFrame(data)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "df_sample['encoded_comment'] = label_encoder.fit_transform(df_sample['comment'])\n",
    "print(df_sample[['comment', 'encoded_comment']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f77511f1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>words</th>\n",
       "      <th>lemmatized_comment</th>\n",
       "      <th>tokens</th>\n",
       "      <th>one_hot_encoded</th>\n",
       "      <th>encoded_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subsection retarded hungarians ohh boy brace l...</td>\n",
       "      <td>1</td>\n",
       "      <td>['subsection', 'retarded', 'hungarians', 'ohh'...</td>\n",
       "      <td>subsection retard hungarians ohh boy brace liv...</td>\n",
       "      <td>[subsection, retard, hungarians, ohh, boy, bra...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>17295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hiii just got work Foundation and grounding ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>['hiii', 'just', 'got', 'work', 'Foundation', ...</td>\n",
       "      <td>hiii just get work Foundation and ground mainl...</td>\n",
       "      <td>[hiii, just, get, work, Foundation, and, groun...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>7662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wow guess soyboys every country</td>\n",
       "      <td>0</td>\n",
       "      <td>['wow', 'guess', 'soyboys', 'every', 'country']</td>\n",
       "      <td>wow guess soyboys every country</td>\n",
       "      <td>[wow, guess, soyboys, every, country]</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>20721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>owen benjamins soyboy song goes every country ...</td>\n",
       "      <td>0</td>\n",
       "      <td>['owen', 'benjamins', 'soyboy', 'song', 'goes'...</td>\n",
       "      <td>owen benjamins soyboy song go every country amaze</td>\n",
       "      <td>[owen, benjamins, soyboy, song, go, every, cou...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "      <td>13417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yall hear sumn means live small town rn for w...</td>\n",
       "      <td>0</td>\n",
       "      <td>['yall', 'hear', 'sumn', 'means', 'live', 'sma...</td>\n",
       "      <td>yall hear sumn mean live small town rn for wor...</td>\n",
       "      <td>[yall, hear, sumn, mean, live, small, town, rn...</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...</td>\n",
       "      <td>20881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  hate_speech  \\\n",
       "0  subsection retarded hungarians ohh boy brace l...            1   \n",
       "1  hiii just got work Foundation and grounding ma...            0   \n",
       "2                    wow guess soyboys every country            0   \n",
       "3  owen benjamins soyboy song goes every country ...            0   \n",
       "4   yall hear sumn means live small town rn for w...            0   \n",
       "\n",
       "                                               words  \\\n",
       "0  ['subsection', 'retarded', 'hungarians', 'ohh'...   \n",
       "1  ['hiii', 'just', 'got', 'work', 'Foundation', ...   \n",
       "2    ['wow', 'guess', 'soyboys', 'every', 'country']   \n",
       "3  ['owen', 'benjamins', 'soyboy', 'song', 'goes'...   \n",
       "4  ['yall', 'hear', 'sumn', 'means', 'live', 'sma...   \n",
       "\n",
       "                                  lemmatized_comment  \\\n",
       "0  subsection retard hungarians ohh boy brace liv...   \n",
       "1  hiii just get work Foundation and ground mainl...   \n",
       "2                    wow guess soyboys every country   \n",
       "3  owen benjamins soyboy song go every country amaze   \n",
       "4  yall hear sumn mean live small town rn for wor...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [subsection, retard, hungarians, ohh, boy, bra...   \n",
       "1  [hiii, just, get, work, Foundation, and, groun...   \n",
       "2              [wow, guess, soyboys, every, country]   \n",
       "3  [owen, benjamins, soyboy, song, go, every, cou...   \n",
       "4  [yall, hear, sumn, mean, live, small, town, rn...   \n",
       "\n",
       "                                     one_hot_encoded  encoded_comment  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...            17295  \n",
       "1  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...             7662  \n",
       "2  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...            20721  \n",
       "3  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...            13417  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...            20881  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "df['encoded_comment'] = label_encoder.fit_transform(df['lemmatized_comment'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb60a80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Reddit_Encoding.csv', index=False)\n",
    "print(\"File saved\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
