{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00d96075",
   "metadata": {},
   "source": [
    "# Automated Hate Speech Detection in Reddit Platform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b557e9a5",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a7206b",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fd1f3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "from stop_words import get_stop_words\n",
    "import demoji\n",
    "import emoji"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb4b83d",
   "metadata": {},
   "source": [
    "### Analyze the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf5d52ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('Original_Reddit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f185787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>hate_speech_idx</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1. e8q18lf\\n2. \\te8q9w5s\\n3. \\t\\te8qbobk\\n4. \\...</td>\n",
       "      <td>1. A subsection of retarded Hungarians? Ohh bo...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[\"I don't see a reason why it's okay to insult...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1. e9c6naz\\n2. \\te9d03a5\\n3. \\t\\te9d8e4d\\n</td>\n",
       "      <td>1. &gt; \"y'all hear sumn?\"  by all means I live i...</td>\n",
       "      <td>[3]</td>\n",
       "      <td>['Persons with disabilities is the accepted te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1. e84rl2i\\n2. \\te84w60l\\n3. \\t\\te8544rn\\n4. \\...</td>\n",
       "      <td>1. wouldn't the defenders or whatever they are...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1. e7kq72n\\n2. \\te7m24ar\\n</td>\n",
       "      <td>1. Because the Japanese aren't retarded and kn...</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[\"It's not right for anyone of any gender to b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1. e7hdgoh\\n2. \\te7iyj6a\\n3. \\t\\te7j6iho\\n4. \\...</td>\n",
       "      <td>1. That might be true if we didn't have an exa...</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>[\"You shouldn't be bringing up sensitive topic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  id  \\\n",
       "0  1. e8q18lf\\n2. \\te8q9w5s\\n3. \\t\\te8qbobk\\n4. \\...   \n",
       "1         1. e9c6naz\\n2. \\te9d03a5\\n3. \\t\\te9d8e4d\\n   \n",
       "2  1. e84rl2i\\n2. \\te84w60l\\n3. \\t\\te8544rn\\n4. \\...   \n",
       "3                         1. e7kq72n\\n2. \\te7m24ar\\n   \n",
       "4  1. e7hdgoh\\n2. \\te7iyj6a\\n3. \\t\\te7j6iho\\n4. \\...   \n",
       "\n",
       "                                                text hate_speech_idx  \\\n",
       "0  1. A subsection of retarded Hungarians? Ohh bo...             [1]   \n",
       "1  1. > \"y'all hear sumn?\"  by all means I live i...             [3]   \n",
       "2  1. wouldn't the defenders or whatever they are...             NaN   \n",
       "3  1. Because the Japanese aren't retarded and kn...             [1]   \n",
       "4  1. That might be true if we didn't have an exa...          [2, 3]   \n",
       "\n",
       "                                            response  \n",
       "0  [\"I don't see a reason why it's okay to insult...  \n",
       "1  ['Persons with disabilities is the accepted te...  \n",
       "2                                                NaN  \n",
       "3  [\"It's not right for anyone of any gender to b...  \n",
       "4  [\"You shouldn't be bringing up sensitive topic...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83fb19ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5020 entries, 0 to 5019\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   id               5020 non-null   object\n",
      " 1   text             5020 non-null   object\n",
      " 2   hate_speech_idx  3847 non-null   object\n",
      " 3   response         3847 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 157.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dc79f7",
   "metadata": {},
   "source": [
    "#### Each row of text contains more than 1 comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9d822a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. Grammatical errors, overt racism, child prostitution.. It would appear we have a despicable moron on our hands. \\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c460049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1. > \"y\\'all hear sumn?\"  by all means I live in a small town rn (for work). 5k people here, originally a mining community. No one is protesting here. Nobody mentioned the protest today. Nobody here cares, they\\'re busy loving their family and working hard.  Thank god for the electoral college. Liberals think we don\\'t matter. \\n2. \\t[removed]\\n3. \\t\\tah a liberal has slipped in. you can tell because the first question asked was loaded and retarded.  >  What does \"working hard\" mean? Your political views get more validated by how much manual labour you put in?   where did I say that? and yes, of course you have no clue what \"working hard\" means. Few soyboys do.  > Based on your comment regarding the EC I guess you don\\'t really think that 2 mil majority of people who voted for Hillary don\\'t really matter.  I shouldn\\'t have to explain to you the point of the EC. If you want to talk to someone who is more patient with you than I am, you can check out AskThe_Donald. \\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d2e43c",
   "metadata": {},
   "source": [
    "#### The corresponding hate speech index determines which comments are categorized as hate speech."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec9dee9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hate_speech_idx'][17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b2c2f93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[3]'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hate_speech_idx'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157fdd9d",
   "metadata": {},
   "source": [
    "#### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "472abd97",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                   5020\n",
       "unique                  5002\n",
       "top       1. What a cunt. \\n\n",
       "freq                       4\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a991594",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     3847\n",
       "unique     316\n",
       "top        [1]\n",
       "freq      1740\n",
       "Name: hate_speech_idx, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['hate_speech_idx'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79c1716d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>hate_speech_idx</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5020</td>\n",
       "      <td>5020</td>\n",
       "      <td>3847</td>\n",
       "      <td>3847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>5015</td>\n",
       "      <td>5002</td>\n",
       "      <td>316</td>\n",
       "      <td>3838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>1. e9ai3dh\\n</td>\n",
       "      <td>1. What a cunt. \\n</td>\n",
       "      <td>[1]</td>\n",
       "      <td>[\"You're disturbingly obsessed with women.\", '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1740</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  id                text hate_speech_idx  \\\n",
       "count           5020                5020            3847   \n",
       "unique          5015                5002             316   \n",
       "top     1. e9ai3dh\\n  1. What a cunt. \\n             [1]   \n",
       "freq               2                   4            1740   \n",
       "\n",
       "                                                 response  \n",
       "count                                                3847  \n",
       "unique                                               3838  \n",
       "top     [\"You're disturbingly obsessed with women.\", '...  \n",
       "freq                                                    3  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e866bcd",
   "metadata": {},
   "source": [
    "### Restructuring the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5999637e",
   "metadata": {},
   "source": [
    "#### Restructuring the dataset to have individual rows for each comment from a post, tagging them with a 1 if they contain hate speech and 0 if not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53d344a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split comments and mark hate speech\n",
    "def process_comments(row):\n",
    "    # Using regex to find the pattern \"index. comment\"\n",
    "    pattern = re.compile(r'(\\d+)\\.\\s(.*?)(?=\\d+\\.\\s|$)', re.DOTALL)\n",
    "    matches = pattern.findall(row['text'])\n",
    "    \n",
    "    # Clean and split the hate_speech_idx column\n",
    "    hate_indices = list(map(int, re.sub(r'[^0-9,]', '', row['hate_speech_idx']).split(','))) if pd.notna(row['hate_speech_idx']) else []\n",
    "    \n",
    "    processed_data = []\n",
    "    \n",
    "    for index, comment in matches:\n",
    "        index = int(index)\n",
    "        comment = comment.strip()\n",
    "        is_hate_speech = 1 if index in hate_indices else 0\n",
    "        processed_data.append([index, comment, is_hate_speech])\n",
    "    \n",
    "    return processed_data\n",
    "\n",
    "processed_comments = df.apply(process_comments, axis=1)\n",
    "processed_comments = [item for sublist in processed_comments for item in sublist]\n",
    "new_df = pd.DataFrame(processed_comments, columns=['index','comment', 'hate_speech'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "08fbe3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File Saved\n"
     ]
    }
   ],
   "source": [
    "new_df.to_csv('Restructure_Reddit.csv', index=False)\n",
    "print(\"File Saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffae5dd",
   "metadata": {},
   "source": [
    "### Import Restructured Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c93f0e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names: Index(['index', 'comment', 'hate_speech'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Restructure_Reddit.csv')\n",
    "print(\"Column names:\", df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "32e1ff22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>comment</th>\n",
       "      <th>hate_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>A subsection of retarded Hungarians? Ohh boy. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Hiii. Just got off work. 444 is mainly the typ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>wow i guess soyboys are the same in every country</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Owen Benjamin's soyboy song goes for every cou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>&gt; \"y'all hear sumn?\"  by all means I live in a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                            comment  hate_speech\n",
       "0      1  A subsection of retarded Hungarians? Ohh boy. ...            1\n",
       "1      2  Hiii. Just got off work. 444 is mainly the typ...            0\n",
       "2      3  wow i guess soyboys are the same in every country            0\n",
       "3      4  Owen Benjamin's soyboy song goes for every cou...            0\n",
       "4      1  > \"y'all hear sumn?\"  by all means I live in a...            0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "205144d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54df9a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>hate_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A subsection of retarded Hungarians? Ohh boy. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hiii. Just got off work. 444 is mainly the typ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wow i guess soyboys are the same in every country</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Owen Benjamin's soyboy song goes for every cou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&gt; \"y'all hear sumn?\"  by all means I live in a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  hate_speech\n",
       "0  A subsection of retarded Hungarians? Ohh boy. ...            1\n",
       "1  Hiii. Just got off work. 444 is mainly the typ...            0\n",
       "2  wow i guess soyboys are the same in every country            0\n",
       "3  Owen Benjamin's soyboy song goes for every cou...            0\n",
       "4  > \"y'all hear sumn?\"  by all means I live in a...            0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b11f2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 22841 entries, 0 to 22840\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   comment      22757 non-null  object\n",
      " 1   hate_speech  22841 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 357.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78ecfcbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hate_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>22841.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.231864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.422032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        hate_speech\n",
       "count  22841.000000\n",
       "mean       0.231864\n",
       "std        0.422032\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000000\n",
       "75%        0.000000\n",
       "max        1.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "550c485a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeEAAAHACAYAAACVutCdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA0gUlEQVR4nO3de1RVdf7/8dcR5YgoRxG5TWhOo4wFecEG0Smvg1LK13KyhtZJy3AcS3LUdJimsmaKKTNbo6tyXKWlzFdnvmWX0Ri8F97DKEkzbXDUAjGFg5ABwv790bh/HkFFQj8Iz8daey32Z7/3Pp/PWdlrffblbIdlWZYAAMAV18J0BwAAaK4IYQAADCGEAQAwhBAGAMAQQhgAAEMIYQAADCGEAQAwhBAGAMCQlqY70JRUV1fr66+/Vrt27eRwOEx3BwBggGVZOnnypMLDw9WixYXnuoRwA/r6668VERFhuhsAgEbg8OHDuuaaay5YQwg3oHbt2kn6/osPCAgw3BsAgAklJSWKiIiwM+FCCOEGdOYUdEBAACEMAM1cXS5LcmMWAACGEMIAABhCCAMAYAghDACAIYQwAACGEMK47D744AONGjVK4eHhcjgcevvtt722OxyOWpc5c+bYNYMGDaqx/e67767188rLy9WrVy85HA7l5ORc9LNeeeWVhh4yANQJjyjhsisrK1PPnj113333acyYMTW25+fne62///77mjBhQo3a5ORkPfXUU/a6n59frZ83c+ZMhYeH65NPPql1++LFizVixAh73eVy1XksANCQCGFcdgkJCUpISDjv9tDQUK/1d955R4MHD9aPf/xjr/Y2bdrUqD3X+++/r8zMTL355pt6//33a61p3779RY8DAFcCp6PRqBw9elSrVq3ShAkTamxLT09XUFCQbrjhBs2YMUMnT56ssW9ycrKWLl2qNm3anPczHnroIQUFBemmm27SK6+8ourq6gYfBwDUBTNhNCqvv/662rVrpzvuuMOr/Z577lHXrl0VGhqq3Nxcpaam6pNPPtGaNWskff+D6ePHj9ekSZPUt29fHTx4sNbj//GPf9TQoUPl5+endevWafr06frmm2/0hz/84XIPDQBqIITRqLz22mu655571Lp1a6/25ORk+++oqCh169ZNffv21a5du9SnTx/Nnz9fJSUlSk1NveDxzw7bXr16SZKeeuopQhiAEZyORqPx4Ycfat++fXrggQcuWtunTx+1atVK+/fvlyStX79e27Ztk9PpVMuWLfWTn/xEktS3b1+NGzfuvMfp16+fSkpKdPTo0YYZBABcAqMhfKUeXSkqKpLb7ZbL5ZLL5ZLb7VZxcbFXzaFDhzRq1Cj5+/srKChIKSkpqqiouFxDRy1effVVxcTEqGfPnhet/eyzz1RZWamwsDBJ0l/+8hd98sknysnJUU5OjlavXi1JWrFihZ5++unzHufjjz9W69at1b59+wYZAwBcCqOno6/UoytJSUk6cuSIMjIyJEkTJ06U2+3We++9J0mqqqrSbbfdpk6dOikrK0vHjx/XuHHjZFmW5s+f3yBjbc5KS0t14MABez0vL085OTkKDAxU586dJX3/6q9//OMfmjt3bo39v/zyS6Wnp+vWW29VUFCQ9uzZo+nTp6t3794aMGCAJNnHOaNt27aSpOuuu85+n+d7772ngoICxcXFyc/PTxs2bNCjjz6qiRMnyul0XpaxA8AFWY2EJGvlypUXrPmf//kfa8iQIV5tAwcOtB5++OHz7rNnzx5LkrVt2za7bevWrZYk6/PPP7csy7JWr15ttWjRwvrqq6/smv/93/+1nE6n5fF46jwGj8djSbqkfZqDDRs2WJJqLOPGjbNrFi5caPn5+VnFxcU19j906JB1yy23WIGBgZavr6913XXXWSkpKdbx48fP+5l5eXmWJOvjjz+2295//32rV69eVtu2ba02bdpYUVFR1osvvmhVVlY25HABNHOXkgUOy7IsQ/nvxeFwaOXKlRo9enSt248ePaprrrlGr7/+upKSkuz2QYMG6bPPPpNlWQoJCVFCQoKeeOIJ+2XKr732mqZNm1bj9HP79u01b9483XfffXr88cf1zjvveP24Q1FRkQIDA7V+/XoNHjy41j6Vl5ervLzcXj/zImePx9Mg7xOOeeSNH3wMoC6y59xrugtAk1FSUiKXy1WnLLhq7o6u76MrBQUFCg4OrnG84OBgFRQU2DUhISFe2zt06CBfX1+7pjZpaWl68sknf+jQAADN1FUTwvV9dEX6fpZ9LsuyvNrrUnOu1NRUTZs2zV4/MxMGAKAuropHlH7IoyuhoaG1Pn5y7Ngxe/YbGhpaY8ZbVFSkysrKGjPkszmdTgUEBHgtAADU1VURwj/k0ZW4uDh5PB7t2LHDrtm+fbs8Ho/69+9v1+Tm5nrdjZ2ZmSmn06mYmJgGHg0AAN8zejr6Sjy60qNHD40YMULJyclauHChpO8fURo5cqQiIyMlSfHx8br++uvldrs1Z84cnThxQjNmzFBycjKzWwDAZWN0JvzRRx+pd+/e6t27tyRp2rRp6t27tx5//HG7Zvny5bIsS7/61a9q7O/r66t169Zp+PDhioyMVEpKiuLj47V27Vr5+PjYdenp6YqOjlZ8fLzi4+N14403aunSpfZ2Hx8frVq1Sq1bt9aAAQM0duxYjR49Ws8///xlHD0AoLlrNI8oNQWXclt6XfCIEq4UHlECGs6lZMFVcU0YAICmiBAGAMAQQhgAAEMIYQAADCGEAQAwhBAGAMAQQhgAAEMIYQAADCGEAQAwhBAGAMAQQhgAAEMIYQAADCGEAQAwhBAGAMAQQhgAAEMIYQAADCGEAQAwhBAGAMAQQhgAAEMIYQAADCGEAQAwhBAGAMAQQhgAAEMIYQAADCGEAQAwhBAGAMAQQhgAAEMIYQAADCGEAQAwhBAGAMAQQhgAAEMIYQAADCGEAQAwhBAGAMAQQhgAAEMIYQAADCGEAQAwhBAGAMAQQhgAAEMIYQAADCGEAQAwxGgIf/DBBxo1apTCw8PlcDj09ttve20fP368HA6H19KvXz+vmvLyck2ZMkVBQUHy9/dXYmKijhw54lVTVFQkt9stl8sll8slt9ut4uJir5pDhw5p1KhR8vf3V1BQkFJSUlRRUXE5hg0AgCTDIVxWVqaePXtqwYIF560ZMWKE8vPz7WX16tVe26dOnaqVK1dq+fLlysrKUmlpqUaOHKmqqiq7JikpSTk5OcrIyFBGRoZycnLkdrvt7VVVVbrttttUVlamrKwsLV++XG+++aamT5/e8IMGAOC/Wpr88ISEBCUkJFywxul0KjQ0tNZtHo9Hr776qpYuXaphw4ZJkpYtW6aIiAitXbtWw4cP1969e5WRkaFt27YpNjZWkrRo0SLFxcVp3759ioyMVGZmpvbs2aPDhw8rPDxckjR37lyNHz9eTz/9tAICAhpw1AAAfK/RXxPeuHGjgoOD1b17dyUnJ6uwsNDelp2drcrKSsXHx9tt4eHhioqK0pYtWyRJW7dulcvlsgNYkvr16yeXy+VVExUVZQewJA0fPlzl5eXKzs4+b9/Ky8tVUlLitQAAUFeNOoQTEhKUnp6u9evXa+7cudq5c6eGDBmi8vJySVJBQYF8fX3VoUMHr/1CQkJUUFBg1wQHB9c4dnBwsFdNSEiI1/YOHTrI19fXrqlNWlqafZ3Z5XIpIiLiB40XANC8GD0dfTF33XWX/XdUVJT69u2rLl26aNWqVbrjjjvOu59lWXI4HPb62X//kJpzpaamatq0afZ6SUkJQQwAqLNGPRM+V1hYmLp06aL9+/dLkkJDQ1VRUaGioiKvusLCQntmGxoaqqNHj9Y41rFjx7xqzp3xFhUVqbKyssYM+WxOp1MBAQFeCwAAdXVVhfDx48d1+PBhhYWFSZJiYmLUqlUrrVmzxq7Jz89Xbm6u+vfvL0mKi4uTx+PRjh077Jrt27fL4/F41eTm5io/P9+uyczMlNPpVExMzJUYGgCgGTJ6Orq0tFQHDhyw1/Py8pSTk6PAwEAFBgZq9uzZGjNmjMLCwnTw4EH9/ve/V1BQkG6//XZJksvl0oQJEzR9+nR17NhRgYGBmjFjhqKjo+27pXv06KERI0YoOTlZCxculCRNnDhRI0eOVGRkpCQpPj5e119/vdxut+bMmaMTJ05oxowZSk5OZnYLALhsjIbwRx99pMGDB9vrZ66vjhs3Ti+//LJ2796tN954Q8XFxQoLC9PgwYO1YsUKtWvXzt5n3rx5atmypcaOHatTp05p6NChWrJkiXx8fOya9PR0paSk2HdRJyYmej2b7OPjo1WrVmny5MkaMGCA/Pz8lJSUpOeff/5yfwUAgGbMYVmWZboTTUVJSYlcLpc8Hk+DzKBjHnmjAXoFXFz2nHtNdwFoMi4lC66qa8IAADQlhDAAAIYQwgAAGEIIAwBgCCEMAIAhhDAAAIYQwgAAGEIIAwBgCCEMAIAhhDAAAIYQwgAAGEIIAwBgCCEMAIAhhDAAAIYQwgAAGEIIAwBgCCEMAIAhhDAAAIYQwgAAGEIIAwBgCCEMAIAhhDAAAIYQwgAAGEIIAwBgCCEMAIAhhDAAAIYQwgAAGEIIAwBgCCEMAIAhhDAAAIYQwgAAGEIIAwBgCCEMAIAhhDAAAIYQwgAAGEIIAwBgCCEMAIAhhDAAAIYQwgAAGEIIAwBgCCEMAIAhRkP4gw8+0KhRoxQeHi6Hw6G3337b3lZZWalZs2YpOjpa/v7+Cg8P17333quvv/7a6xiDBg2Sw+HwWu6++26vmqKiIrndbrlcLrlcLrndbhUXF3vVHDp0SKNGjZK/v7+CgoKUkpKiioqKyzV0AADMhnBZWZl69uypBQsW1Nj27bffateuXXrssce0a9cuvfXWW/riiy+UmJhYozY5OVn5+fn2snDhQq/tSUlJysnJUUZGhjIyMpSTkyO3221vr6qq0m233aaysjJlZWVp+fLlevPNNzV9+vSGHzQAAP/V0uSHJyQkKCEhodZtLpdLa9as8WqbP3++fvazn+nQoUPq3Lmz3d6mTRuFhobWepy9e/cqIyND27ZtU2xsrCRp0aJFiouL0759+xQZGanMzEzt2bNHhw8fVnh4uCRp7ty5Gj9+vJ5++mkFBAQ0xHABAPByVV0T9ng8cjgcat++vVd7enq6goKCdMMNN2jGjBk6efKkvW3r1q1yuVx2AEtSv3795HK5tGXLFrsmKirKDmBJGj58uMrLy5WdnX3e/pSXl6ukpMRrAQCgrozOhC/Fd999p9/97ndKSkrympnec8896tq1q0JDQ5Wbm6vU1FR98skn9iy6oKBAwcHBNY4XHBysgoICuyYkJMRre4cOHeTr62vX1CYtLU1PPvlkQwwPANAMXRUhXFlZqbvvvlvV1dV66aWXvLYlJyfbf0dFRalbt27q27evdu3apT59+kiSHA5HjWNaluXVXpeac6WmpmratGn2eklJiSIiIuo+MABAs9boT0dXVlZq7NixysvL05o1ay56fbZPnz5q1aqV9u/fL0kKDQ3V0aNHa9QdO3bMnv2GhobWmPEWFRWpsrKyxgz5bE6nUwEBAV4LAAB11ahD+EwA79+/X2vXrlXHjh0vus9nn32myspKhYWFSZLi4uLk8Xi0Y8cOu2b79u3yeDzq37+/XZObm6v8/Hy7JjMzU06nUzExMQ08KgAAvmf0dHRpaakOHDhgr+fl5SknJ0eBgYEKDw/XL3/5S+3atUv//Oc/VVVVZc9WAwMD5evrqy+//FLp6em69dZbFRQUpD179mj69Onq3bu3BgwYIEnq0aOHRowYoeTkZPvRpYkTJ2rkyJGKjIyUJMXHx+v666+X2+3WnDlzdOLECc2YMUPJycnMbgEAl43RmfBHH32k3r17q3fv3pKkadOmqXfv3nr88cd15MgRvfvuuzpy5Ih69eqlsLAwezlzV7Ovr6/WrVun4cOHKzIyUikpKYqPj9fatWvl4+Njf056erqio6MVHx+v+Ph43XjjjVq6dKm93cfHR6tWrVLr1q01YMAAjR07VqNHj9bzzz9/Zb8QAECz4rAsyzLdiaaipKRELpdLHo+nQWbQMY+80QC9Ai4ue869prsANBmXkgWN+powAABNGSEMAIAhhDAAAIYQwgAAGEIIAwBgCCEMAIAhhDAAAIYQwgAAGEIIAwBgCCEMAIAhhDAAAIYQwgAAGEIIAwBgCCEMAIAhhDAAAIYQwgAAGEIIAwBgCCEMAIAhhDAAAIYQwgAAGEIIAwBgCCEMAIAhhDAAAIYQwgAAGEIIAwBgCCEMAIAhhDAAAIYQwgAAGEIIAwBgCCEMAIAhhDAAAIYQwgAAGEIIAwBgCCEMAIAhhDAAAIYQwgAAGEIIAwBgCCEMAIAhhDAAAIYQwgAAGEIIAwBgCCEMAIAhRkP4gw8+0KhRoxQeHi6Hw6G3337ba7tlWZo9e7bCw8Pl5+enQYMG6bPPPvOqKS8v15QpUxQUFCR/f38lJibqyJEjXjVFRUVyu91yuVxyuVxyu90qLi72qjl06JBGjRolf39/BQUFKSUlRRUVFZdj2AAASDIcwmVlZerZs6cWLFhQ6/bnnntOL7zwghYsWKCdO3cqNDRUv/jFL3Ty5Em7ZurUqVq5cqWWL1+urKwslZaWauTIkaqqqrJrkpKSlJOTo4yMDGVkZCgnJ0dut9veXlVVpdtuu01lZWXKysrS8uXL9eabb2r69OmXb/AAgGbPYVmWZboTkuRwOLRy5UqNHj1a0vez4PDwcE2dOlWzZs2S9P2sNyQkRM8++6x+/etfy+PxqFOnTlq6dKnuuusuSdLXX3+tiIgIrV69WsOHD9fevXt1/fXXa9u2bYqNjZUkbdu2TXFxcfr8888VGRmp999/XyNHjtThw4cVHh4uSVq+fLnGjx+vwsJCBQQE1GkMJSUlcrlc8ng8dd7nQmIeeeMHHwOoi+w595ruAtBkXEoW1GsmPGTIkBqnc8988JAhQ+pzyBry8vJUUFCg+Ph4u83pdGrgwIHasmWLJCk7O1uVlZVeNeHh4YqKirJrtm7dKpfLZQewJPXr108ul8urJioqyg5gSRo+fLjKy8uVnZ193j6Wl5erpKTEawEAoK7qFcIbN26s9Xrpd999pw8//PAHd0qSCgoKJEkhISFe7SEhIfa2goIC+fr6qkOHDhesCQ4OrnH84OBgr5pzP6dDhw7y9fW1a2qTlpZmX2d2uVyKiIi4xFECAJqzlpdS/Omnn9p/79mzxyugqqqqlJGRoR/96EcN1zt9f5r6bJZl1Wg717k1tdXXp+ZcqampmjZtmr1eUlJCEAMA6uySQrhXr15yOBxyOBy1nnb28/PT/PnzG6RjoaGhkr6fpYaFhdnthYWF9qw1NDRUFRUVKioq8poNFxYWqn///nbN0aNHaxz/2LFjXsfZvn271/aioiJVVlbWmCGfzel0yul01nOEAIDm7pJOR+fl5enLL7+UZVnasWOH8vLy7OWrr75SSUmJ7r///gbpWNeuXRUaGqo1a9bYbRUVFdq0aZMdsDExMWrVqpVXTX5+vnJzc+2auLg4eTwe7dixw67Zvn27PB6PV01ubq7y8/PtmszMTDmdTsXExDTIeAAAONclzYS7dOkiSaqurm6QDy8tLdWBAwfs9by8POXk5CgwMFCdO3fW1KlT9cwzz6hbt27q1q2bnnnmGbVp00ZJSUmSJJfLpQkTJmj69Onq2LGjAgMDNWPGDEVHR2vYsGGSpB49emjEiBFKTk7WwoULJUkTJ07UyJEjFRkZKUmKj4/X9ddfL7fbrTlz5ujEiROaMWOGkpOTG+QuZwAAanNJIXy2L774Qhs3blRhYWGNUH788cfrdIyPPvpIgwcPttfPXF8dN26clixZopkzZ+rUqVOaPHmyioqKFBsbq8zMTLVr187eZ968eWrZsqXGjh2rU6dOaejQoVqyZIl8fHzsmvT0dKWkpNh3UScmJno9m+zj46NVq1Zp8uTJGjBggPz8/JSUlKTnn3/+0r8YAADqqF7PCS9atEi/+c1vFBQUpNDQ0Bo3OO3atatBO3m14DlhXK14ThhoOJeSBfWaCf/pT3/S008/bf+IBgAAuHT1ek64qKhId955Z0P3BQCAZqVeIXznnXcqMzOzofsCAECzUq/T0T/5yU/02GOPadu2bYqOjlarVq28tqekpDRI5wAAaMrqFcJ//etf1bZtW23atEmbNm3y2uZwOAhhAADqoF4hnJeX19D9AACg2TH6PmEAAJqzes2EL/bTlK+99lq9OgMAQHNSrxAuKiryWq+srFRubq6Ki4sb7H3CAAA0dfUK4ZUrV9Zoq66u1uTJk/XjH//4B3cKAIDmoMGuCbdo0UK//e1vNW/evIY6JAAATVqD3pj15Zdf6vTp0w15SAAAmqx6nY4+87ajMyzLUn5+vlatWqVx48Y1SMcAAGjq6hXCH3/8sdd6ixYt1KlTJ82dO/eid04DAIDv1SuEN2zY0ND9AACg2alXCJ9x7Ngx7du3Tw6HQ927d1enTp0aql8AADR59boxq6ysTPfff7/CwsJ0yy236Oabb1Z4eLgmTJigb7/9tqH7CABAk1SvEJ42bZo2bdqk9957T8XFxSouLtY777yjTZs2afr06Q3dRwAAmqR6nY5+88039X//938aNGiQ3XbrrbfKz89PY8eO1csvv9xQ/QMAoMmq10z422+/VUhISI324OBgTkcDAFBH9QrhuLg4PfHEE/ruu+/stlOnTunJJ59UXFxcg3UOAICmrF6no1988UUlJCTommuuUc+ePeVwOJSTkyOn06nMzMyG7iMAAE1SvUI4Ojpa+/fv17Jly/T555/Lsizdfffduueee+Tn59fQfQQAoEmqVwinpaUpJCREycnJXu2vvfaajh07plmzZjVI5wAAaMrqdU144cKF+ulPf1qj/YYbbtArr7zygzsFAEBzUK8QLigoUFhYWI32Tp06KT8//wd3CgCA5qBeIRwREaHNmzfXaN+8ebPCw8N/cKcAAGgO6nVN+IEHHtDUqVNVWVmpIUOGSJLWrVunmTNn8otZAADUUb1CeObMmTpx4oQmT56siooKSVLr1q01a9YspaamNmgHAQBoquoVwg6HQ88++6wee+wx7d27V35+furWrZucTmdD9w8AgCbrB73KsG3btrrpppsaqi8AADQr9boxCwAA/HCEMAAAhhDCAAAYQggDAGAIIQwAgCGEMAAAhhDCAAAYQggDAGAIIQwAgCGEMAAAhjT6EL722mvlcDhqLA8++KAkafz48TW29evXz+sY5eXlmjJlioKCguTv76/ExEQdOXLEq6aoqEhut1sul0sul0tut1vFxcVXapgAgGao0Yfwzp07lZ+fby9r1qyRJN155512zYgRI7xqVq9e7XWMqVOnauXKlVq+fLmysrJUWlqqkSNHqqqqyq5JSkpSTk6OMjIylJGRoZycHLnd7iszSABAs/SDXuBwJXTq1Mlr/c9//rOuu+46DRw40G5zOp0KDQ2tdX+Px6NXX31VS5cu1bBhwyRJy5YtU0REhNauXavhw4dr7969ysjI0LZt2xQbGytJWrRokeLi4rRv3z5FRkZeptEBAJqzRj8TPltFRYWWLVum+++/Xw6Hw27fuHGjgoOD1b17dyUnJ6uwsNDelp2drcrKSsXHx9tt4eHhioqK0pYtWyRJW7dulcvlsgNYkvr16yeXy2XX1Ka8vFwlJSVeCwAAdXVVhfDbb7+t4uJijR8/3m5LSEhQenq61q9fr7lz52rnzp0aMmSIysvLJUkFBQXy9fVVhw4dvI4VEhKigoICuyY4OLjG5wUHB9s1tUlLS7OvIbtcLkVERDTAKAEAzUWjPx19tldffVUJCQkKDw+32+666y7776ioKPXt21ddunTRqlWrdMcdd5z3WJZlec2mz/77fDXnSk1N1bRp0+z1kpISghgAUGdXTQj/5z//0dq1a/XWW29dsC4sLExdunTR/v37JUmhoaGqqKhQUVGR12y4sLBQ/fv3t2uOHj1a41jHjh1TSEjIeT/L6XTK6XTWZzgAAFw9p6MXL16s4OBg3XbbbResO378uA4fPqywsDBJUkxMjFq1amXfVS1J+fn5ys3NtUM4Li5OHo9HO3bssGu2b98uj8dj1wAA0NCuiplwdXW1Fi9erHHjxqlly//f5dLSUs2ePVtjxoxRWFiYDh48qN///vcKCgrS7bffLklyuVyaMGGCpk+fro4dOyowMFAzZsxQdHS0fbd0jx49NGLECCUnJ2vhwoWSpIkTJ2rkyJHcGQ0AuGyuihBeu3atDh06pPvvv9+r3cfHR7t379Ybb7yh4uJihYWFafDgwVqxYoXatWtn182bN08tW7bU2LFjderUKQ0dOlRLliyRj4+PXZOenq6UlBT7LurExEQtWLDgygwQANAsOSzLskx3oqkoKSmRy+WSx+NRQEDADz5ezCNvNECvgIvLnnOv6S4ATcalZMFVc00YAICmhhAGAMAQQhgAAEMIYQAADCGEAQAwhBAGAMAQQhgAAEMIYQAADCGEAQAwhBAGAMAQQhgAAEMIYQAADCGEAQAwhBAGAMAQQhgAAEMIYQAADCGEAQAwhBAGAMAQQhgAAEMIYQAADCGEAQAwhBAGAMAQQhgAAEMIYQAADCGEAQAwhBAGAMAQQhgAAEMIYQAADCGEAQAwhBAGgMts9uzZcjgcXktoaKgkqbKyUrNmzVJ0dLT8/f0VHh6ue++9V19//bXXMb788kvdfvvt6tSpkwICAjR27FgdPXq0xmetWrVKsbGx8vPzU1BQkO64444rMkbUDyEMAFfADTfcoPz8fHvZvXu3JOnbb7/Vrl279Nhjj2nXrl1666239MUXXygxMdHet6ysTPHx8XI4HFq/fr02b96siooKjRo1StXV1Xbdm2++Kbfbrfvuu0+ffPKJNm/erKSkpCs+VtRdS9MdAIDmoGXLlvbs92wul0tr1qzxaps/f75+9rOf6dChQ+rcubM2b96sgwcP6uOPP1ZAQIAkafHixQoMDNT69es1bNgwnT59Wg8//LDmzJmjCRMm2MeKjIy8vAPDD8JMGACugP379ys8PFxdu3bV3XffrX//+9/nrfV4PHI4HGrfvr0kqby8XA6HQ06n065p3bq1WrRooaysLEnSrl279NVXX6lFixbq3bu3wsLClJCQoM8+++yyjgs/DCEMAJdZbGys3njjDf3rX//SokWLVFBQoP79++v48eM1ar/77jv97ne/U1JSkj3r7devn/z9/TVr1ix9++23Kisr0yOPPKLq6mrl5+dLkh3qs2fP1h/+8Af985//VIcOHTRw4ECdOHHiyg0Wl4QQBoDLLCEhQWPGjFF0dLSGDRumVatWSZJef/11r7rKykrdfffdqq6u1ksvvWS3d+rUSf/4xz/03nvvqW3btnK5XPJ4POrTp498fHwkyb42/Oijj2rMmDGKiYnR4sWL5XA49I9//OMKjRSXimvCAHCF+fv7Kzo6Wvv377fbKisrNXbsWOXl5Wn9+vX2LPiM+Ph4ffnll/rmm2/UsmVLtW/fXqGhoerataskKSwsTJJ0/fXX2/s4nU79+Mc/1qFDh67AqFAfzIQB4AorLy/X3r177eA8E8D79+/X2rVr1bFjx/PuGxQUpPbt22v9+vUqLCy076KOiYmR0+nUvn377NrKykodPHhQXbp0ubwDQr0xEwaAy2zGjBkaNWqUOnfurMLCQv3pT39SSUmJxo0bp9OnT+uXv/yldu3apX/+85+qqqpSQUGBJCkwMFC+vr6Svr8bukePHurUqZO2bt2qhx9+WL/97W/tu58DAgI0adIkPfHEE4qIiFCXLl00Z84cSdKdd95pZuC4KEIYAC6zI0eO6Fe/+pW++eYbderUSf369dO2bdvUpUsXHTx4UO+++64kqVevXl77bdiwQYMGDZIk7du3T6mpqTpx4oSuvfZaPfroo/rtb3/rVT9nzhy1bNlSbrdbp06dUmxsrNavX68OHTpciWGiHhyWZVmmO9FUlJSU2DdMnHs9pz5iHnmjAXoFXFz2nHtNd+G8Dj0VbboLaCY6P767QY5zKVnANWEAAAxp1CF8od9blSTLsjR79myFh4fLz89PgwYNqvFgenl5uaZMmaKgoCD5+/srMTFRR44c8aopKiqS2+2Wy+WSy+WS2+1WcXHxlRgiAKAZa9QhLJ3/91Yl6bnnntMLL7ygBQsWaOfOnQoNDdUvfvELnTx50q6ZOnWqVq5cqeXLlysrK0ulpaUaOXKkqqqq7JqkpCTl5OQoIyNDGRkZysnJkdvtvqLjBAA0P43+xqzz/d6qZVl68cUX9eijj9pvCXn99dcVEhKiv/3tb/r1r38tj8ejV199VUuXLtWwYcMkScuWLVNERITWrl2r4cOHa+/evcrIyNC2bdsUGxsrSVq0aJHi4uK0b98+fncVAHDZNPqZ8Pl+bzUvL08FBQWKj4+3a51OpwYOHKgtW7ZIkrKzs1VZWelVEx4erqioKLtm69atcrlcdgBL3/9EnMvlsmvOp7y8XCUlJV4LAAB11ahD+EK/t3rmObqQkBCvfUJCQuxtBQUF8vX1rXF7/rk1wcHBNT47ODjYrjmftLQ0+zqyy+VSREREvccKAGh+GnUI1+X3Vh0Oh9c+lmXVaDvXuTW11dflOKmpqfJ4PPZy+PDhi44JAIAzGnUIn+vs31s9c5343NlqYWGhPTsODQ1VRUWFioqKLlhz9OjRGp917NixGrPsczmdTgUEBHgtAADU1VUVwmf/3mrXrl0VGhrq9TLsiooKbdq0Sf3795f0/W+ptmrVyqsmPz9fubm5dk1cXJw8Ho927Nhh12zfvl0ej8euAQDgcmjUd0df6PdWHQ6Hpk6dqmeeeUbdunVTt27d9Mwzz6hNmzZKSkqSJLlcLk2YMEHTp09Xx44dFRgYqBkzZtintyWpR48eGjFihJKTk7Vw4UJJ0sSJEzVy5EjujAYAXFaNOoQv9HurkjRz5kydOnVKkydPVlFRkWJjY5WZmal27drZx5g3b55atmypsWPH6tSpUxo6dKiWLFliv4NTktLT05WSkmLfRZ2YmKgFCxZc2cECAJodfju6AfHb0bha8dvRAL8dDQBAs0IIAwBgCCEMAIAhhDAAAIYQwgAAGEIIAwBgCCEMAIAhhDAAAIYQwgAAGEIIAwBgCCEMAIAhhDAAAIYQwgAAGEIIAwBgCCEMAIAhhDAAAIYQwgAAGEIIAwBgCCEMAIAhhDAAAIYQwgAAGEIIAwBgCCEMAIAhhDAAAIYQwgAAGEIIAwBgCCEMAIAhhDAAAIYQwgAAGEIIAwBgCCEMAIAhhDAAAIYQwgAAGEIIAwBgCCEMAIAhhDAAAIYQwgAAGEIIAwBgCCEMAIAhhDAAAIYQwgAAGNKoQzgtLU033XST2rVrp+DgYI0ePVr79u3zqhk/frwcDofX0q9fP6+a8vJyTZkyRUFBQfL391diYqKOHDniVVNUVCS32y2XyyWXyyW3263i4uLLPUQAQDPWqEN406ZNevDBB7Vt2zatWbNGp0+fVnx8vMrKyrzqRowYofz8fHtZvXq11/apU6dq5cqVWr58ubKyslRaWqqRI0eqqqrKrklKSlJOTo4yMjKUkZGhnJwcud3uKzJOAEDz1NJ0By4kIyPDa33x4sUKDg5Wdna2brnlFrvd6XQqNDS01mN4PB69+uqrWrp0qYYNGyZJWrZsmSIiIrR27VoNHz5ce/fuVUZGhrZt26bY2FhJ0qJFixQXF6d9+/YpMjLyMo0QANCcNeqZ8Lk8Ho8kKTAw0Kt948aNCg4OVvfu3ZWcnKzCwkJ7W3Z2tiorKxUfH2+3hYeHKyoqSlu2bJEkbd26VS6Xyw5gSerXr59cLpddU5vy8nKVlJR4LQAA1NVVE8KWZWnatGn6+c9/rqioKLs9ISFB6enpWr9+vebOnaudO3dqyJAhKi8vlyQVFBTI19dXHTp08DpeSEiICgoK7Jrg4OAanxkcHGzX1CYtLc2+huxyuRQREdEQQwUANBON+nT02R566CF9+umnysrK8mq/66677L+joqLUt29fdenSRatWrdIdd9xx3uNZliWHw2Gvn/33+WrOlZqaqmnTptnrJSUlBDEAoM6uipnwlClT9O6772rDhg265pprLlgbFhamLl26aP/+/ZKk0NBQVVRUqKioyKuusLBQISEhds3Ro0drHOvYsWN2TW2cTqcCAgK8FgAA6qpRh7BlWXrooYf01ltvaf369eratetF9zl+/LgOHz6ssLAwSVJMTIxatWqlNWvW2DX5+fnKzc1V//79JUlxcXHyeDzasWOHXbN9+3Z5PB67BgCAhtaoT0c/+OCD+tvf/qZ33nlH7dq1s6/Pulwu+fn5qbS0VLNnz9aYMWMUFhamgwcP6ve//72CgoJ0++2327UTJkzQ9OnT1bFjRwUGBmrGjBmKjo6275bu0aOHRowYoeTkZC1cuFCSNHHiRI0cOZI7owEAl02jDuGXX35ZkjRo0CCv9sWLF2v8+PHy8fHR7t279cYbb6i4uFhhYWEaPHiwVqxYoXbt2tn18+bNU8uWLTV27FidOnVKQ4cO1ZIlS+Tj42PXpKenKyUlxb6LOjExUQsWLLj8gwQANFuNOoQty7rgdj8/P/3rX/+66HFat26t+fPna/78+eetCQwM1LJlyy65jwAA1FejviYMAEBTRggDAGAIIQwAgCGEMAAAhhDCAAAYQggDAGAIIQwAgCGEMAAAhhDCAAAYQggDAGAIIQwAgCGEMAAAhhDCAAAYQggDAGAIIQwAgCGEMAAAhhDCAAAYQggDAGAIIQwAgCGEMAAAhhDCAAAYQggDAGAIIQwAgCGEMAAAhhDCAAAYQggDAGAIIQwAgCGEMAAAhhDCAAAYQggDAGAIIQwAgCGEMAAAhhDCAAAYQggDAGAIIQwAgCGEMAAAhhDCAAAYQggDAGAIIQwAgCGEMAAAhhDCAAAYQggDAGAIIXyOl156SV27dlXr1q0VExOjDz/80HSXAABNFCF8lhUrVmjq1Kl69NFH9fHHH+vmm29WQkKCDh06ZLprAIAmiBA+ywsvvKAJEybogQceUI8ePfTiiy8qIiJCL7/8sumuAQCaoJamO9BYVFRUKDs7W7/73e+82uPj47Vly5Za9ykvL1d5ebm97vF4JEklJSUN0qeq8lMNchzgYhrqv9nL4eR3Vaa7gGaiof4dnDmOZVkXrSWE/+ubb75RVVWVQkJCvNpDQkJUUFBQ6z5paWl68skna7RHRERclj4Cl4tr/iTTXQDMS3M16OFOnjwpl+vCxySEz+FwOLzWLcuq0XZGamqqpk2bZq9XV1frxIkT6tix43n3weVVUlKiiIgIHT58WAEBAaa7A1xx/Bswz7IsnTx5UuHh4RetJYT/KygoSD4+PjVmvYWFhTVmx2c4nU45nU6vtvbt21+uLuISBAQE8D8gNGv8GzDrYjPgM7gx6798fX0VExOjNWvWeLWvWbNG/fv3N9QrAEBTxkz4LNOmTZPb7Vbfvn0VFxenv/71rzp06JAmTeJ6GQCg4RHCZ7nrrrt0/PhxPfXUU8rPz1dUVJRWr16tLl26mO4a6sjpdOqJJ56ocZkAaC74N3B1cVh1uYcaAAA0OK4JAwBgCCEMAIAhhDAAAIYQwgAAGEIIo8ngNZRozj744AONGjVK4eHhcjgcevvtt013CXVACKNJ4DWUaO7KysrUs2dPLViwwHRXcAl4RAlNQmxsrPr06eP12skePXpo9OjRSktLM9gz4MpzOBxauXKlRo8ebboruAhmwrjqnXkNZXx8vFf7hV5DCQCNASGMq159XkMJAI0BIYwm41JeQwkAjQEhjKtefV5DCQCNASGMqx6voQRwteItSmgSeA0lmrvS0lIdOHDAXs/Ly1NOTo4CAwPVuXNngz3DhfCIEpqMl156Sc8995z9Gsp58+bplltuMd0t4IrYuHGjBg8eXKN93LhxWrJkyZXvEOqEEAYAwBCuCQMAYAghDACAIYQwAACGEMIAABhCCAMAYAghDACAIYQwAACGEMLAVWLQoEGaOnWq6W5cdfje0JgRwkAzsWTJErVv3950NwCchRAGAMAQQhi4ilRXV2vmzJkKDAxUaGioZs+ebW974YUXFB0dLX9/f0VERGjy5MkqLS2V9P3vCt93333yeDxyOBxyOBz2vhUVFZo5c6Z+9KMfyd/fX7Gxsdq4cWOd+vOf//xHo0aNUocOHeTv768bbrhBq1evtj/T4XBo1apV6tmzp1q3bq3Y2Fjt3r3b6xhbtmzRLbfcIj8/P0VERCglJUVlZWX29rr0b/PmzRo4cKDatGmjDh06aPjw4SoqKqrT9waYRAgDV5HXX39d/v7+2r59u5577jk99dRT9iscW7Roob/85S/Kzc3V66+/rvXr12vmzJmSpP79++vFF19UQECA8vPzlZ+frxkzZkiS7rvvPm3evFnLly/Xp59+qjvvvFMjRozQ/v37L9qfBx98UOXl5frggw+0e/duPfvss2rbtq1XzSOPPKLnn39eO3fuVHBwsBITE1VZWSlJ2r17t4YPH6477rhDn376qVasWKGsrCw99NBD9v4X619OTo6GDh2qG264QVu3blVWVpZGjRqlqqqqOn1vgFEWgKvCwIEDrZ///OdebTfddJM1a9asWuv//ve/Wx07drTXFy9ebLlcLq+aAwcOWA6Hw/rqq6+82ocOHWqlpqZetE/R0dHW7Nmza922YcMGS5K1fPlyu+348eOWn5+ftWLFCsuyLMvtdlsTJ0702u/DDz+0WrRoYZ06dapO/fvVr35lDRgw4Lx9vNTvDbiSeJ8wcBW58cYbvdbDwsJUWFgoSdqwYYOeeeYZ7dmzRyUlJTp9+rS+++47lZWVyd/fv9bj7dq1S5ZlqXv37l7t5eXl6tix40X7k5KSot/85jfKzMzUsGHDNGbMmBp9jIuLs/8ODAxUZGSk9u7dK0nKzs7WgQMHlJ6ebtdYlqXq6mrl5eUpNzf3ov3LycnRnXfeecF+Xuh7A0wihIGrSKtWrbzWHQ6Hqqur9Z///Ee33nqrJk2apD/+8Y8KDAxUVlaWJkyYYJ/6rU11dbV8fHyUnZ0tHx8fr23nnlauzQMPPKDhw4dr1apVyszMVFpamubOnaspU6ZccD+Hw2F//q9//WulpKTUqOncubM+/fTTi/bPz8/vov083/cGmEYIA03ARx99pNOnT2vu3Llq0eL7Wz3+/ve/e9X4+vp6XSeVpN69e6uqqkqFhYW6+eab6/XZERERmjRpkiZNmqTU1FQtWrTIK4S3bdumzp07S5KKior0xRdf6Kc//akkqU+fPvrss8/0k5/8pNZj16V/N954o9atW6cnn3yyXv0HTOLGLKAJuO6663T69GnNnz9f//73v7V06VK98sorXjXXXnutSktLtW7dOn3zzTf69ttv1b17d91zzz2699579dZbbykvL087d+7Us88+a9/lfCFTp07Vv/71L+Xl5WnXrl1av369evTo4VXz1FNPad26dcrNzdX48eMVFBSk0aNHS5JmzZqlrVu36sEHH1ROTo7279+vd9991w7xuvQvNTVVO3fu1OTJk/Xpp5/q888/18svv6xvvvmmAb5Z4PIihIEmoFevXnrhhRf07LPPKioqSunp6UpLS/Oq6d+/vyZNmqS77rpLnTp10nPPPSdJWrx4se69915Nnz5dkZGRSkxM1Pbt2xUREXHRz62qqtKDDz6oHj16aMSIEYqMjNRLL73kVfPnP/9ZDz/8sGJiYpSfn693331Xvr6+kr6fxW7atEn79+/XzTffrN69e+uxxx5TWFiYvf/F+te9e3dlZmbqk08+0c9+9jPFxcXpnXfeUcuWnOhD4+ewLMsy3QkATc/GjRs1ePBgFRUV8UtdwHkwEwYAwBBCGMB5JSQkqG3btrUuzzzzjOnuAVc9TkcDOK+vvvpKp06dqnVbYGCgAgMDr3CPgKaFEAYAwBBORwMAYAghDACAIYQwAACGEMIAABhCCAMAYAghDACAIYQwAACGEMIAABjy/wCvcCEsMzkU/QAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "ax=sns.countplot(x=df['hate_speech'],data=df,order=df['hate_speech'].value_counts().index)\n",
    "for p,label in zip(ax.patches,df['hate_speech'].value_counts()):\n",
    "    ax.annotate(label,(p.get_x()+0.25,p.get_height()+0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704129cf",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9201f1d",
   "metadata": {},
   "source": [
    "#### Remove NaN values and drop comments which are deleted or removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c83555f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment Length:  22841\n",
      "Comment Count:  22757\n",
      "Hate Speech Length:  22841\n",
      "Hate Speech Count:  22841\n"
     ]
    }
   ],
   "source": [
    "size_col0 = len(df['comment'])\n",
    "size_col1 = df['comment'].count()\n",
    "size_col2 = len(df['hate_speech'])\n",
    "size_col3 = df['hate_speech'].count()\n",
    "print(\"Comment Length: \", size_col0)\n",
    "print(\"Comment Count: \", size_col1)\n",
    "print(\"Hate Speech Length: \", size_col2)\n",
    "print(\"Hate Speech Count: \",size_col3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b85b670",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna().loc[(df['comment'] != '[deleted]') & (df['comment'] != '[removed]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c3293986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comment Length:  22246\n",
      "Comment Count:  22246\n",
      "Hate Speech Length:  22246\n",
      "Hate Speech Count:  22246\n"
     ]
    }
   ],
   "source": [
    "size_col0 = len(df['comment'])\n",
    "size_col1 = df['comment'].count()\n",
    "size_col2 = len(df['hate_speech'])\n",
    "size_col3 = df['hate_speech'].count()\n",
    "print(\"Comment Length: \", size_col0)\n",
    "print(\"Comment Count: \", size_col1)\n",
    "print(\"Hate Speech Length: \", size_col2)\n",
    "print(\"Hate Speech Count: \",size_col3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ed0471",
   "metadata": {},
   "source": [
    "### Convert to lowercase \n",
    "\n",
    "\n",
    "#### In tokenization a sentence word by word, same word represented in upper and lower case notations are identified as different words. For example, ‘Basic’ and ‘basic’ are considered different but they both are same,because python is case-sensitive,it adds complexity to model, to simplify it we do lowercasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aede55c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hiii. Just got off work. 444 is mainly the typa guys you imagine writing for US stupid sites, but basically they just try to fit in with the Western European and US big city hipsters.   Rich kids from Budapest who feel they are brave journalistic heroes.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c48614a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>hate_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a subsection of retarded hungarians? ohh boy. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hiii. just got off work. 444 is mainly the typ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wow i guess soyboys are the same in every country</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>owen benjamin's soyboy song goes for every cou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&gt; \"y'all hear sumn?\"  by all means i live in a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  hate_speech\n",
       "0  a subsection of retarded hungarians? ohh boy. ...            1\n",
       "1  hiii. just got off work. 444 is mainly the typ...            0\n",
       "2  wow i guess soyboys are the same in every country            0\n",
       "3  owen benjamin's soyboy song goes for every cou...            0\n",
       "4  > \"y'all hear sumn?\"  by all means i live in a...            0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment']=df['comment'].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "59dbde25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hiii. just got off work. 444 is mainly the typa guys you imagine writing for us stupid sites, but basically they just try to fit in with the western european and us big city hipsters.   rich kids from budapest who feel they are brave journalistic heroes.'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3d4018",
   "metadata": {},
   "source": [
    "### Remove Extra Spaces\n",
    "\n",
    "#### While analyzing text data for classification or other types of analysis, it's essential to ensure the text is clean and well-formatted. Extra spaces, whether between words or at the beginning and end of the text, can lead to inconsistencies and affect the performance of text processing algorithms. Removing these extra spaces helps standardize the text, making it more suitable for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "05d4baf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hiii. just got off work. 444 is mainly the typa guys you imagine writing for us stupid sites, but basically they just try to fit in with the western european and us big city hipsters.   rich kids from budapest who feel they are brave journalistic heroes.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e008f279",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>hate_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a subsection of retarded hungarians? ohh boy. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hiii. just got off work. 444 is mainly the typ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wow i guess soyboys are the same in every country</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>owen benjamin's soyboy song goes for every cou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&gt; \"y'all hear sumn?\" by all means i live in a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  hate_speech\n",
       "0  a subsection of retarded hungarians? ohh boy. ...            1\n",
       "1  hiii. just got off work. 444 is mainly the typ...            0\n",
       "2  wow i guess soyboys are the same in every country            0\n",
       "3  owen benjamin's soyboy song goes for every cou...            0\n",
       "4  > \"y'all hear sumn?\" by all means i live in a ...            0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean_spaces(text):\n",
    "    if isinstance(text, str):\n",
    "        # Remove multiple consecutive spaces and trim leading/trailing spaces\n",
    "        text = ' '.join(text.split())\n",
    "    return text\n",
    "\n",
    "df['comment'] = df['comment'].apply(clean_spaces)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e8507d1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hiii. just got off work. 444 is mainly the typa guys you imagine writing for us stupid sites, but basically they just try to fit in with the western european and us big city hipsters. rich kids from budapest who feel they are brave journalistic heroes.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a22cb1",
   "metadata": {},
   "source": [
    "### Removing HTML Tags \n",
    "\n",
    "#### Removing unwanted data from the text, let’s take the case of scraping data from web, where we get html tags which are unnecessary for the data,those should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "65cee46d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>hate_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a subsection of retarded hungarians? ohh boy. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hiii. just got off work. 444 is mainly the typ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wow i guess soyboys are the same in every country</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>owen benjamin's soyboy song goes for every cou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&gt; \"y'all hear sumn?\" by all means i live in a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  hate_speech\n",
       "0  a subsection of retarded hungarians? ohh boy. ...            1\n",
       "1  hiii. just got off work. 444 is mainly the typ...            0\n",
       "2  wow i guess soyboys are the same in every country            0\n",
       "3  owen benjamin's soyboy song goes for every cou...            0\n",
       "4  > \"y'all hear sumn?\" by all means i live in a ...            0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_html_tags(text):\n",
    "    if isinstance(text, float) or text is None:  # Check for float or None and convert to empty string\n",
    "        text = ''\n",
    "    pattern = re.compile(r'<.*?>')\n",
    "    return pattern.sub('', text)\n",
    "\n",
    "df['comment'] = df['comment'].astype(str)\n",
    "df['comment'] = df['comment'].apply(remove_html_tags)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938e6737",
   "metadata": {},
   "source": [
    "### Removing URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "801ce1c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>hate_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a subsection of retarded hungarians? ohh boy. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hiii. just got off work. 444 is mainly the typ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wow i guess soyboys are the same in every country</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>owen benjamin's soyboy song goes for every cou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&gt; \"y'all hear sumn?\" by all means i live in a ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  hate_speech\n",
       "0  a subsection of retarded hungarians? ohh boy. ...            1\n",
       "1  hiii. just got off work. 444 is mainly the typ...            0\n",
       "2  wow i guess soyboys are the same in every country            0\n",
       "3  owen benjamin's soyboy song goes for every cou...            0\n",
       "4  > \"y'all hear sumn?\" by all means i live in a ...            0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_url(text):\n",
    "    pattern=re.compile(r'https?://\\s+|www.\\.\\S+')\n",
    "    return pattern.sub(r'',text)\n",
    "\n",
    "df['comment']=df['comment'].apply(remove_url)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f1d0fa",
   "metadata": {},
   "source": [
    "### Stop Words Removal \n",
    "\n",
    "#### Words which help in sentence formation, but does not aid any meaning to the sentence like ‘a’, ‘an’, ‘the’, ‘is’ and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a0581abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hiii. just got off work. 444 is mainly the typa guys you imagine writing for us stupid sites, but basically they just try to fit in with the western european and us big city hipsters. rich kids from budapest who feel they are brave journalistic heroes.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e7e163e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>hate_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subsection  retarded hungarians? ohh boy. bra...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hiii. just got  work. 444  mainly  typa guys  ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wow  guess soyboys     every country</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>owen benjamin's soyboy song goes  every countr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&gt; \"y'all hear sumn?\"   means  live   small tow...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  hate_speech\n",
       "0   subsection  retarded hungarians? ohh boy. bra...            1\n",
       "1  hiii. just got  work. 444  mainly  typa guys  ...            0\n",
       "2               wow  guess soyboys     every country            0\n",
       "3  owen benjamin's soyboy song goes  every countr...            0\n",
       "4  > \"y'all hear sumn?\"   means  live   small tow...            0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = get_stop_words('en')\n",
    "def stop_words_removal(text):\n",
    "    new_text=[]\n",
    "    for word in text.split():\n",
    "        if word in get_stop_words('en'):\n",
    "            new_text.append('')\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "    return ' '.join(new_text)\n",
    "\n",
    "df['comment']=df['comment'].apply(stop_words_removal)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "408eff26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hiii. just got  work. 444  mainly  typa guys  imagine writing  us stupid sites,  basically  just try  fit    western european  us big city hipsters. rich kids  budapest  feel   brave journalistic heroes.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a26915",
   "metadata": {},
   "source": [
    "### Chat Word Treatment \n",
    "\n",
    "#### Words like ROFL,LMAO,FYI,GD,ASAP, are found in chat messages of many social media platforms like WhatsApp, Instagram, Twitter. While summarizing the text, to understand the meaning of the word, these short words should be replaced with long forms. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "50a4f48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_words={'AFAIK': 'As Far As I Know',\n",
    "'AFK':'Away From Keyboard',\n",
    "'ASAP':'As Soon As Possible',\n",
    "'ATK':'At The Keyboard',\n",
    "'ATM':'At The Moment',\n",
    "'A3':'Anytime, Anywhere, Anyplace',\n",
    "'BAK':'Back At Keyboard',\n",
    "'BBL': 'Be Back Later',\n",
    "'BBS': 'Be Back Soon',\n",
    "'BFN': 'Bye For Now',\n",
    "'B4N': 'Bye For Now',\n",
    "'BRB': 'Be Right Back',\n",
    "'BRT': 'Be Right There',\n",
    "'BTW': 'By The Way',\n",
    "'B4': 'Before',\n",
    "'B4N': 'Bye For Now',\n",
    "'CU':'See You',\n",
    "'CUL8R':'See You Later',\n",
    "'CYA': 'See You',\n",
    "'FAQ': 'Frequently Asked Questions',\n",
    "'FC': 'Fingers Crossed',\n",
    "'FWIW': 'For What Its Worth',\n",
    "'FYI': 'For Your Information',\n",
    "'GAL': 'Get A Life',\n",
    "'GG': 'Good Game',\n",
    "'GN' : 'Good Night',\n",
    "'GMTA': 'Great Minds Think Alike',\n",
    "'GR8': 'Great!',\n",
    "'G9': 'Genius',\n",
    "'IC': 'I See',\n",
    "'ICQ': 'I Seek you (also a chat program)',\n",
    "'ILU': 'I Love You',\n",
    "'IMHO': 'In My Honest/Humble Opinion',\n",
    "'IMO':'In My Opinion',\n",
    "'IOW':'In Other Words',\n",
    "'IRL': 'In Real Life',\n",
    "'KISS':'Keep It Simple, Stupid',\n",
    "'LDR':'Long Distance Relationship',\n",
    "'LMAO':'Laugh My A.. Off',\n",
    "'LOL':'Laughing Out Loud',\n",
    "'LTNS': 'Long Time No See',\n",
    "'L8R': 'Later',\n",
    "'MTE': 'My Thoughts Exactly',\n",
    "'M8': 'Mate',\n",
    "'NRN': 'No Reply Necessary',\n",
    "'OIC':'Oh I See',\n",
    "'PITA':'Pain In The A..',\n",
    "'PRT': 'Party',\n",
    "'PRW':'Parents Are Watching',\n",
    "'QPSA':\t'Que Pasa?',\n",
    "'ROFL':'Rolling On The Floor Laughing',\n",
    "'ROFLOL': 'Rolling On The Floor Laughing Out Loud',\n",
    "'ROTFLMAO':'Rolling On The Floor Laughing My A.. Off',\n",
    "'SK8':'Skate',\n",
    "'STATS':'Your sex and age',\n",
    "'ASL':'Age, Sex, Location',\n",
    "'THX':'Thank You',\n",
    "'TTFN':'Ta-Ta For Now!',\n",
    "'TTYL':'Talk To You Later',\n",
    "'U':'You',\n",
    "'U2':'You Too',\n",
    "'U4E':'Yours For Ever',\n",
    "'WB':'Welcome Back',\n",
    "'WTF':'What The F...',\n",
    "'WTG':'Way To Go!',\n",
    "'WUF':'Where Are You From?',\n",
    "'W8':'Wait...',\n",
    "'7K':'Sick'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a1bc79e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' apparently  don’t *study*    either.    had, you’d know   much-anticipated modern reformation  islam will never actually happen.  i’m wasting  time.   think marxism   positive influence   christian west,   retarded. last  checked, atheists still need food lol'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment'][16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dbe898a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>hate_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subsection retarded hungarians? ohh boy. brace...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hiii. just got work. 444 mainly typa guys imag...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wow guess soyboys every country</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>owen benjamin's soyboy song goes every country...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&gt; \"y'all hear sumn?\" means live small town rn ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  hate_speech\n",
       "0  subsection retarded hungarians? ohh boy. brace...            1\n",
       "1  hiii. just got work. 444 mainly typa guys imag...            0\n",
       "2                    wow guess soyboys every country            0\n",
       "3  owen benjamin's soyboy song goes every country...            0\n",
       "4  > \"y'all hear sumn?\" means live small town rn ...            0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chat_word(text):\n",
    "    new_text=[]\n",
    "    for word in text.split():\n",
    "        if word.upper() in chat_words:\n",
    "            new_text.append(chat_words[word.upper()])\n",
    "        else:\n",
    "            new_text.append(word)\n",
    "            \n",
    "    return \" \".join(new_text)\n",
    "\n",
    "df['comment']=df['comment'].apply(chat_word)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5dd103c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'apparently don’t *study* either. had, you’d know much-anticipated modern reformation islam will never actually happen. i’m wasting time. think marxism positive influence christian west, retarded. last checked, atheists still need food Laughing Out Loud'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment'][16]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea68239",
   "metadata": {},
   "source": [
    "### Handling Emoji’s \n",
    "\n",
    "#### While analyzing chatting messages, for text classification or sentiment analysis, emoji’s particularly have a meaning, we can replace emoji expression with their corresponding meaning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ea80250e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“harvard working inclusive.” “oh, they’re accepting students next year?” “no, meant they’re literally racist asians.” 👌'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment'][9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "872ed52d-73e5-47c8-9662-040f33afeaa5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>hate_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subsection retarded hungarians? ohh boy. brace...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hiii. just got work. 444 mainly typa guys imag...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wow guess soyboys every country</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>owen benjamin's soyboy song goes every country...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&gt; \"y'all hear sumn?\" means live small town rn ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  hate_speech\n",
       "0  subsection retarded hungarians? ohh boy. brace...            1\n",
       "1  hiii. just got work. 444 mainly typa guys imag...            0\n",
       "2                    wow guess soyboys every country            0\n",
       "3  owen benjamin's soyboy song goes every country...            0\n",
       "4  > \"y'all hear sumn?\" means live small town rn ...            0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_emojis(text): \n",
    "    text=emoji.demojize(text,delimiters=(\"\",\"\"))\n",
    "    return text\n",
    "\n",
    "df['comment']=df['comment'].apply(convert_emojis)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "145ef05e-742f-453b-93d9-749328f05e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'“harvard working inclusive.” “oh, they’re accepting students next year?” “no, meant they’re literally racist asians.” OK_hand'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment'][9]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19cb556d",
   "metadata": {},
   "source": [
    "### Handling Special Numbers\n",
    "\n",
    "#### While analyzing text data for classification or other types of analysis, special numbers within the text can hold significant meaning. These numbers can be replaced with their corresponding meanings to provide context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "37640f1e-cc65-45ad-82be-99defe414c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_meanings = {\n",
    "    '111': 'Alignment and manifestation',\n",
    "    '1111': 'New beginnings and unity',\n",
    "    '222': 'Balance and harmony',\n",
    "    '333': 'Protection and encouragement',\n",
    "    '444': 'Foundation and grounding',\n",
    "    '555': 'Change and transformation',\n",
    "    '666': 'Reflection and personal development',\n",
    "    '777': 'Spiritual growth and good fortune',\n",
    "    '888': 'Abundance and success',\n",
    "    '999': 'Completion and closure',\n",
    "    '1010': 'Personal development and growth',\n",
    "    '1212': 'Spiritual awakening and higher consciousness',\n",
    "    '1234': 'Progress and moving forward',\n",
    "    '2222': 'Peace and balance in life',\n",
    "    '3333': 'Divine protection and guidance',\n",
    "    '4444': 'Strong foundation and support',\n",
    "    '5555': 'Major life changes',\n",
    "    '6666': 'Reflecting on past choices',\n",
    "    '7777': 'Luck and spiritual awareness',\n",
    "    '8888': 'Financial abundance and prosperity',\n",
    "    '9999': 'Endings leading to new beginnings',\n",
    "    '1001': 'Self-improvement and new perspectives',\n",
    "    '1101': 'Opening new doors and opportunities',\n",
    "    '1211': 'Embracing new phases in life',\n",
    "    '1233': 'Balanced progress and harmony',\n",
    "    '1441': 'Foundation and new opportunities',\n",
    "    '1515': 'Personal growth and freedom',\n",
    "    '1616': 'Stability and inner strength',\n",
    "    '1717': 'Awakening and self-awareness',\n",
    "    '1818': 'Financial success and independence',\n",
    "    '1919': 'Completion of cycles and new beginnings',\n",
    "    '2020': 'Vision and clarity',\n",
    "    '2121': 'Positive change and new opportunities',\n",
    "    '2323': 'Creativity and self-expression',\n",
    "    '2424': 'Building strong foundations',\n",
    "    '2525': 'Adaptability and positive change',\n",
    "    '2626': 'Nurturing and care for loved ones',\n",
    "    '2727': 'Spiritual awareness and inner wisdom',\n",
    "    '2828': 'Abundance and prosperity',\n",
    "    '2929': 'Transformation and new phases',\n",
    "    '3030': 'Creativity and communication',\n",
    "    '3131': 'Optimism and positive energy',\n",
    "    '3232': 'Faith and trust in the universe',\n",
    "    '3434': 'Stability and determination',\n",
    "    '3535': 'Personal freedom and individuality',\n",
    "    '3636': 'Nurturing and compassion',\n",
    "    '3737': 'Spiritual growth and awareness',\n",
    "    '3838': 'Ab'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "13bdb5fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hiii. just got work. 444 mainly typa guys imagine writing us stupid sites, basically just try fit western european us big city hipsters. rich kids budapest feel brave journalistic heroes.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fc96d676",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>hate_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subsection retarded hungarians? ohh boy. brace...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hiii. just got work. Foundation and grounding ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wow guess soyboys every country</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>owen benjamin's soyboy song goes every country...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&gt; \"y'all hear sumn?\" means live small town rn ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  hate_speech\n",
       "0  subsection retarded hungarians? ohh boy. brace...            1\n",
       "1  hiii. just got work. Foundation and grounding ...            0\n",
       "2                    wow guess soyboys every country            0\n",
       "3  owen benjamin's soyboy song goes every country...            0\n",
       "4  > \"y'all hear sumn?\" means live small town rn ...            0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def replace_numbers(text):\n",
    "    new_text = []\n",
    "    if isinstance(text, str):\n",
    "        for word in text.split():\n",
    "            if word.isdigit() and word in number_meanings:\n",
    "                new_text.append(number_meanings[word])\n",
    "            elif word.isdigit():\n",
    "                continue  # Skip the word if it is a number and not in number_meanings\n",
    "            else:\n",
    "                new_text.append(word)\n",
    "        text = \" \".join(new_text).strip()\n",
    "    return text\n",
    "\n",
    "df['comment'] = df['comment'].apply(replace_numbers)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5eb83768-ccb8-4676-8099-949cdc40d28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hiii. just got work. Foundation and grounding mainly typa guys imagine writing us stupid sites, basically just try fit western european us big city hipsters. rich kids budapest feel brave journalistic heroes.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c19783e-35c6-47e5-9e28-637b19aa4cdc",
   "metadata": {},
   "source": [
    "### Removing Punctuations \n",
    "\n",
    "#### When we are tokenizing the sentences, punctuations become different words. For example, \"Hello! how are you?\" is tokenized as [Hello , !, how ,are, you,?]. Here punctuation marks are taken as different words. It adds complexity to the model by performing more operations to the code and punctuations does not attribute any meaning to the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "16acdc0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hiii. just got work. Foundation and grounding mainly typa guys imagine writing us stupid sites, basically just try fit western european us big city hipsters. rich kids budapest feel brave journalistic heroes.'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8ee9e4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>hate_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subsection retarded hungarians ohh boy brace l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hiii just got work Foundation and grounding ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wow guess soyboys every country</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>owen benjamins soyboy song goes every country ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yall hear sumn means live small town rn for w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  hate_speech\n",
       "0  subsection retarded hungarians ohh boy brace l...            1\n",
       "1  hiii just got work Foundation and grounding ma...            0\n",
       "2                    wow guess soyboys every country            0\n",
       "3  owen benjamins soyboy song goes every country ...            0\n",
       "4   yall hear sumn means live small town rn for w...            0"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(string.punctuation)\n",
    "exclude=string.punctuation\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    for char in exclude:\n",
    "        text=text.replace(char,'')\n",
    "    return text\n",
    "\n",
    "df['comment']=df['comment'].apply(remove_punctuation)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ba3e3302",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hiii just got work Foundation and grounding mainly typa guys imagine writing us stupid sites basically just try fit western european us big city hipsters rich kids budapest feel brave journalistic heroes'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['comment'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee2b75e",
   "metadata": {},
   "source": [
    "#### Check for null values for preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "29e85a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comment        0\n",
      "hate_speech    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cd19e7",
   "metadata": {},
   "source": [
    "#### Save the Preprocessed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "073fbdaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved\n"
     ]
    }
   ],
   "source": [
    "df.to_csv('Reddit_Preprocessed.csv', index=False)\n",
    "print(\"File saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c093c1da",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "275b0377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e732159c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('Reddit_Preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8e1e3db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comment        35\n",
      "hate_speech     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a7833aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "67ed86ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comment        0\n",
      "hate_speech    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4e991621",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['words'] = df['comment'].apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bbaa9b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subsection retarded hungarians ohh boy brace l...</td>\n",
       "      <td>1</td>\n",
       "      <td>[subsection, retarded, hungarians, ohh, boy, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hiii just got work Foundation and grounding ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>[hiii, just, got, work, Foundation, and, groun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wow guess soyboys every country</td>\n",
       "      <td>0</td>\n",
       "      <td>[wow, guess, soyboys, every, country]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>owen benjamins soyboy song goes every country ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[owen, benjamins, soyboy, song, goes, every, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yall hear sumn means live small town rn for w...</td>\n",
       "      <td>0</td>\n",
       "      <td>[yall, hear, sumn, means, live, small, town, r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  hate_speech  \\\n",
       "0  subsection retarded hungarians ohh boy brace l...            1   \n",
       "1  hiii just got work Foundation and grounding ma...            0   \n",
       "2                    wow guess soyboys every country            0   \n",
       "3  owen benjamins soyboy song goes every country ...            0   \n",
       "4   yall hear sumn means live small town rn for w...            0   \n",
       "\n",
       "                                               words  \n",
       "0  [subsection, retarded, hungarians, ohh, boy, b...  \n",
       "1  [hiii, just, got, work, Foundation, and, groun...  \n",
       "2              [wow, guess, soyboys, every, country]  \n",
       "3  [owen, benjamins, soyboy, song, goes, every, c...  \n",
       "4  [yall, hear, sumn, means, live, small, town, r...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "421e86e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "df['lemmatized_comment'] = df['words'].apply(lambda x: ' '.join([lemmatizer.lemmatize(word, pos='v') for word in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d96f4096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>words</th>\n",
       "      <th>lemmatized_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subsection retarded hungarians ohh boy brace l...</td>\n",
       "      <td>1</td>\n",
       "      <td>[subsection, retarded, hungarians, ohh, boy, b...</td>\n",
       "      <td>subsection retard hungarians ohh boy brace liv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hiii just got work Foundation and grounding ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>[hiii, just, got, work, Foundation, and, groun...</td>\n",
       "      <td>hiii just get work Foundation and ground mainl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wow guess soyboys every country</td>\n",
       "      <td>0</td>\n",
       "      <td>[wow, guess, soyboys, every, country]</td>\n",
       "      <td>wow guess soyboys every country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>owen benjamins soyboy song goes every country ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[owen, benjamins, soyboy, song, goes, every, c...</td>\n",
       "      <td>owen benjamins soyboy song go every country amaze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yall hear sumn means live small town rn for w...</td>\n",
       "      <td>0</td>\n",
       "      <td>[yall, hear, sumn, means, live, small, town, r...</td>\n",
       "      <td>yall hear sumn mean live small town rn for wor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  hate_speech  \\\n",
       "0  subsection retarded hungarians ohh boy brace l...            1   \n",
       "1  hiii just got work Foundation and grounding ma...            0   \n",
       "2                    wow guess soyboys every country            0   \n",
       "3  owen benjamins soyboy song goes every country ...            0   \n",
       "4   yall hear sumn means live small town rn for w...            0   \n",
       "\n",
       "                                               words  \\\n",
       "0  [subsection, retarded, hungarians, ohh, boy, b...   \n",
       "1  [hiii, just, got, work, Foundation, and, groun...   \n",
       "2              [wow, guess, soyboys, every, country]   \n",
       "3  [owen, benjamins, soyboy, song, goes, every, c...   \n",
       "4  [yall, hear, sumn, means, live, small, town, r...   \n",
       "\n",
       "                                  lemmatized_comment  \n",
       "0  subsection retard hungarians ohh boy brace liv...  \n",
       "1  hiii just get work Foundation and ground mainl...  \n",
       "2                    wow guess soyboys every country  \n",
       "3  owen benjamins soyboy song go every country amaze  \n",
       "4  yall hear sumn mean live small town rn for wor...  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c9d4ed",
   "metadata": {},
   "source": [
    "#### Save the Tokenized Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a7a28021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved\n"
     ]
    }
   ],
   "source": [
    "df.to_csv('Reddit_Tokenization.csv', index=False)\n",
    "print(\"File saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8b325c",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7c9f89b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import fasttext\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "40b69cc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>words</th>\n",
       "      <th>lemmatized_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subsection retarded hungarians ohh boy brace l...</td>\n",
       "      <td>1</td>\n",
       "      <td>['subsection', 'retarded', 'hungarians', 'ohh'...</td>\n",
       "      <td>subsection retard hungarians ohh boy brace liv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hiii just got work Foundation and grounding ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>['hiii', 'just', 'got', 'work', 'Foundation', ...</td>\n",
       "      <td>hiii just get work Foundation and ground mainl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wow guess soyboys every country</td>\n",
       "      <td>0</td>\n",
       "      <td>['wow', 'guess', 'soyboys', 'every', 'country']</td>\n",
       "      <td>wow guess soyboys every country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>owen benjamins soyboy song goes every country ...</td>\n",
       "      <td>0</td>\n",
       "      <td>['owen', 'benjamins', 'soyboy', 'song', 'goes'...</td>\n",
       "      <td>owen benjamins soyboy song go every country amaze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yall hear sumn means live small town rn for w...</td>\n",
       "      <td>0</td>\n",
       "      <td>['yall', 'hear', 'sumn', 'means', 'live', 'sma...</td>\n",
       "      <td>yall hear sumn mean live small town rn for wor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  hate_speech  \\\n",
       "0  subsection retarded hungarians ohh boy brace l...            1   \n",
       "1  hiii just got work Foundation and grounding ma...            0   \n",
       "2                    wow guess soyboys every country            0   \n",
       "3  owen benjamins soyboy song goes every country ...            0   \n",
       "4   yall hear sumn means live small town rn for w...            0   \n",
       "\n",
       "                                               words  \\\n",
       "0  ['subsection', 'retarded', 'hungarians', 'ohh'...   \n",
       "1  ['hiii', 'just', 'got', 'work', 'Foundation', ...   \n",
       "2    ['wow', 'guess', 'soyboys', 'every', 'country']   \n",
       "3  ['owen', 'benjamins', 'soyboy', 'song', 'goes'...   \n",
       "4  ['yall', 'hear', 'sumn', 'means', 'live', 'sma...   \n",
       "\n",
       "                                  lemmatized_comment  \n",
       "0  subsection retard hungarians ohh boy brace liv...  \n",
       "1  hiii just get work Foundation and ground mainl...  \n",
       "2                    wow guess soyboys every country  \n",
       "3  owen benjamins soyboy song go every country amaze  \n",
       "4  yall hear sumn mean live small town rn for wor...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Reddit_Tokenization.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f121a526",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tokens'] = df['lemmatized_comment'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "14739c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a pre-trained FastText model (English)\n",
    "model = fasttext.load_model('cc.en.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c78bdbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get word vectors for each token\n",
    "df['word_vectors'] = df['tokens'].apply(lambda tokens: [model.get_word_vector(token) for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "873c01d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to average word vectors\n",
    "def average_word_vectors(word_vectors):\n",
    "    return np.mean(word_vectors, axis=0) if word_vectors else np.zeros(model.get_dimension())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b8a6289d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 comment  \\\n",
      "0      subsection retarded hungarians ohh boy brace l...   \n",
      "1      hiii just got work Foundation and grounding ma...   \n",
      "2                        wow guess soyboys every country   \n",
      "3      owen benjamins soyboy song goes every country ...   \n",
      "4       yall hear sumn means live small town rn for w...   \n",
      "...                                                  ...   \n",
      "22206          op stop faggot post videos next time hard   \n",
      "22207  minute long video top hate champagne goes need...   \n",
      "22208  clue whos ecelebs are point time  need get alo...   \n",
      "22209                        didn’t insult you insult me   \n",
      "22210                                         living lie   \n",
      "\n",
      "                                         document_vector  \n",
      "0      [0.014043219, -0.01809359, 0.017145459, 0.0806...  \n",
      "1      [-0.0030388932, -0.035133556, 0.020659983, 0.0...  \n",
      "2      [0.017362628, 0.005587179, 0.0297773, 0.109146...  \n",
      "3      [0.018085241, 0.0011954829, 2.8959475e-05, 0.0...  \n",
      "4      [0.023993038, -0.00060867134, 0.005239945, 0.0...  \n",
      "...                                                  ...  \n",
      "22206  [0.08339707, -0.017676119, -0.036872935, 0.103...  \n",
      "22207  [0.009342635, 0.02728245, -0.0013451587, 0.076...  \n",
      "22208  [-0.0006810841, 0.008315975, 0.029024707, 0.07...  \n",
      "22209  [0.06474433, -0.17082486, -0.029483724, 0.0438...  \n",
      "22210  [-0.11396426, 0.04755594, -0.07264759, 0.08606...  \n",
      "\n",
      "[22211 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Aggregate word vectors for each document\n",
    "df['document_vector'] = df['word_vectors'].apply(average_word_vectors)\n",
    "print(df[['comment', 'document_vector']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c32bc2e",
   "metadata": {},
   "source": [
    "#### Flatten document vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a27ccaaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             comment  \\\n",
      "0  subsection retarded hungarians ohh boy brace l...   \n",
      "1  hiii just got work Foundation and grounding ma...   \n",
      "2                    wow guess soyboys every country   \n",
      "3  owen benjamins soyboy song goes every country ...   \n",
      "4   yall hear sumn means live small town rn for w...   \n",
      "\n",
      "                                document_vector_flat  \n",
      "0  0.014043219,-0.01809359,0.017145459,0.08062436...  \n",
      "1  -0.0030388932,-0.035133556,0.020659983,0.07383...  \n",
      "2  0.017362628,0.005587179,0.0297773,0.109146975,...  \n",
      "3  0.018085241,0.0011954829,2.8959475e-05,0.07601...  \n",
      "4  0.023993038,-0.00060867134,0.005239945,0.05989...  \n"
     ]
    }
   ],
   "source": [
    "df['document_vector_flat'] = df['document_vector'].apply(lambda vec: ','.join(map(str, vec)))\n",
    "print(df[['comment', 'document_vector_flat']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58099b85",
   "metadata": {},
   "source": [
    "#### Save the Encoded Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9a2bc68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved\n"
     ]
    }
   ],
   "source": [
    "df.to_csv('Reddit_Encoded.csv', index=False, columns=['comment', 'hate_speech', 'lemmatized_comment', 'document_vector_flat'])\n",
    "print(\"File saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff165810",
   "metadata": {},
   "source": [
    "## Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1bfda3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5d056f7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             comment  hate_speech  \\\n",
      "0  subsection retarded hungarians ohh boy brace l...            1   \n",
      "1  hiii just got work Foundation and grounding ma...            0   \n",
      "2                    wow guess soyboys every country            0   \n",
      "3  owen benjamins soyboy song goes every country ...            0   \n",
      "4   yall hear sumn means live small town rn for w...            0   \n",
      "\n",
      "                                  lemmatized_comment  \\\n",
      "0  subsection retard hungarians ohh boy brace liv...   \n",
      "1  hiii just get work Foundation and ground mainl...   \n",
      "2                    wow guess soyboys every country   \n",
      "3  owen benjamins soyboy song go every country amaze   \n",
      "4  yall hear sumn mean live small town rn for wor...   \n",
      "\n",
      "                                document_vector_flat  \n",
      "0  0.014043219,-0.01809359,0.017145459,0.08062436...  \n",
      "1  -0.0030388932,-0.035133556,0.020659983,0.07383...  \n",
      "2  0.017362628,0.005587179,0.0297773,0.109146975,...  \n",
      "3  0.018085241,0.0011954829,2.8959475e-05,0.07601...  \n",
      "4  0.023993038,-0.00060867134,0.005239945,0.05989...  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Reddit_Encoded.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0619d192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [0.014043219, -0.01809359, 0.017145459, 0.0806...\n",
      "1    [-0.0030388932, -0.035133556, 0.020659983, 0.0...\n",
      "2    [0.017362628, 0.005587179, 0.0297773, 0.109146...\n",
      "3    [0.018085241, 0.0011954829, 2.8959475e-05, 0.0...\n",
      "4    [0.023993038, -0.00060867134, 0.005239945, 0.0...\n",
      "Name: document_vector, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Convert the document vectors from their string representation back into numerical form\n",
    "df['document_vector'] = df['document_vector_flat'].apply(lambda x: np.fromstring(x, sep=','))\n",
    "\n",
    "# Ensure the conversion was successful\n",
    "print(df['document_vector'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ca54e927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features (document vectors) and labels (hate speech)\n",
    "X = np.array(df['document_vector'].tolist())\n",
    "y = df['hate_speech']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "17e38b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f05fdd38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(random_state=42)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the SVM\n",
    "model = SVC(kernel='rbf', gamma='scale', random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "model.fit(X_train_resampled, y_train_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "37377832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f21142d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.83\n",
      "Precision: 0.61\n",
      "Recall: 0.79\n",
      "F1-Score: 0.69\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='binary')\n",
    "recall = recall_score(y_test, y_pred, average='binary')\n",
    "f1 = f1_score(y_test, y_pred, average='binary')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "752db516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.84      0.88      3369\n",
      "           1       0.61      0.79      0.69      1074\n",
      "\n",
      "    accuracy                           0.83      4443\n",
      "   macro avg       0.77      0.81      0.78      4443\n",
      "weighted avg       0.85      0.83      0.83      4443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0aa26c3",
   "metadata": {},
   "source": [
    "### HyperParameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "002ef56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "4a32cb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],        # Regularization parameter\n",
    "    'gamma': ['scale', 'auto'],   # Kernel coefficient for 'rbf'\n",
    "    'kernel': ['rbf']             # Kernel type\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "04e0ed70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the SVM\n",
    "svc = SVC(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "aa1cf103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Best Parameters found:  {'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "Best Cross-validation Accuracy: 0.91\n"
     ]
    }
   ],
   "source": [
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=svc, param_grid=param_grid, cv=3, scoring='recall', verbose=1, n_jobs= -1)\n",
    "\n",
    "# Perform GridSearchCV to find the best parameters\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Print the best parameters and best score\n",
    "print(\"Best Parameters found: \", grid_search.best_params_)\n",
    "print(\"Best Cross-validation Accuracy: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2ce00f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the best model found by GridSearchCV\n",
    "best_svc = grid_search.best_estimator_\n",
    "\n",
    "# Train the best model on the full training data\n",
    "best_svc.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions with the best model\n",
    "y_pred = best_svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ed53ea5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.84\n",
      "Precision: 0.69\n",
      "Recall: 0.63\n",
      "F1-Score: 0.66\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='binary')\n",
    "recall = recall_score(y_test, y_pred, average='binary')\n",
    "f1 = f1_score(y_test, y_pred, average='binary')\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b0f4b1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.91      0.90      3369\n",
      "           1       0.69      0.63      0.66      1074\n",
      "\n",
      "    accuracy                           0.84      4443\n",
      "   macro avg       0.79      0.77      0.78      4443\n",
      "weighted avg       0.84      0.84      0.84      4443\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "dd0c3351",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "e9d5c0e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8289\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.89      3369\n",
      "           1       0.64      0.67      0.66      1074\n",
      "\n",
      "    accuracy                           0.83      4443\n",
      "   macro avg       0.77      0.78      0.77      4443\n",
      "weighted avg       0.83      0.83      0.83      4443\n",
      "\n",
      "Benchmark score (SVM): 0.8289\n"
     ]
    }
   ],
   "source": [
    "benchmark_score = evaluate_model(best_svc, X_train_resampled, y_train_resampled, X_test, y_test)\n",
    "\n",
    "print(f\"Benchmark score (SVM): {benchmark_score:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
