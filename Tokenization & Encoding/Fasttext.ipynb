{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a263723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 comment  \\\n",
      "0      subsection retarded hungarians ohh boy brace l...   \n",
      "1      hiii just got work Foundation and grounding ma...   \n",
      "2                        wow guess soyboys every country   \n",
      "3      owen benjamins soyboy song goes every country ...   \n",
      "4       yall hear sumn means live small town rn for w...   \n",
      "...                                                  ...   \n",
      "22206          op stop faggot post videos next time hard   \n",
      "22207  minute long video top hate champagne goes need...   \n",
      "22208  clue whos ecelebs are point time  need get alo...   \n",
      "22209                        didnâ€™t insult you insult me   \n",
      "22210                                         living lie   \n",
      "\n",
      "                                         document_vector  \n",
      "0      [0.014043219, -0.01809359, 0.017145459, 0.0806...  \n",
      "1      [-0.0030388932, -0.035133556, 0.020659983, 0.0...  \n",
      "2      [0.017362628, 0.005587179, 0.0297773, 0.109146...  \n",
      "3      [0.018085241, 0.0011954829, 2.8959475e-05, 0.0...  \n",
      "4      [0.023993038, -0.00060867134, 0.005239945, 0.0...  \n",
      "...                                                  ...  \n",
      "22206  [0.08339707, -0.017676119, -0.036872935, 0.103...  \n",
      "22207  [0.009342635, 0.02728245, -0.0013451587, 0.076...  \n",
      "22208  [-0.0006810841, 0.008315975, 0.029024707, 0.07...  \n",
      "22209  [0.06474433, -0.17082486, -0.029483724, 0.0438...  \n",
      "22210  [-0.11396426, 0.04755594, -0.07264759, 0.08606...  \n",
      "\n",
      "[22211 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import fasttext\n",
    "import numpy as np\n",
    "\n",
    "# Load your dataset (replace 'your_dataset.csv' with your actual file)\n",
    "df = pd.read_csv('Reddit_Tokenization.csv')\n",
    "\n",
    "# Assuming 'lemmatized_comment' contains space-separated lemmatized tokens\n",
    "df['tokens'] = df['lemmatized_comment'].apply(lambda x: x.split())\n",
    "\n",
    "# Load a pre-trained FastText model (e.g., English)\n",
    "model = fasttext.load_model('cc.en.300.bin')\n",
    "\n",
    "# Get word vectors for each token\n",
    "df['word_vectors'] = df['tokens'].apply(lambda tokens: [model.get_word_vector(token) for token in tokens])\n",
    "\n",
    "# Function to average word vectors\n",
    "def average_word_vectors(word_vectors):\n",
    "    return np.mean(word_vectors, axis=0) if word_vectors else np.zeros(model.get_dimension())\n",
    "\n",
    "# Aggregate word vectors for each document\n",
    "df['document_vector'] = df['word_vectors'].apply(average_word_vectors)\n",
    "\n",
    "# Display the DataFrame with document vectors\n",
    "print(df[['comment', 'document_vector']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fa17c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             comment  \\\n",
      "0  subsection retarded hungarians ohh boy brace l...   \n",
      "1  hiii just got work Foundation and grounding ma...   \n",
      "2                    wow guess soyboys every country   \n",
      "3  owen benjamins soyboy song goes every country ...   \n",
      "4   yall hear sumn means live small town rn for w...   \n",
      "\n",
      "                                document_vector_flat  \n",
      "0  0.014043219,-0.01809359,0.017145459,0.08062436...  \n",
      "1  -0.0030388932,-0.035133556,0.020659983,0.07383...  \n",
      "2  0.017362628,0.005587179,0.0297773,0.109146975,...  \n",
      "3  0.018085241,0.0011954829,2.8959475e-05,0.07601...  \n",
      "4  0.023993038,-0.00060867134,0.005239945,0.05989...  \n"
     ]
    }
   ],
   "source": [
    "# Flatten document vectors\n",
    "df['document_vector_flat'] = df['document_vector'].apply(lambda vec: ','.join(map(str, vec)))\n",
    "\n",
    "# Save to CSV\n",
    "df.to_csv('encoded_dataset.csv', index=False, columns=['comment', 'hate_speech', 'lemmatized_comment', 'document_vector_flat'])\n",
    "\n",
    "# Display the DataFrame with document vectors\n",
    "print(df[['comment', 'document_vector_flat']].head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
