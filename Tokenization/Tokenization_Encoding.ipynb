{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c510c9e1-f768-4c87-8f29-5ea1a117bd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a888dcae-62a4-43de-a95d-03386892a815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>hate_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subsection retarded hungarians ohh boy brace l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hiii just got work Foundation and grounding ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wow guess soyboys every country</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>owen benjamins soyboy song goes every country ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yall hear sumn means live small town rn for w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  hate_speech\n",
       "0  subsection retarded hungarians ohh boy brace l...            1\n",
       "1  hiii just got work Foundation and grounding ma...            0\n",
       "2                    wow guess soyboys every country            0\n",
       "3  owen benjamins soyboy song goes every country ...            0\n",
       "4   yall hear sumn means live small town rn for w...            0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Reddit_Preprocessed.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dfafc0-960d-4041-ac0a-806dc1facddc",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4ac75a1-1edf-4e79-a135-3771186461e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Aman Shekhar\n",
      "[nltk_data]     Sachan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 comment  \\\n",
      "0      subsection retarded hungarians ohh boy brace l...   \n",
      "1      hiii just got work Foundation and grounding ma...   \n",
      "2                        wow guess soyboys every country   \n",
      "3      owen benjamins soyboy song goes every country ...   \n",
      "4       yall hear sumn means live small town rn for w...   \n",
      "...                                                  ...   \n",
      "22241          op stop faggot post videos next time hard   \n",
      "22242  minute long video top hate champagne goes need...   \n",
      "22243  clue whos ecelebs are point time  need get alo...   \n",
      "22244                        didn’t insult you insult me   \n",
      "22245                                         living lie   \n",
      "\n",
      "                                                  tokens  \n",
      "0      [subsection, retarded, hungarians, ohh, boy, b...  \n",
      "1      [hiii, just, got, work, foundation, and, groun...  \n",
      "2                  [wow, guess, soyboys, every, country]  \n",
      "3      [owen, benjamins, soyboy, song, goes, every, c...  \n",
      "4      [yall, hear, sumn, means, live, small, town, r...  \n",
      "...                                                  ...  \n",
      "22241  [op, stop, faggot, post, videos, next, time, h...  \n",
      "22242  [minute, long, video, top, hate, champagne, go...  \n",
      "22243  [clue, whos, ecelebs, are, point, time, need, ...  \n",
      "22244              [didn, ’, t, insult, you, insult, me]  \n",
      "22245                                      [living, lie]  \n",
      "\n",
      "[22246 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Word Tokenization with NLTK - Handles punctuation and contractions and Suitable for general text processing.\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Define tokenization function\n",
    "def tokenize_text(text):\n",
    "    if isinstance(text, str):  # Check if the input is a string\n",
    "        return word_tokenize(text.lower())\n",
    "    else:\n",
    "        return []  # Return an empty list for NaN or non-string inputs\n",
    "\n",
    "\n",
    "# Apply tokenization to the DataFrame\n",
    "df['tokens'] = df['comment'].apply(tokenize_text)\n",
    "print(df[['comment', 'tokens']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a19172b4-9d87-4cb4-8aaa-9b1f8262c198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SpaCy Tokenization - A robust tokenizer that handles punctuation, contractions, and multi-word expressions.\n",
    "#(Handles a wide variety of text and Good for syntactic and semantic analysis.)\n",
    "\n",
    "# import spacy\n",
    "\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "# df['tokens_spacy'] = df['comment'].apply(lambda x: [token.text.lower() for token in nlp(x)])\n",
    "# print(df[['comment', 'tokens_spacy']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc6fe8d5-ad43-45e0-812e-833f40068852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subsection retarded hungarians ohh boy brace l...</td>\n",
       "      <td>1</td>\n",
       "      <td>[subsection, retarded, hungarians, ohh, boy, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hiii just got work Foundation and grounding ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>[hiii, just, got, work, foundation, and, groun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wow guess soyboys every country</td>\n",
       "      <td>0</td>\n",
       "      <td>[wow, guess, soyboys, every, country]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>owen benjamins soyboy song goes every country ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[owen, benjamins, soyboy, song, goes, every, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yall hear sumn means live small town rn for w...</td>\n",
       "      <td>0</td>\n",
       "      <td>[yall, hear, sumn, means, live, small, town, r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  hate_speech  \\\n",
       "0  subsection retarded hungarians ohh boy brace l...            1   \n",
       "1  hiii just got work Foundation and grounding ma...            0   \n",
       "2                    wow guess soyboys every country            0   \n",
       "3  owen benjamins soyboy song goes every country ...            0   \n",
       "4   yall hear sumn means live small town rn for w...            0   \n",
       "\n",
       "                                              tokens  \n",
       "0  [subsection, retarded, hungarians, ohh, boy, b...  \n",
       "1  [hiii, just, got, work, foundation, and, groun...  \n",
       "2              [wow, guess, soyboys, every, country]  \n",
       "3  [owen, benjamins, soyboy, song, goes, every, c...  \n",
       "4  [yall, hear, sumn, means, live, small, town, r...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36c13e8d-9ca5-43ac-a78f-2afd6b7ed06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aman Shekhar Sachan\\anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated and will be removed in a future release\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0         1         2         3         4         5         6   \\\n",
      "0 -0.251175  0.411333  0.005816 -0.084610  0.094933 -0.425982  0.152648   \n",
      "1 -0.331190  0.609861  0.029274 -0.004950  0.215589 -0.660030  0.235494   \n",
      "2 -0.365259  0.548870  0.002898  0.061551  0.292027 -0.748879  0.266215   \n",
      "3 -0.250300  0.347068 -0.008472  0.077580  0.215518 -0.501333  0.154633   \n",
      "4 -0.438419  0.657626 -0.003080 -0.069164  0.275322 -0.671642  0.295552   \n",
      "\n",
      "         7         8         9   ...        90        91        92        93  \\\n",
      "0  0.651988 -0.120628 -0.130732  ...  0.409181  0.191700 -0.027522 -0.052436   \n",
      "1  1.035723 -0.166821 -0.226844  ...  0.599045  0.277148 -0.012279 -0.068796   \n",
      "2  1.176665 -0.313497 -0.218774  ...  0.790191  0.236035  0.036444  0.052367   \n",
      "3  0.779339 -0.196540 -0.111574  ...  0.537521  0.119185  0.036577  0.023845   \n",
      "4  1.054249 -0.137912 -0.307651  ...  0.633526  0.275008  0.012784 -0.042302   \n",
      "\n",
      "         94        95        96        97        98        99  \n",
      "0  0.508725  0.193502  0.222731 -0.137926  0.066246  0.032505  \n",
      "1  0.845968  0.352135  0.319913 -0.216364  0.036126  0.013374  \n",
      "2  0.897628  0.404143  0.372533 -0.248781  0.128974 -0.035997  \n",
      "3  0.612798  0.283233  0.253994 -0.204285  0.054519 -0.055682  \n",
      "4  0.945500  0.385048  0.371603 -0.273422  0.042566 -0.031485  \n",
      "\n",
      "[5 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Train a Word2Vec model\n",
    "word2vec_model = Word2Vec(sentences=df['tokens'], vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Function to get Word2Vec vectors for each text\n",
    "def get_word2vec_vectors(tokens, model, vector_size):\n",
    "    vector = np.zeros(vector_size)\n",
    "    valid_words = 0\n",
    "    for word in tokens:\n",
    "        if word in model.wv:\n",
    "            vector += model.wv[word]\n",
    "            valid_words += 1\n",
    "    if valid_words > 0:\n",
    "        vector /= valid_words\n",
    "    return vector\n",
    "\n",
    "# Apply Word2Vec to the dataset\n",
    "df['word2vec_vector'] = df['tokens'].apply(lambda x: get_word2vec_vectors(x, word2vec_model, 100))\n",
    "\n",
    "# Convert Word2Vec features to a DataFrame\n",
    "word2vec_df = pd.DataFrame(df['word2vec_vector'].tolist())\n",
    "\n",
    "print(word2vec_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "983bd5f2-4e9b-45ed-8a8d-46696ecd4f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>tokens</th>\n",
       "      <th>word2vec_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>subsection retarded hungarians ohh boy brace l...</td>\n",
       "      <td>1</td>\n",
       "      <td>[subsection, retarded, hungarians, ohh, boy, b...</td>\n",
       "      <td>[-0.251175391088639, 0.41133259270074113, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hiii just got work Foundation and grounding ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>[hiii, just, got, work, foundation, and, groun...</td>\n",
       "      <td>[-0.3311895348888356, 0.6098612794157816, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wow guess soyboys every country</td>\n",
       "      <td>0</td>\n",
       "      <td>[wow, guess, soyboys, every, country]</td>\n",
       "      <td>[-0.36525934040546415, 0.5488696023821831, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>owen benjamins soyboy song goes every country ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[owen, benjamins, soyboy, song, goes, every, c...</td>\n",
       "      <td>[-0.25029953569173813, 0.34706754656508565, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yall hear sumn means live small town rn for w...</td>\n",
       "      <td>0</td>\n",
       "      <td>[yall, hear, sumn, means, live, small, town, r...</td>\n",
       "      <td>[-0.43841885767933736, 0.6576257680567938, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  hate_speech  \\\n",
       "0  subsection retarded hungarians ohh boy brace l...            1   \n",
       "1  hiii just got work Foundation and grounding ma...            0   \n",
       "2                    wow guess soyboys every country            0   \n",
       "3  owen benjamins soyboy song goes every country ...            0   \n",
       "4   yall hear sumn means live small town rn for w...            0   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [subsection, retarded, hungarians, ohh, boy, b...   \n",
       "1  [hiii, just, got, work, foundation, and, groun...   \n",
       "2              [wow, guess, soyboys, every, country]   \n",
       "3  [owen, benjamins, soyboy, song, goes, every, c...   \n",
       "4  [yall, hear, sumn, means, live, small, town, r...   \n",
       "\n",
       "                                     word2vec_vector  \n",
       "0  [-0.251175391088639, 0.41133259270074113, 0.00...  \n",
       "1  [-0.3311895348888356, 0.6098612794157816, 0.02...  \n",
       "2  [-0.36525934040546415, 0.5488696023821831, 0.0...  \n",
       "3  [-0.25029953569173813, 0.34706754656508565, -0...  \n",
       "4  [-0.43841885767933736, 0.6576257680567938, -0....  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09685147-8d04-499d-92bd-97f4b6152662",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
