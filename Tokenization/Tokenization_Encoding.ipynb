{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c510c9e1-f768-4c87-8f29-5ea1a117bd6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a888dcae-62a4-43de-a95d-03386892a815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>hate_speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A subsection of retarded Hungarians? Oh boy. b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iii. Just got off work. Foundation and groundi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wow i guess cowboys are the same in every country</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Owen Benjamin's cowboy song goes for every cou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&gt; \"y'all hear sun?\" by all means I live in a s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  hate_speech\n",
       "0  A subsection of retarded Hungarians? Oh boy. b...            1\n",
       "1  Iii. Just got off work. Foundation and groundi...            0\n",
       "2  wow i guess cowboys are the same in every country            0\n",
       "3  Owen Benjamin's cowboy song goes for every cou...            0\n",
       "4  > \"y'all hear sun?\" by all means I live in a s...            0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Reddit_final.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3dfafc0-960d-4041-ac0a-806dc1facddc",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4ac75a1-1edf-4e79-a135-3771186461e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Aman Shekhar\n",
      "[nltk_data]     Sachan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 comment  \\\n",
      "0      A subsection of retarded Hungarians? Oh boy. b...   \n",
      "1      Iii. Just got off work. Foundation and groundi...   \n",
      "2      wow i guess cowboys are the same in every country   \n",
      "3      Owen Benjamin's cowboy song goes for every cou...   \n",
      "4      > \"y'all hear sun?\" by all means I live in a s...   \n",
      "...                                                  ...   \n",
      "22241  Of, stop being a forgot and post videos next t...   \n",
      "22242  In this minute long video, Top Hate and Champa...   \n",
      "22243  No clue whos these e-celebs are, but at this p...   \n",
      "22244      I didn’t insult you, why would you insult me?   \n",
      "22245                      Because you are living a lie.   \n",
      "\n",
      "                                                  tokens  \n",
      "0      [a, subsection, of, retarded, hungarians, ?, o...  \n",
      "1      [iii, ., just, got, off, work, ., foundation, ...  \n",
      "2      [wow, i, guess, cowboys, are, the, same, in, e...  \n",
      "3      [owen, benjamin, 's, cowboy, song, goes, for, ...  \n",
      "4      [>, ``, y'all, hear, sun, ?, '', by, all, mean...  \n",
      "...                                                  ...  \n",
      "22241  [of, ,, stop, being, a, forgot, and, post, vid...  \n",
      "22242  [in, this, minute, long, video, ,, top, hate, ...  \n",
      "22243  [no, clue, whos, these, e-celebs, are, ,, but,...  \n",
      "22244  [i, didn, ’, t, insult, you, ,, why, would, yo...  \n",
      "22245             [because, you, are, living, a, lie, .]  \n",
      "\n",
      "[22246 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Word Tokenization with NLTK - Handles punctuation and contractions and Suitable for general text processing.\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Download NLTK data\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Define tokenization function\n",
    "def tokenize_text(text):\n",
    "    if isinstance(text, str):  # Check if the input is a string\n",
    "        return word_tokenize(text.lower())\n",
    "    else:\n",
    "        return []  # Return an empty list for NaN or non-string inputs\n",
    "\n",
    "\n",
    "# Apply tokenization to the DataFrame\n",
    "df['tokens'] = df['comment'].apply(tokenize_text)\n",
    "print(df[['comment', 'tokens']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a19172b4-9d87-4cb4-8aaa-9b1f8262c198",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SpaCy Tokenization - A robust tokenizer that handles punctuation, contractions, and multi-word expressions.\n",
    "#(Handles a wide variety of text and Good for syntactic and semantic analysis.)\n",
    "\n",
    "# import spacy\n",
    "\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "# df['tokens_spacy'] = df['comment'].apply(lambda x: [token.text.lower() for token in nlp(x)])\n",
    "# print(df[['comment', 'tokens_spacy']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc6fe8d5-ad43-45e0-812e-833f40068852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A subsection of retarded Hungarians? Oh boy. b...</td>\n",
       "      <td>1</td>\n",
       "      <td>[a, subsection, of, retarded, hungarians, ?, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iii. Just got off work. Foundation and groundi...</td>\n",
       "      <td>0</td>\n",
       "      <td>[iii, ., just, got, off, work, ., foundation, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wow i guess cowboys are the same in every country</td>\n",
       "      <td>0</td>\n",
       "      <td>[wow, i, guess, cowboys, are, the, same, in, e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Owen Benjamin's cowboy song goes for every cou...</td>\n",
       "      <td>0</td>\n",
       "      <td>[owen, benjamin, 's, cowboy, song, goes, for, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&gt; \"y'all hear sun?\" by all means I live in a s...</td>\n",
       "      <td>0</td>\n",
       "      <td>[&gt;, ``, y'all, hear, sun, ?, '', by, all, mean...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  hate_speech  \\\n",
       "0  A subsection of retarded Hungarians? Oh boy. b...            1   \n",
       "1  Iii. Just got off work. Foundation and groundi...            0   \n",
       "2  wow i guess cowboys are the same in every country            0   \n",
       "3  Owen Benjamin's cowboy song goes for every cou...            0   \n",
       "4  > \"y'all hear sun?\" by all means I live in a s...            0   \n",
       "\n",
       "                                              tokens  \n",
       "0  [a, subsection, of, retarded, hungarians, ?, o...  \n",
       "1  [iii, ., just, got, off, work, ., foundation, ...  \n",
       "2  [wow, i, guess, cowboys, are, the, same, in, e...  \n",
       "3  [owen, benjamin, 's, cowboy, song, goes, for, ...  \n",
       "4  [>, ``, y'all, hear, sun, ?, '', by, all, mean...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36c13e8d-9ca5-43ac-a78f-2afd6b7ed06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\Lib\\site-packages\\paramiko\\transport.py:219: CryptographyDeprecationWarning: Blowfish has been deprecated and will be removed in a future release\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0         1         2         3         4         5         6   \\\n",
      "0  0.024228  0.034538  0.151526 -0.717572  0.319267 -0.452068  0.599014   \n",
      "1  0.018594 -0.081036  0.187420 -0.153866  0.022831 -0.505655  0.717692   \n",
      "2 -0.219919  0.477358  0.167302 -0.117339 -0.040331 -0.375824  0.592844   \n",
      "3  0.040825  0.386046 -0.061500 -0.695316 -0.329573 -0.827267  0.688353   \n",
      "4  0.034304 -0.045680  0.143956 -0.466570  0.125248 -0.486454  0.548949   \n",
      "\n",
      "         7         8         9   ...        90        91        92        93  \\\n",
      "0  0.984125  0.147259 -0.725343  ...  0.189234  0.317745  0.492391 -0.221271   \n",
      "1  1.110163 -0.101841 -0.857093  ...  0.437212  0.499844  0.348613  0.057537   \n",
      "2  1.092306  0.042508 -0.698886  ...  0.390546  0.403835  0.225338 -0.839457   \n",
      "3  0.763487 -0.125009 -0.865352  ...  0.544859  0.823666  0.188625 -0.394568   \n",
      "4  0.957444 -0.202432 -0.814244  ...  0.673100  0.399568  0.155341 -0.135279   \n",
      "\n",
      "         94        95        96        97        98        99  \n",
      "0  0.769897  0.059830  0.238036 -0.453589  0.516597  0.044842  \n",
      "1  0.713175  0.221340 -0.093440 -0.107649  0.131516 -0.435715  \n",
      "2  0.773557  0.225407  0.438742  0.365908  0.344128  0.040176  \n",
      "3  0.594076 -0.149328  0.013988 -0.315811  0.067040 -0.010981  \n",
      "4  0.569052  0.190766  0.072097 -0.134972  0.256293 -0.146810  \n",
      "\n",
      "[5 rows x 100 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Train a Word2Vec model\n",
    "word2vec_model = Word2Vec(sentences=df['tokens'], vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Function to get Word2Vec vectors for each text\n",
    "def get_word2vec_vectors(tokens, model, vector_size):\n",
    "    vector = np.zeros(vector_size)\n",
    "    valid_words = 0\n",
    "    for word in tokens:\n",
    "        if word in model.wv:\n",
    "            vector += model.wv[word]\n",
    "            valid_words += 1\n",
    "    if valid_words > 0:\n",
    "        vector /= valid_words\n",
    "    return vector\n",
    "\n",
    "# Apply Word2Vec to the dataset\n",
    "df['word2vec_vector'] = df['tokens'].apply(lambda x: get_word2vec_vectors(x, word2vec_model, 100))\n",
    "\n",
    "# Convert Word2Vec features to a DataFrame\n",
    "word2vec_df = pd.DataFrame(df['word2vec_vector'].tolist())\n",
    "\n",
    "print(word2vec_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "983bd5f2-4e9b-45ed-8a8d-46696ecd4f85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>tokens</th>\n",
       "      <th>word2vec_vector</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A subsection of retarded Hungarians? Oh boy. b...</td>\n",
       "      <td>1</td>\n",
       "      <td>[a, subsection, of, retarded, hungarians, ?, o...</td>\n",
       "      <td>[0.024227744409942936, 0.03453819876825758, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iii. Just got off work. Foundation and groundi...</td>\n",
       "      <td>0</td>\n",
       "      <td>[iii, ., just, got, off, work, ., foundation, ...</td>\n",
       "      <td>[0.018594301187099434, -0.08103627108810645, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wow i guess cowboys are the same in every country</td>\n",
       "      <td>0</td>\n",
       "      <td>[wow, i, guess, cowboys, are, the, same, in, e...</td>\n",
       "      <td>[-0.21991944704204797, 0.4773578126973007, 0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Owen Benjamin's cowboy song goes for every cou...</td>\n",
       "      <td>0</td>\n",
       "      <td>[owen, benjamin, 's, cowboy, song, goes, for, ...</td>\n",
       "      <td>[0.04082503143904938, 0.38604630845495397, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&gt; \"y'all hear sun?\" by all means I live in a s...</td>\n",
       "      <td>0</td>\n",
       "      <td>[&gt;, ``, y'all, hear, sun, ?, '', by, all, mean...</td>\n",
       "      <td>[0.03430420139797924, -0.04568030201488922, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  hate_speech  \\\n",
       "0  A subsection of retarded Hungarians? Oh boy. b...            1   \n",
       "1  Iii. Just got off work. Foundation and groundi...            0   \n",
       "2  wow i guess cowboys are the same in every country            0   \n",
       "3  Owen Benjamin's cowboy song goes for every cou...            0   \n",
       "4  > \"y'all hear sun?\" by all means I live in a s...            0   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [a, subsection, of, retarded, hungarians, ?, o...   \n",
       "1  [iii, ., just, got, off, work, ., foundation, ...   \n",
       "2  [wow, i, guess, cowboys, are, the, same, in, e...   \n",
       "3  [owen, benjamin, 's, cowboy, song, goes, for, ...   \n",
       "4  [>, ``, y'all, hear, sun, ?, '', by, all, mean...   \n",
       "\n",
       "                                     word2vec_vector  \n",
       "0  [0.024227744409942936, 0.03453819876825758, 0....  \n",
       "1  [0.018594301187099434, -0.08103627108810645, 0...  \n",
       "2  [-0.21991944704204797, 0.4773578126973007, 0.1...  \n",
       "3  [0.04082503143904938, 0.38604630845495397, -0....  \n",
       "4  [0.03430420139797924, -0.04568030201488922, 0....  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09685147-8d04-499d-92bd-97f4b6152662",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Join tokens into space-separated strings\n",
    "df['text'] = df['tokens'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "# Prefix labels with '__label__'\n",
    "df['label'] = '__label__' + df['hate_speech'].astype(str)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_data, test_data = train_test_split(df[['label', 'text']], test_size=0.2, random_state=42)\n",
    "\n",
    "# Save to files\n",
    "train_data[['label', 'text']].to_csv('train.txt', sep=' ', header=None, index=None)\n",
    "test_data[['label', 'text']].to_csv('test.txt', sep=' ', header=None, index=None)\n",
    "\n",
    "# Train a FastText supervised model\n",
    "model = fasttext.train_supervised(input='train.txt', epoch=10, lr=0.1, wordNgrams=2, bucket=200000, dim=100, loss='ova')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13a13248-1164-492a-9be9-25b45828b94f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>tokens</th>\n",
       "      <th>word2vec_vector</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A subsection of retarded Hungarians? Oh boy. b...</td>\n",
       "      <td>1</td>\n",
       "      <td>[a, subsection, of, retarded, hungarians, ?, o...</td>\n",
       "      <td>[0.024227744409942936, 0.03453819876825758, 0....</td>\n",
       "      <td>a subsection of retarded hungarians ? oh boy ....</td>\n",
       "      <td>__label__1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iii. Just got off work. Foundation and groundi...</td>\n",
       "      <td>0</td>\n",
       "      <td>[iii, ., just, got, off, work, ., foundation, ...</td>\n",
       "      <td>[0.018594301187099434, -0.08103627108810645, 0...</td>\n",
       "      <td>iii . just got off work . foundation and groun...</td>\n",
       "      <td>__label__0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wow i guess cowboys are the same in every country</td>\n",
       "      <td>0</td>\n",
       "      <td>[wow, i, guess, cowboys, are, the, same, in, e...</td>\n",
       "      <td>[-0.21991944704204797, 0.4773578126973007, 0.1...</td>\n",
       "      <td>wow i guess cowboys are the same in every country</td>\n",
       "      <td>__label__0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Owen Benjamin's cowboy song goes for every cou...</td>\n",
       "      <td>0</td>\n",
       "      <td>[owen, benjamin, 's, cowboy, song, goes, for, ...</td>\n",
       "      <td>[0.04082503143904938, 0.38604630845495397, -0....</td>\n",
       "      <td>owen benjamin 's cowboy song goes for every co...</td>\n",
       "      <td>__label__0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&gt; \"y'all hear sun?\" by all means I live in a s...</td>\n",
       "      <td>0</td>\n",
       "      <td>[&gt;, ``, y'all, hear, sun, ?, '', by, all, mean...</td>\n",
       "      <td>[0.03430420139797924, -0.04568030201488922, 0....</td>\n",
       "      <td>&gt; `` y'all hear sun ? '' by all means i live i...</td>\n",
       "      <td>__label__0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22241</th>\n",
       "      <td>Of, stop being a forgot and post videos next t...</td>\n",
       "      <td>1</td>\n",
       "      <td>[of, ,, stop, being, a, forgot, and, post, vid...</td>\n",
       "      <td>[0.0032317287781659294, 0.018679809044389165, ...</td>\n",
       "      <td>of , stop being a forgot and post videos next ...</td>\n",
       "      <td>__label__1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22242</th>\n",
       "      <td>In this minute long video, Top Hate and Champa...</td>\n",
       "      <td>0</td>\n",
       "      <td>[in, this, minute, long, video, ,, top, hate, ...</td>\n",
       "      <td>[-0.15791856837940627, 0.2616135396127557, 0.1...</td>\n",
       "      <td>in this minute long video , top hate and champ...</td>\n",
       "      <td>__label__0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22243</th>\n",
       "      <td>No clue whos these e-celebs are, but at this p...</td>\n",
       "      <td>1</td>\n",
       "      <td>[no, clue, whos, these, e-celebs, are, ,, but,...</td>\n",
       "      <td>[-0.00767811543376344, 0.16418187655281366, -0...</td>\n",
       "      <td>no clue whos these e-celebs are , but at this ...</td>\n",
       "      <td>__label__1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22244</th>\n",
       "      <td>I didn’t insult you, why would you insult me?</td>\n",
       "      <td>0</td>\n",
       "      <td>[i, didn, ’, t, insult, you, ,, why, would, yo...</td>\n",
       "      <td>[0.26191420738513654, 0.5319719864771917, 0.13...</td>\n",
       "      <td>i didn ’ t insult you , why would you insult me ?</td>\n",
       "      <td>__label__0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22245</th>\n",
       "      <td>Because you are living a lie.</td>\n",
       "      <td>0</td>\n",
       "      <td>[because, you, are, living, a, lie, .]</td>\n",
       "      <td>[-0.16746660055858748, -0.49405921303800177, 0...</td>\n",
       "      <td>because you are living a lie .</td>\n",
       "      <td>__label__0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22246 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment  hate_speech  \\\n",
       "0      A subsection of retarded Hungarians? Oh boy. b...            1   \n",
       "1      Iii. Just got off work. Foundation and groundi...            0   \n",
       "2      wow i guess cowboys are the same in every country            0   \n",
       "3      Owen Benjamin's cowboy song goes for every cou...            0   \n",
       "4      > \"y'all hear sun?\" by all means I live in a s...            0   \n",
       "...                                                  ...          ...   \n",
       "22241  Of, stop being a forgot and post videos next t...            1   \n",
       "22242  In this minute long video, Top Hate and Champa...            0   \n",
       "22243  No clue whos these e-celebs are, but at this p...            1   \n",
       "22244      I didn’t insult you, why would you insult me?            0   \n",
       "22245                      Because you are living a lie.            0   \n",
       "\n",
       "                                                  tokens  \\\n",
       "0      [a, subsection, of, retarded, hungarians, ?, o...   \n",
       "1      [iii, ., just, got, off, work, ., foundation, ...   \n",
       "2      [wow, i, guess, cowboys, are, the, same, in, e...   \n",
       "3      [owen, benjamin, 's, cowboy, song, goes, for, ...   \n",
       "4      [>, ``, y'all, hear, sun, ?, '', by, all, mean...   \n",
       "...                                                  ...   \n",
       "22241  [of, ,, stop, being, a, forgot, and, post, vid...   \n",
       "22242  [in, this, minute, long, video, ,, top, hate, ...   \n",
       "22243  [no, clue, whos, these, e-celebs, are, ,, but,...   \n",
       "22244  [i, didn, ’, t, insult, you, ,, why, would, yo...   \n",
       "22245             [because, you, are, living, a, lie, .]   \n",
       "\n",
       "                                         word2vec_vector  \\\n",
       "0      [0.024227744409942936, 0.03453819876825758, 0....   \n",
       "1      [0.018594301187099434, -0.08103627108810645, 0...   \n",
       "2      [-0.21991944704204797, 0.4773578126973007, 0.1...   \n",
       "3      [0.04082503143904938, 0.38604630845495397, -0....   \n",
       "4      [0.03430420139797924, -0.04568030201488922, 0....   \n",
       "...                                                  ...   \n",
       "22241  [0.0032317287781659294, 0.018679809044389165, ...   \n",
       "22242  [-0.15791856837940627, 0.2616135396127557, 0.1...   \n",
       "22243  [-0.00767811543376344, 0.16418187655281366, -0...   \n",
       "22244  [0.26191420738513654, 0.5319719864771917, 0.13...   \n",
       "22245  [-0.16746660055858748, -0.49405921303800177, 0...   \n",
       "\n",
       "                                                    text       label  \n",
       "0      a subsection of retarded hungarians ? oh boy ....  __label__1  \n",
       "1      iii . just got off work . foundation and groun...  __label__0  \n",
       "2      wow i guess cowboys are the same in every country  __label__0  \n",
       "3      owen benjamin 's cowboy song goes for every co...  __label__0  \n",
       "4      > `` y'all hear sun ? '' by all means i live i...  __label__0  \n",
       "...                                                  ...         ...  \n",
       "22241  of , stop being a forgot and post videos next ...  __label__1  \n",
       "22242  in this minute long video , top hate and champ...  __label__0  \n",
       "22243  no clue whos these e-celebs are , but at this ...  __label__1  \n",
       "22244  i didn ’ t insult you , why would you insult me ?  __label__0  \n",
       "22245                     because you are living a lie .  __label__0  \n",
       "\n",
       "[22246 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b009223-80f3-47f2-94de-44db114fe275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8733\n",
      "Precision: 0.8590\n",
      "Recall: 0.5879\n",
      "F1-score: 0.6981\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "def evaluate_model(model, test_file):\n",
    "    with open(test_file, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for line in lines:\n",
    "        label, text = line.strip().split(' ', 1)\n",
    "        y_true.append(int(label.replace('__label__', '')))\n",
    "        pred_label, _ = model.predict(text)\n",
    "        y_pred.append(int(pred_label[0].replace('__label__', '')))\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    print(f'Accuracy: {accuracy:.4f}')\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    print(f'F1-score: {f1:.4f}')\n",
    "\n",
    "# Call the evaluate_model function\n",
    "evaluate_model(model, 'test.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc9e281-236f-4a11-bcd9-dbd4056f8224",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
